{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#\n",
    "# Copyright (C) 2023 Maxim Integrated Products, Inc. All Rights Reserved.\n",
    "#\n",
    "# Maxim Integrated Products, Inc. Default Copyright Notice:\n",
    "# https://www.maximintegrated.com/en/aboutus/legal/copyrights.html\n",
    "#\n",
    "###################################################################################################\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "import distiller\n",
    "\n",
    "try:\n",
    "    import tensorboard  # pylint: disable=import-error\n",
    "    import tensorflow  # pylint: disable=import-error\n",
    "    tensorflow.io.gfile = tensorboard.compat.tensorflow_stub.io.gfile\n",
    "except (ModuleNotFoundError, AttributeError):\n",
    "    pass\n",
    "\n",
    "import torchnet.meter as tnt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import distiller.apputils as apputils\n",
    "from distiller.data_loggers import PythonLogger, TensorBoardLogger\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'models'))\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'datasets'))\n",
    "\n",
    "from datasets import nilm\n",
    "import ai8x\n",
    "mod = importlib.import_module(\"ai87net-unetnilm\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "msglogger = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"ukdale\"\n",
    "dataset_fn = nilm.ukdale_get_datasets\n",
    "model_name = \"cnn1dnilm\"\n",
    "num_classes = 5\n",
    "workers = 5\n",
    "batch_size = 8\n",
    "seq_len = 100\n",
    "data_path = \"../data/NILM/\"\n",
    "deterministic = True\n",
    "log_prefix = \"ukdale-train\"\n",
    "log_dir = \"../logs/\"\n",
    "validation_split = 0.1\n",
    "print_freq = 10\n",
    "lr = 1e-4\n",
    "beta_1 = 0.999\n",
    "beta_2 = 0.98\n",
    "quantiles = [0.0025,0.1, 0.5, 0.9, 0.975]\n",
    "patience_scheduler = 5\n",
    "appliance_data = {\n",
    "    \"kettle\": {\n",
    "        \"mean\": 700,\n",
    "        \"std\": 1000,\n",
    "        'window':10,\n",
    "        'on_power_threshold': 2000,\n",
    "        'max_on_power': 3998\n",
    "    },\n",
    "    \"fridge\": {\n",
    "        \"mean\": 200,\n",
    "        \"std\": 400,\n",
    "        \"window\":50,\n",
    "        'on_power_threshold': 50,\n",
    "    },\n",
    "    \"dish washer\": {\n",
    "        \"mean\": 700,\n",
    "        \"std\": 700,\n",
    "        \"window\":50,\n",
    "        'on_power_threshold': 10\n",
    "    },\n",
    "    \"washer dryer\": {\n",
    "        \"mean\": 400,\n",
    "        \"std\": 700,\n",
    "        \"window\":50,\n",
    "        'on_power_threshold': 20,\n",
    "        'max_on_power': 3999\n",
    "    },\n",
    "    \"microwave\": {\n",
    "        \"mean\": 500,\n",
    "        \"std\": 800,\n",
    "        \"window\":10,\n",
    "        'on_power_threshold': 200,\n",
    "    },\n",
    "}\n",
    "appliances = list(appliance_data.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "        def __init__(self, act_mode_8bit):\n",
    "                self.act_mode_8bit = act_mode_8bit\n",
    "                self.truncate_testset = False\n",
    "\n",
    "def count_params(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params\n",
    "\n",
    "class NormDen:\n",
    "        def __init__(self, mini, maxi):\n",
    "               self.mini = mini\n",
    "               self.maxi = maxi\n",
    "\n",
    "        def normalize(self, data):\n",
    "                data = (data - self.mini) / (self.maxi - self.mini)\n",
    "                return data.sub(0.5).mul(256.).round().clamp(min=-128, max=127).div(128.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msglogger = apputils.config_pylogger('logging.conf', log_prefix,\n",
    "                                        log_dir)\n",
    "\n",
    "pylogger = PythonLogger(msglogger, log_1d=True)\n",
    "all_loggers = [pylogger]\n",
    "\n",
    "# tensorboard\n",
    "tflogger = TensorBoardLogger(msglogger.logdir, log_1d=True, comment='_'+dataset_name)\n",
    "\n",
    "tflogger.tblogger.writer.add_text('Command line', \"args ---\")\n",
    "\n",
    "msglogger.info('dataset_name:%s\\ndataset_fn=%s\\nnum_classes=%d\\nmodel_name=%s\\seq_len=%s\\nbatch_size=%d\\nvalidation_split=%s\\nlr=%f',\n",
    "                dataset_name,dataset_fn,num_classes,model_name,seq_len,batch_size,validation_split,lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(act_mode_8bit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, val_set = dataset_fn((data_path, args), load_train=True, load_test=True, load_val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.visualize_batch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, _ = apputils.get_data_loaders(\n",
    "        dataset_fn, (data_path,args), batch_size,\n",
    "        workers, validation_split, deterministic,1, 1, 1)\n",
    "msglogger.info('Dataset sizes:\\n\\ttraining=%d\\n\\tvalidation=%d\\n\\ttest=%d',\n",
    "                   len(train_loader.sampler), len(val_loader.sampler), len(test_loader.sampler))\n",
    "msglogger.info('Augmentations:%s',train_loader.dataset.transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the device, cuda or cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ai8x.set_device(device=85, simulate=False, round_avg=False)\n",
    "\n",
    "model = mod.AI85CNN1DNiLM(in_size=1, output_size=5, dropout=0.4, n_quantiles=len(quantiles), device=device)\n",
    "msglogger.info('model: %s',model)\n",
    "model = model.to(device)\n",
    "\n",
    "msglogger.info('Number of Model Params: %d',count_params(model))\n",
    "\n",
    "# configure tensorboard\n",
    "# dummy_input = torch.randn(1, seq_len)\n",
    "# tflogger.tblogger.writer.add_graph(model.to('cpu'), (dummy_input, ), False)\n",
    "\n",
    "all_loggers.append(tflogger)\n",
    "all_tbloggers = [tflogger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unetnilm.utils import QuantileLoss\n",
    "\n",
    "num_epochs = 10\n",
    "msglogger.info('epochs: %d',num_epochs)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "msglogger.info('Optimizer Type: %s', type(optimizer))\n",
    "# ms_lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 35,100], gamma=0.5)\n",
    "# msglogger.info(\"lr_schedule:%s\",\"base: \"+str(ms_lr_scheduler.base_lrs)+\" milestones: \"+str(ms_lr_scheduler.milestones)+ \" gamma: \"+str(ms_lr_scheduler.gamma))\n",
    "ms_lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=patience_scheduler, verbose=True, min_lr=1e-6, mode=\"max\")\n",
    "# criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "criterion = QuantileLoss(quantiles=quantiles).to(device)\n",
    "\n",
    "qat_policy = {'start_epoch':10,\n",
    "              'weight_bits':8}\n",
    "msglogger.info('qat policy: %s',qat_policy)\n",
    "compression_scheduler = distiller.CompressionScheduler(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(data_loader, model, criterion, loggers, epoch=-1, tflogger=None):\n",
    "        \"\"\"Execute the validation/test loop.\"\"\"\n",
    "\n",
    "        # keep track of incorrect predictions\n",
    "        wrong_samples = None\n",
    "        wrong_preds = None\n",
    "        actual_preds = None\n",
    "        img_names = None\n",
    "\n",
    "        # store loss stats\n",
    "        losses = {'objective_loss': tnt.AverageValueMeter()}\n",
    "        classerr = tnt.ClassErrorMeter(accuracy=True, topk=(1, min(num_classes, 5)))\n",
    "\n",
    "        # validation set info\n",
    "        batch_time = tnt.AverageValueMeter()\n",
    "        total_samples = len(data_loader.sampler)\n",
    "        batch_size = data_loader.batch_size\n",
    "        confusion = tnt.ConfusionMeter(num_classes)\n",
    "        total_steps = (total_samples + batch_size - 1) // batch_size\n",
    "        msglogger.info('%d samples (%d per mini-batch)', total_samples, batch_size)\n",
    "\n",
    "        # Switch to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        end = time.time()\n",
    "        class_probs = []\n",
    "        class_preds = []\n",
    "\n",
    "        # iterate over the batches in the validation set\n",
    "        for validation_step, (inputs, target, states) in enumerate(data_loader):\n",
    "                with torch.no_grad():\n",
    "                        inputs, target, states = inputs.to(device), target.to(device), states.to(device)\n",
    "                        # compute output from model\n",
    "                        target, states = model(inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unetnilm.metrics import get_results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normden = NormDen(mini=-1, maxi=12.92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch_end(outputs):\n",
    "        \n",
    "        # appliance_data = {'fridge': {'window': 50, 'mean': 40.158577, 'std': 53.56288}, 'washer dryer': {'window': 50, 'mean': 27.768433, 'std': 212.51971}, 'kettle': {'window': 10, 'mean': 16.753872, 'std': 191.05873}, 'dish washer': {'window': 50, 'mean': 27.384077, 'std': 239.23492}, 'microwave': {'window': 10, 'mean': 8.35921, 'std': 105.1099}}\n",
    "        pred_power = torch.cat([x['pred_power'] for x in outputs], 0).cpu().numpy()\n",
    "        pred_state = torch.cat([x['pred_state'] for x in outputs], 0).cpu().numpy().astype(np.int32)\n",
    "        power = torch.cat([x['power'] for x in outputs], 0).cpu().numpy()\n",
    "        state = torch.cat([x['state'] for x in outputs], 0).cpu().numpy().astype(np.int32)\n",
    "\n",
    "        for idx, app in enumerate(appliances):\n",
    "                power[:,idx] = (power[:, idx] * appliance_data[app]['std']) + appliance_data[app]['std']\n",
    "                if len(quantiles)>=2:\n",
    "                        pred_power[:,:, idx] = (pred_power[:,:, idx] * appliance_data[app]['std']) + appliance_data[app]['std']\n",
    "                        pred_power[:,:, idx] = np.where(pred_power[:,:, idx]<0, 0, pred_power[:,:, idx])\n",
    "                else:\n",
    "                        pred_power[:, idx] = (pred_power[:, idx] * appliance_data[app]['std']) + appliance_data[app]['std']\n",
    "                        pred_power[:, idx] = np.where(pred_power[:, idx]<0, 0, pred_power[:, idx])    \n",
    "\n",
    "        if len(quantiles)>=2:\n",
    "                idx = len(quantiles)//2\n",
    "                y_pred = pred_power[:,idx]\n",
    "        else:\n",
    "                y_pred = pred_power \n",
    "                \n",
    "        per_app_results, avg_results = get_results_summary(state, pred_state, \n",
    "                                                                        power, y_pred,\n",
    "                                                                        appliances, \n",
    "                                                                        dataset_name.upper())  \n",
    "        logs = {\"pred_power\":pred_power, \n",
    "                \"pred_state\":pred_state, \n",
    "                \"power\":power, \n",
    "                \"state\":state,  \n",
    "                'app_results':per_app_results, \n",
    "                'avg_results':avg_results} \n",
    "        \n",
    "        return logs   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"caching_allocator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store model history across epochs\n",
    "perf_scores_history = []\n",
    "model = model.to(device)\n",
    "\n",
    "name = model_name\n",
    "\n",
    "# start the clock\n",
    "tic = datetime.datetime.now()\n",
    "\n",
    "break_point = 10\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "        if epoch > break_point:\n",
    "                break\n",
    "\n",
    "        if epoch > 0 and epoch == qat_policy['start_epoch']:\n",
    "                print('QAT is starting!')\n",
    "                # Fuse the BN parameters into conv layers before Quantization \n",
    "                ai8x.fuse_bn_layers(model)\n",
    "        \n",
    "                # Switch model from unquantized to quantized for QAT\n",
    "                ai8x.initiate_qat(model, qat_policy)\n",
    "\n",
    "                # Model is re-transferred to GPU in case parameters were added\n",
    "                model.to(device)\n",
    "\n",
    "                # Empty the performance scores list for QAT operation\n",
    "                perf_scores_history = []\n",
    "                name = f'{model_name}_qat'\n",
    "        \n",
    "        # store loss and training stats\n",
    "        losses = {'objective_loss': tnt.AverageValueMeter()}\n",
    "        classerr = tnt.ClassErrorMeter(accuracy=True, topk=(1, min(num_classes, 5)))\n",
    "        batch_time = tnt.AverageValueMeter()\n",
    "        data_time = tnt.AverageValueMeter()\n",
    "\n",
    "        # logging stats\n",
    "        total_samples = len(train_loader.sampler)\n",
    "        batch_size = train_loader.batch_size\n",
    "        steps_per_epoch = (total_samples + batch_size - 1) // batch_size\n",
    "        msglogger.info('Training epoch: %d samples (%d per mini-batch)', total_samples, batch_size)\n",
    "\n",
    "        # Switch to train mode\n",
    "        model.train()\n",
    "        acc_stats = []\n",
    "        end = time.time()\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        # iterate over all batches in the dataset    \n",
    "        for train_step, (inputs, target, states) in enumerate(train_loader):\n",
    "\n",
    "                # Measure data loading time\n",
    "                data_time.add(time.time() - end)\n",
    "\n",
    "                inputs_, target, states = inputs.to(device), target.to(device), states.to(device)\n",
    "\n",
    "                B = inputs_.size(0)\n",
    "\n",
    "                # forward pass and loss calculation\n",
    "                logits, rmse_logits = model(inputs_)\n",
    "\n",
    "                prob, pred = torch.max(F.softmax(logits, 1), 1)\n",
    "                loss_nll   = F.nll_loss(F.log_softmax(logits, 1), states)\n",
    "                if len(quantiles)>1:\n",
    "                        prob=prob.unsqueeze(1).expand_as(rmse_logits)\n",
    "                        loss_mse = criterion(rmse_logits, target)\n",
    "                        mae_score = F.l1_loss(rmse_logits,target.unsqueeze(1).expand_as(rmse_logits))\n",
    "                else:    \n",
    "                        loss_mse = F.mse_loss(rmse_logits, target)\n",
    "                        mae_score = F.l1_loss(rmse_logits, target)\n",
    "\n",
    "                # UNETNILM\n",
    "                loss = loss_nll + loss_mse\n",
    "                res = f1_score(pred, states, task=\"multiclass\", num_classes=5)\n",
    "                logs = {\"nlloss\":loss_nll, \"mseloss\":loss_mse,\n",
    "                        \"mae\":mae_score, \"F1\": res}\n",
    "                \n",
    "                train_logs = {}\n",
    "                for key, value in logs.items():\n",
    "                        train_logs[f'tra_{key}']=value.item()\n",
    "\n",
    "                # # on the last batch store the stats for the epoch\n",
    "                # if train_step >= len(train_loader)-2:\n",
    "                #         if len(target.data.shape) <= 2:\n",
    "                #                 classerr.add(target.data, target)\n",
    "                #         else:\n",
    "                #                 classerr.add(target.data.permute(0, 2, 3, 1).flatten(start_dim=0, end_dim=2),\n",
    "                #                                 target.flatten())\n",
    "                #         acc_stats.append([classerr.value(1), classerr.value(min(num_classes, 5))])\n",
    "\n",
    "                # add the loss for each batch\n",
    "                losses[\"objective_loss\"].add(loss.item())\n",
    "\n",
    "                # reset the optimizer\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # backwards pass and parameter update\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "                # track batch stats\n",
    "                batch_time.add(time.time() - end)\n",
    "                steps_completed = (train_step+1)\n",
    "\n",
    "                # log stats every 10 batches\n",
    "                if steps_completed % print_freq == 0 or steps_completed == steps_per_epoch:\n",
    "                # Log some statistics\n",
    "                        errs = OrderedDict()\n",
    "                        stats_dict = OrderedDict()\n",
    "                        stats_dict.update(train_logs)\n",
    "\n",
    "                        for loss_name, meter in losses.items():\n",
    "                                stats_dict[loss_name] = meter.mean\n",
    "                        stats_dict.update(errs)\n",
    "\n",
    "                        stats_dict['LR'] = optimizer.param_groups[0]['lr']\n",
    "                        stats_dict['Time'] = batch_time.mean\n",
    "                        stats = ('Performance/Training/', stats_dict)\n",
    "                        params = None\n",
    "                        distiller.log_training_progress(stats,\n",
    "                                                        params,\n",
    "                                                        epoch, steps_completed,\n",
    "                                                        steps_per_epoch, print_freq,\n",
    "                                                        all_loggers)\n",
    "                end = time.time()\n",
    "\n",
    "                # Test\n",
    "                with torch.no_grad():\n",
    "                        logits, pred_power  = model(inputs_)\n",
    "\n",
    "                prob, pred_state = torch.max(F.softmax(logits, 1), 1)\n",
    "                if len(quantiles)>1:\n",
    "                        prob=prob.unsqueeze(1).expand_as(pred_power)\n",
    "                \n",
    "                logs = {\"pred_power\":pred_power, \"pred_state\":pred_state, \"power\":target, \"state\":states}\n",
    "\n",
    "                outputs.append(logs)\n",
    "\n",
    "                del logits\n",
    "                del rmse_logits \n",
    "                del logs\n",
    "                del pred_power\n",
    "                del prob\n",
    "                del pred_state\n",
    "                del inputs_\n",
    "\n",
    "outputs = test_epoch_end(outputs)\n",
    "print(outputs)\n",
    "\n",
    "# after a training epoch, do validation\n",
    "msglogger.info('--- validate (epoch=%d)-----------', epoch)\n",
    "\n",
    "# vloss = validate(val_loader, model, criterion, [pylogger], epoch, tflogger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
