{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#\n",
    "# Copyright (C) 2023 Maxim Integrated Products, Inc. All Rights Reserved.\n",
    "#\n",
    "# Maxim Integrated Products, Inc. Default Copyright Notice:\n",
    "# https://www.maximintegrated.com/en/aboutus/legal/copyrights.html\n",
    "#\n",
    "###################################################################################################\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "import distiller\n",
    "\n",
    "try:\n",
    "    import tensorboard  # pylint: disable=import-error\n",
    "    import tensorflow  # pylint: disable=import-error\n",
    "    tensorflow.io.gfile = tensorboard.compat.tensorflow_stub.io.gfile\n",
    "except (ModuleNotFoundError, AttributeError):\n",
    "    pass\n",
    "\n",
    "import torchnet.meter as tnt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import distiller.apputils as apputils\n",
    "from distiller.data_loggers import PythonLogger, TensorBoardLogger\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'models'))\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'datasets'))\n",
    "\n",
    "from datasets import nilm\n",
    "import ai8x\n",
    "mod = importlib.import_module(\"ai87net-unetnilm\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "msglogger = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"ukdale\"\n",
    "dataset_fn = nilm.ukdale_get_datasets\n",
    "model_name = \"cnn1dnilm\"\n",
    "num_classes = 5\n",
    "workers = 5\n",
    "batch_size = 8\n",
    "seq_len = 100\n",
    "data_path = \"../data/NILM/\"\n",
    "deterministic = True\n",
    "log_prefix = \"ukdale-train\"\n",
    "log_dir = \"jupyter_logging\"\n",
    "validation_split = 0.1\n",
    "print_freq = 10\n",
    "lr = 1e-4\n",
    "beta_1 = 0.999\n",
    "beta_2 = 0.98\n",
    "quantiles = [0.0025,0.1, 0.5, 0.9, 0.975]\n",
    "patience_scheduler = 5\n",
    "appliance_data = {\n",
    "    \"kettle\": {\n",
    "        \"mean\": 700,\n",
    "        \"std\": 1000,\n",
    "        'window':10,\n",
    "        'on_power_threshold': 2000,\n",
    "        'max_on_power': 3998\n",
    "    },\n",
    "    \"fridge\": {\n",
    "        \"mean\": 200,\n",
    "        \"std\": 400,\n",
    "        \"window\":50,\n",
    "        'on_power_threshold': 50,\n",
    "    },\n",
    "    \"dish washer\": {\n",
    "        \"mean\": 700,\n",
    "        \"std\": 700,\n",
    "        \"window\":50,\n",
    "        'on_power_threshold': 10\n",
    "    },\n",
    "    \"washer dryer\": {\n",
    "        \"mean\": 400,\n",
    "        \"std\": 700,\n",
    "        \"window\":50,\n",
    "        'on_power_threshold': 20,\n",
    "        'max_on_power': 3999\n",
    "    },\n",
    "    \"microwave\": {\n",
    "        \"mean\": 500,\n",
    "        \"std\": 800,\n",
    "        \"window\":10,\n",
    "        'on_power_threshold': 200,\n",
    "    },\n",
    "}\n",
    "appliances = list(appliance_data.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "        def __init__(self, act_mode_8bit):\n",
    "                self.act_mode_8bit = act_mode_8bit\n",
    "                self.truncate_testset = False\n",
    "\n",
    "def count_params(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log file for this run: C:\\Users\\MTinaco\\Dev\\ai8x-training\\notebooks\\jupyter_logging\\ukdale-train___2024.02.12-151238\\ukdale-train___2024.02.12-151238.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------\n",
      "Logging to TensorBoard - remember to execute the server:\n",
      "> tensorboard --logdir='./logs'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dataset_name:ukdale\n",
      "dataset_fn=<function ukdale_get_datasets at 0x00000269B0407670>\n",
      "num_classes=5\n",
      "model_name=cnn1dnilm\\seq_len=100\n",
      "batch_size=8\n",
      "validation_split=0.1\n",
      "lr=0.000100\n"
     ]
    }
   ],
   "source": [
    "msglogger = apputils.config_pylogger('logging.conf', log_prefix,\n",
    "                                        log_dir)\n",
    "\n",
    "pylogger = PythonLogger(msglogger, log_1d=True)\n",
    "all_loggers = [pylogger]\n",
    "\n",
    "# tensorboard\n",
    "tflogger = TensorBoardLogger(msglogger.logdir, log_1d=True, comment='_'+dataset_name)\n",
    "\n",
    "tflogger.tblogger.writer.add_text('Command line', \"args ---\")\n",
    "\n",
    "msglogger.info('dataset_name:%s\\ndataset_fn=%s\\nnum_classes=%d\\nmodel_name=%s\\seq_len=%s\\nbatch_size=%d\\nvalidation_split=%s\\nlr=%f',\n",
    "                dataset_name,dataset_fn,num_classes,model_name,seq_len,batch_size,validation_split,lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(act_mode_8bit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, val_set = dataset_fn((data_path, args), load_train=True, load_test=True, load_val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "train_set.visualize_batch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "\ttraining=582237\n",
      "\tvalidation=64692\n",
      "\ttest=161658\n",
      "Augmentations:Compose(\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, _ = apputils.get_data_loaders(\n",
    "        dataset_fn, (data_path,args), batch_size,\n",
    "        workers, validation_split, deterministic,1, 1, 1)\n",
    "msglogger.info('Dataset sizes:\\n\\ttraining=%d\\n\\tvalidation=%d\\n\\ttest=%d',\n",
    "                   len(train_loader.sampler), len(val_loader.sampler), len(test_loader.sampler))\n",
    "msglogger.info('Augmentations:%s',train_loader.dataset.transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the device, cuda or cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring device: MAX78000, simulate=False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model: AI85CNN1DNiLM(\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (enc_net): Encoder(\n",
      "    (conv_stack): Sequential(\n",
      "      (0): Conv1D(\n",
      "        (net): FusedConv1dBNReLU(\n",
      "          (activate): ReLU(inplace=True)\n",
      "          (op): Conv1d(1, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (bn): BatchNorm1d(4, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
      "          (calc_out_shift): OutputShiftSqueeze()\n",
      "          (calc_weight_scale): One()\n",
      "          (scale): Scaler()\n",
      "          (calc_out_scale): OutputScale()\n",
      "          (quantize_weight): Empty()\n",
      "          (quantize_bias): Empty()\n",
      "          (clamp_weight): Empty()\n",
      "          (clamp_bias): Empty()\n",
      "          (quantize): Empty()\n",
      "          (clamp): Clamp()\n",
      "          (quantize_pool): Empty()\n",
      "          (clamp_pool): Empty()\n",
      "        )\n",
      "      )\n",
      "      (1): Conv1D(\n",
      "        (net): FusedConv1dBNReLU(\n",
      "          (activate): ReLU(inplace=True)\n",
      "          (op): Conv1d(4, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (bn): BatchNorm1d(8, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
      "          (calc_out_shift): OutputShiftSqueeze()\n",
      "          (calc_weight_scale): One()\n",
      "          (scale): Scaler()\n",
      "          (calc_out_scale): OutputScale()\n",
      "          (quantize_weight): Empty()\n",
      "          (quantize_bias): Empty()\n",
      "          (clamp_weight): Empty()\n",
      "          (clamp_bias): Empty()\n",
      "          (quantize): Empty()\n",
      "          (clamp): Clamp()\n",
      "          (quantize_pool): Empty()\n",
      "          (clamp_pool): Empty()\n",
      "        )\n",
      "      )\n",
      "      (2): Conv1D(\n",
      "        (net): FusedConv1dBNReLU(\n",
      "          (activate): ReLU(inplace=True)\n",
      "          (op): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
      "          (calc_out_shift): OutputShiftSqueeze()\n",
      "          (calc_weight_scale): One()\n",
      "          (scale): Scaler()\n",
      "          (calc_out_scale): OutputScale()\n",
      "          (quantize_weight): Empty()\n",
      "          (quantize_bias): Empty()\n",
      "          (clamp_weight): Empty()\n",
      "          (clamp_bias): Empty()\n",
      "          (quantize): Empty()\n",
      "          (clamp): Clamp()\n",
      "          (quantize_pool): Empty()\n",
      "          (clamp_pool): Empty()\n",
      "        )\n",
      "      )\n",
      "      (3): Conv1D(\n",
      "        (net): FusedConv1dBNReLU(\n",
      "          (activate): ReLU(inplace=True)\n",
      "          (op): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (bn): BatchNorm1d(32, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
      "          (calc_out_shift): OutputShiftSqueeze()\n",
      "          (calc_weight_scale): One()\n",
      "          (scale): Scaler()\n",
      "          (calc_out_scale): OutputScale()\n",
      "          (quantize_weight): Empty()\n",
      "          (quantize_bias): Empty()\n",
      "          (clamp_weight): Empty()\n",
      "          (clamp_bias): Empty()\n",
      "          (quantize): Empty()\n",
      "          (clamp): Clamp()\n",
      "          (quantize_pool): Empty()\n",
      "          (clamp_pool): Empty()\n",
      "        )\n",
      "      )\n",
      "      (4): Conv1D(\n",
      "        (net): FusedConv1dBNReLU(\n",
      "          (activate): ReLU(inplace=True)\n",
      "          (op): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (bn): BatchNorm1d(64, eps=1e-05, momentum=0.05, affine=False, track_running_stats=True)\n",
      "          (calc_out_shift): OutputShiftSqueeze()\n",
      "          (calc_weight_scale): One()\n",
      "          (scale): Scaler()\n",
      "          (calc_out_scale): OutputScale()\n",
      "          (quantize_weight): Empty()\n",
      "          (quantize_bias): Empty()\n",
      "          (clamp_weight): Empty()\n",
      "          (clamp_bias): Empty()\n",
      "          (quantize): Empty()\n",
      "          (clamp): Clamp()\n",
      "          (quantize_pool): Empty()\n",
      "          (clamp_pool): Empty()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_layer): MLPLayer(\n",
      "    (mlp_network): Sequential(\n",
      "      (0): FusedLinearReLU(\n",
      "        (activate): ReLU(inplace=True)\n",
      "        (op): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (calc_out_shift): OutputShiftSqueeze()\n",
      "        (calc_weight_scale): One()\n",
      "        (scale): Scaler()\n",
      "        (calc_out_scale): OutputScale()\n",
      "        (quantize_weight): Empty()\n",
      "        (quantize_bias): Empty()\n",
      "        (clamp_weight): Empty()\n",
      "        (clamp_bias): Empty()\n",
      "        (quantize): Empty()\n",
      "        (clamp): Clamp()\n",
      "        (quantize_pool): Empty()\n",
      "        (clamp_pool): Empty()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc_out_state): FusedLinearReLU(\n",
      "    (activate): ReLU(inplace=True)\n",
      "    (op): Linear(in_features=1024, out_features=10, bias=True)\n",
      "    (calc_out_shift): OutputShiftSqueeze()\n",
      "    (calc_weight_scale): One()\n",
      "    (scale): Scaler()\n",
      "    (calc_out_scale): OutputScale()\n",
      "    (quantize_weight): Empty()\n",
      "    (quantize_bias): Empty()\n",
      "    (clamp_weight): Empty()\n",
      "    (clamp_bias): Empty()\n",
      "    (quantize): Empty()\n",
      "    (clamp): Clamp()\n",
      "    (quantize_pool): Empty()\n",
      "    (clamp_pool): Empty()\n",
      "  )\n",
      "  (fc_out_power): FusedLinearReLU(\n",
      "    (activate): ReLU(inplace=True)\n",
      "    (op): Linear(in_features=1024, out_features=25, bias=True)\n",
      "    (calc_out_shift): OutputShiftSqueeze()\n",
      "    (calc_weight_scale): One()\n",
      "    (scale): Scaler()\n",
      "    (calc_out_scale): OutputScale()\n",
      "    (quantize_weight): Empty()\n",
      "    (quantize_bias): Empty()\n",
      "    (clamp_weight): Empty()\n",
      "    (clamp_bias): Empty()\n",
      "    (quantize): Empty()\n",
      "    (clamp): Clamp()\n",
      "    (quantize_pool): Empty()\n",
      "    (clamp_pool): Empty()\n",
      "  )\n",
      ")\n",
      "Number of Model Params: 1092871\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ai8x.set_device(device=85, simulate=False, round_avg=False)\n",
    "\n",
    "model = mod.AI85CNN1DNiLM(in_size=1, output_size=5, dropout=0.4, n_quantiles=len(quantiles), device=device)\n",
    "msglogger.info('model: %s',model)\n",
    "model = model.to(device)\n",
    "\n",
    "msglogger.info('Number of Model Params: %d',count_params(model))\n",
    "\n",
    "# configure tensorboard\n",
    "# dummy_input = torch.randn(1, seq_len)\n",
    "# tflogger.tblogger.writer.add_graph(model.to('cpu'), (dummy_input, ), False)\n",
    "\n",
    "all_loggers.append(tflogger)\n",
    "all_tbloggers = [tflogger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 10\n",
      "Optimizer Type: <class 'torch.optim.adam.Adam'>\n",
      "qat policy: {'start_epoch': 10, 'weight_bits': 8}\n"
     ]
    }
   ],
   "source": [
    "from unetnilm.utils import QuantileLoss\n",
    "\n",
    "num_epochs = 10\n",
    "msglogger.info('epochs: %d',num_epochs)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "msglogger.info('Optimizer Type: %s', type(optimizer))\n",
    "# ms_lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 35,100], gamma=0.5)\n",
    "# msglogger.info(\"lr_schedule:%s\",\"base: \"+str(ms_lr_scheduler.base_lrs)+\" milestones: \"+str(ms_lr_scheduler.milestones)+ \" gamma: \"+str(ms_lr_scheduler.gamma))\n",
    "ms_lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=patience_scheduler, verbose=True, min_lr=1e-6, mode=\"max\")\n",
    "# criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "criterion = QuantileLoss(quantiles=quantiles).to(device)\n",
    "\n",
    "qat_policy = {'start_epoch':10,\n",
    "              'weight_bits':8}\n",
    "msglogger.info('qat policy: %s',qat_policy)\n",
    "compression_scheduler = distiller.CompressionScheduler(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(data_loader, model, criterion, loggers, epoch=-1, tflogger=None):\n",
    "        \"\"\"Execute the validation/test loop.\"\"\"\n",
    "\n",
    "        # keep track of incorrect predictions\n",
    "        wrong_samples = None\n",
    "        wrong_preds = None\n",
    "        actual_preds = None\n",
    "        img_names = None\n",
    "\n",
    "        # store loss stats\n",
    "        losses = {'objective_loss': tnt.AverageValueMeter()}\n",
    "        classerr = tnt.ClassErrorMeter(accuracy=True, topk=(1, min(num_classes, 5)))\n",
    "\n",
    "        # validation set info\n",
    "        batch_time = tnt.AverageValueMeter()\n",
    "        total_samples = len(data_loader.sampler)\n",
    "        batch_size = data_loader.batch_size\n",
    "        confusion = tnt.ConfusionMeter(num_classes)\n",
    "        total_steps = (total_samples + batch_size - 1) // batch_size\n",
    "        msglogger.info('%d samples (%d per mini-batch)', total_samples, batch_size)\n",
    "\n",
    "        # Switch to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        end = time.time()\n",
    "        class_probs = []\n",
    "        class_preds = []\n",
    "\n",
    "        # iterate over the batches in the validation set\n",
    "        for validation_step, (inputs, target, states) in enumerate(data_loader):\n",
    "                with torch.no_grad():\n",
    "                        inputs, target, states = inputs.to(device), target.to(device), states.to(device)\n",
    "                        # compute output from model\n",
    "                        target, states = model(inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unetnilm.metrics import get_results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch_end(outputs):\n",
    "        \n",
    "        # appliance_data = {'fridge': {'window': 50, 'mean': 40.158577, 'std': 53.56288}, 'washer dryer': {'window': 50, 'mean': 27.768433, 'std': 212.51971}, 'kettle': {'window': 10, 'mean': 16.753872, 'std': 191.05873}, 'dish washer': {'window': 50, 'mean': 27.384077, 'std': 239.23492}, 'microwave': {'window': 10, 'mean': 8.35921, 'std': 105.1099}}\n",
    "        pred_power = torch.cat([x['pred_power'] for x in outputs], 0).cpu().numpy()\n",
    "        pred_state = torch.cat([x['pred_state'] for x in outputs], 0).cpu().numpy().astype(np.int32)\n",
    "        power = torch.cat([x['power'] for x in outputs], 0).cpu().numpy()\n",
    "        state = torch.cat([x['state'] for x in outputs], 0).cpu().numpy().astype(np.int32)\n",
    "\n",
    "        for idx, app in enumerate(appliances):\n",
    "                power[:,idx] = (power[:, idx] * appliance_data[app]['std']) + appliance_data[app]['std']\n",
    "                if len(quantiles)>=2:\n",
    "                        pred_power[:,:, idx] = (pred_power[:,:, idx] * appliance_data[app]['std']) + appliance_data[app]['std']\n",
    "                        pred_power[:,:, idx] = np.where(pred_power[:,:, idx]<0, 0, pred_power[:,:, idx])\n",
    "                else:\n",
    "                        pred_power[:, idx] = (pred_power[:, idx] * appliance_data[app]['std']) + appliance_data[app]['std']\n",
    "                        pred_power[:, idx] = np.where(pred_power[:, idx]<0, 0, pred_power[:, idx])    \n",
    "\n",
    "        if len(quantiles)>=2:\n",
    "                idx = len(quantiles)//2\n",
    "                y_pred = pred_power[:,idx]\n",
    "        else:\n",
    "                y_pred = pred_power \n",
    "                \n",
    "        per_app_results, avg_results = get_results_summary(state, pred_state, \n",
    "                                                                        power, y_pred,\n",
    "                                                                        appliances, \n",
    "                                                                        dataset_name.upper())  \n",
    "        logs = {\"pred_power\":pred_power, \n",
    "                \"pred_state\":pred_state, \n",
    "                \"power\":power, \n",
    "                \"state\":state,  \n",
    "                'app_results':per_app_results, \n",
    "                'avg_results':avg_results} \n",
    "        \n",
    "        return logs   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"caching_allocator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 582237 samples (8 per mini-batch)\n",
      "Epoch: [0][   10/72780]    tra_nlloss 0.602213    tra_mseloss 0.360167    tra_mae 0.724463    tra_F1 0.875000    objective_loss 1.003437    LR 0.000100    Time 1.581238    \n",
      "Epoch: [0][   20/72780]    tra_nlloss 0.484326    tra_mseloss 0.333767    tra_mae 0.672427    tra_F1 0.975000    objective_loss 0.947451    LR 0.000100    Time 0.802527    \n",
      "Epoch: [0][   30/72780]    tra_nlloss 0.515835    tra_mseloss 0.335530    tra_mae 0.680298    tra_F1 0.850000    objective_loss 0.902482    LR 0.000100    Time 0.542275    \n",
      "Epoch: [0][   40/72780]    tra_nlloss 0.423767    tra_mseloss 0.332968    tra_mae 0.671492    tra_F1 0.925000    objective_loss 0.874524    LR 0.000100    Time 0.412284    \n",
      "Epoch: [0][   50/72780]    tra_nlloss 0.362590    tra_mseloss 0.340875    tra_mae 0.688045    tra_F1 0.975000    objective_loss 0.846125    LR 0.000100    Time 0.334278    \n",
      "Epoch: [0][   60/72780]    tra_nlloss 0.381568    tra_mseloss 0.331337    tra_mae 0.665520    tra_F1 0.925000    objective_loss 0.824161    LR 0.000100    Time 0.282291    \n",
      "Epoch: [0][   70/72780]    tra_nlloss 0.392324    tra_mseloss 0.332370    tra_mae 0.666835    tra_F1 0.900000    objective_loss 0.806607    LR 0.000100    Time 0.245188    \n",
      "Epoch: [0][   80/72780]    tra_nlloss 0.468571    tra_mseloss 0.346009    tra_mae 0.697207    tra_F1 0.850000    objective_loss 0.795380    LR 0.000100    Time 0.217344    \n",
      "Epoch: [0][   90/72780]    tra_nlloss 0.444856    tra_mseloss 0.339227    tra_mae 0.683735    tra_F1 0.825000    objective_loss 0.786098    LR 0.000100    Time 0.195674    \n",
      "Epoch: [0][  100/72780]    tra_nlloss 0.406388    tra_mseloss 0.329265    tra_mae 0.658433    tra_F1 0.875000    objective_loss 0.779224    LR 0.000100    Time 0.178267    \n",
      "Epoch: [0][  110/72780]    tra_nlloss 0.355746    tra_mseloss 0.334016    tra_mae 0.664749    tra_F1 0.950000    objective_loss 0.771238    LR 0.000100    Time 0.164092    \n",
      "Epoch: [0][  120/72780]    tra_nlloss 0.400843    tra_mseloss 0.347203    tra_mae 0.693316    tra_F1 0.925000    objective_loss 0.766328    LR 0.000100    Time 0.152246    \n",
      "Epoch: [0][  130/72780]    tra_nlloss 0.391291    tra_mseloss 0.346293    tra_mae 0.688061    tra_F1 0.925000    objective_loss 0.762121    LR 0.000100    Time 0.142252    \n",
      "Epoch: [0][  140/72780]    tra_nlloss 0.361106    tra_mseloss 0.334759    tra_mae 0.665482    tra_F1 0.950000    objective_loss 0.756329    LR 0.000100    Time 0.133703    \n",
      "Epoch: [0][  150/72780]    tra_nlloss 0.497815    tra_mseloss 0.338561    tra_mae 0.672398    tra_F1 0.800000    objective_loss 0.753204    LR 0.000100    Time 0.126251    \n",
      "Epoch: [0][  160/72780]    tra_nlloss 0.338347    tra_mseloss 0.333896    tra_mae 0.661836    tra_F1 0.975000    objective_loss 0.749747    LR 0.000100    Time 0.119752    \n",
      "Epoch: [0][  170/72780]    tra_nlloss 0.353666    tra_mseloss 0.350706    tra_mae 0.697940    tra_F1 0.975000    objective_loss 0.747365    LR 0.000100    Time 0.114025    \n",
      "Epoch: [0][  180/72780]    tra_nlloss 0.377708    tra_mseloss 0.332022    tra_mae 0.658121    tra_F1 0.925000    objective_loss 0.744690    LR 0.000100    Time 0.108922    \n",
      "Epoch: [0][  190/72780]    tra_nlloss 0.366442    tra_mseloss 0.332937    tra_mae 0.659934    tra_F1 0.950000    objective_loss 0.741445    LR 0.000100    Time 0.104389    \n",
      "Epoch: [0][  200/72780]    tra_nlloss 0.340485    tra_mseloss 0.340901    tra_mae 0.676345    tra_F1 0.975000    objective_loss 0.739132    LR 0.000100    Time 0.100297    \n",
      "Epoch: [0][  210/72780]    tra_nlloss 0.371003    tra_mseloss 0.332878    tra_mae 0.659818    tra_F1 0.950000    objective_loss 0.736743    LR 0.000100    Time 0.096577    \n",
      "Epoch: [0][  220/72780]    tra_nlloss 0.374423    tra_mseloss 0.361628    tra_mae 0.718345    tra_F1 0.925000    objective_loss 0.734734    LR 0.000100    Time 0.093195    \n",
      "Epoch: [0][  230/72780]    tra_nlloss 0.364041    tra_mseloss 0.323099    tra_mae 0.640434    tra_F1 0.950000    objective_loss 0.733207    LR 0.000100    Time 0.090111    \n",
      "Epoch: [0][  240/72780]    tra_nlloss 0.316112    tra_mseloss 0.330946    tra_mae 0.655987    tra_F1 1.000000    objective_loss 0.730458    LR 0.000100    Time 0.087319    \n",
      "Epoch: [0][  250/72780]    tra_nlloss 0.315369    tra_mseloss 0.331279    tra_mae 0.656648    tra_F1 1.000000    objective_loss 0.727940    LR 0.000100    Time 0.084717    \n",
      "Epoch: [0][  260/72780]    tra_nlloss 0.315369    tra_mseloss 0.331261    tra_mae 0.656612    tra_F1 1.000000    objective_loss 0.726474    LR 0.000100    Time 0.082312    \n",
      "Epoch: [0][  270/72780]    tra_nlloss 0.456043    tra_mseloss 0.365803    tra_mae 0.726880    tra_F1 0.850000    objective_loss 0.725714    LR 0.000100    Time 0.080083    \n",
      "Epoch: [0][  280/72780]    tra_nlloss 0.349618    tra_mseloss 0.326869    tra_mae 0.647907    tra_F1 0.950000    objective_loss 0.724373    LR 0.000100    Time 0.078033    \n",
      "Epoch: [0][  290/72780]    tra_nlloss 0.342919    tra_mseloss 0.351329    tra_mae 0.697273    tra_F1 0.975000    objective_loss 0.723065    LR 0.000100    Time 0.076158    \n",
      "Epoch: [0][  300/72780]    tra_nlloss 0.330692    tra_mseloss 0.330982    tra_mae 0.656059    tra_F1 0.975000    objective_loss 0.721900    LR 0.000100    Time 0.074365    \n",
      "Epoch: [0][  310/72780]    tra_nlloss 0.391467    tra_mseloss 0.328135    tra_mae 0.650416    tra_F1 0.925000    objective_loss 0.720878    LR 0.000100    Time 0.072685    \n",
      "Epoch: [0][  320/72780]    tra_nlloss 0.315369    tra_mseloss 0.331247    tra_mae 0.656586    tra_F1 1.000000    objective_loss 0.720158    LR 0.000100    Time 0.071103    \n",
      "Epoch: [0][  330/72780]    tra_nlloss 0.340173    tra_mseloss 0.334130    tra_mae 0.662300    tra_F1 0.975000    objective_loss 0.719574    LR 0.000100    Time 0.069654    \n",
      "Epoch: [0][  340/72780]    tra_nlloss 0.457710    tra_mseloss 0.340593    tra_mae 0.676130    tra_F1 0.850000    objective_loss 0.718914    LR 0.000100    Time 0.068262    \n",
      "Epoch: [0][  350/72780]    tra_nlloss 0.349618    tra_mseloss 0.328806    tra_mae 0.651746    tra_F1 0.950000    objective_loss 0.717976    LR 0.000100    Time 0.066967    \n",
      "Epoch: [0][  360/72780]    tra_nlloss 0.315369    tra_mseloss 0.328392    tra_mae 0.650925    tra_F1 1.000000    objective_loss 0.717497    LR 0.000100    Time 0.065742    \n",
      "Epoch: [0][  370/72780]    tra_nlloss 0.365341    tra_mseloss 0.325471    tra_mae 0.645193    tra_F1 0.950000    objective_loss 0.716893    LR 0.000100    Time 0.064603    \n",
      "Epoch: [0][  380/72780]    tra_nlloss 0.411870    tra_mseloss 0.344342    tra_mae 0.683621    tra_F1 0.900000    objective_loss 0.716910    LR 0.000100    Time 0.063504    \n",
      "Epoch: [0][  390/72780]    tra_nlloss 0.317318    tra_mseloss 0.326837    tra_mae 0.647898    tra_F1 1.000000    objective_loss 0.715769    LR 0.000100    Time 0.062441    \n",
      "Epoch: [0][  400/72780]    tra_nlloss 0.364978    tra_mseloss 0.357197    tra_mae 0.709014    tra_F1 0.950000    objective_loss 0.715772    LR 0.000100    Time 0.061471    \n",
      "Epoch: [0][  410/72780]    tra_nlloss 0.366408    tra_mseloss 0.348618    tra_mae 0.691761    tra_F1 0.950000    objective_loss 0.715146    LR 0.000100    Time 0.060546    \n",
      "Epoch: [0][  420/72780]    tra_nlloss 0.339544    tra_mseloss 0.331369    tra_mae 0.656827    tra_F1 0.975000    objective_loss 0.714427    LR 0.000100    Time 0.059636    \n",
      "Epoch: [0][  430/72780]    tra_nlloss 0.340853    tra_mseloss 0.336842    tra_mae 0.667675    tra_F1 0.975000    objective_loss 0.713988    LR 0.000100    Time 0.058779    \n",
      "Epoch: [0][  440/72780]    tra_nlloss 0.340977    tra_mseloss 0.333189    tra_mae 0.660434    tra_F1 0.975000    objective_loss 0.712971    LR 0.000100    Time 0.057960    \n",
      "Epoch: [0][  450/72780]    tra_nlloss 0.315369    tra_mseloss 0.334022    tra_mae 0.662086    tra_F1 1.000000    objective_loss 0.712478    LR 0.000100    Time 0.057174    \n",
      "Epoch: [0][  460/72780]    tra_nlloss 0.364978    tra_mseloss 0.336189    tra_mae 0.666380    tra_F1 0.950000    objective_loss 0.712032    LR 0.000100    Time 0.056418    \n",
      "Epoch: [0][  470/72780]    tra_nlloss 0.340173    tra_mseloss 0.346302    tra_mae 0.687184    tra_F1 0.975000    objective_loss 0.711623    LR 0.000100    Time 0.055702    \n",
      "Epoch: [0][  480/72780]    tra_nlloss 0.373902    tra_mseloss 0.332450    tra_mae 0.658970    tra_F1 0.925000    objective_loss 0.710993    LR 0.000100    Time 0.055017    \n",
      "Epoch: [0][  490/72780]    tra_nlloss 0.315369    tra_mseloss 0.330329    tra_mae 0.654764    tra_F1 1.000000    objective_loss 0.710528    LR 0.000100    Time 0.054355    \n",
      "Epoch: [0][  500/72780]    tra_nlloss 0.395712    tra_mseloss 0.329468    tra_mae 0.653059    tra_F1 0.900000    objective_loss 0.710387    LR 0.000100    Time 0.053711    \n",
      "Epoch: [0][  510/72780]    tra_nlloss 0.315369    tra_mseloss 0.331000    tra_mae 0.656095    tra_F1 1.000000    objective_loss 0.709832    LR 0.000100    Time 0.053112    \n",
      "Epoch: [0][  520/72780]    tra_nlloss 0.315862    tra_mseloss 0.328396    tra_mae 0.650934    tra_F1 1.000000    objective_loss 0.709133    LR 0.000100    Time 0.052529    \n",
      "Epoch: [0][  530/72780]    tra_nlloss 0.315369    tra_mseloss 0.333991    tra_mae 0.662023    tra_F1 1.000000    objective_loss 0.708536    LR 0.000100    Time 0.051991    \n",
      "Epoch: [0][  540/72780]    tra_nlloss 0.436367    tra_mseloss 0.337327    tra_mae 0.669153    tra_F1 0.875000    objective_loss 0.708277    LR 0.000100    Time 0.051446    \n",
      "Epoch: [0][  550/72780]    tra_nlloss 0.346904    tra_mseloss 0.353172    tra_mae 0.701086    tra_F1 0.975000    objective_loss 0.707959    LR 0.000100    Time 0.050924    \n",
      "Epoch: [0][  560/72780]    tra_nlloss 0.358415    tra_mseloss 0.328459    tra_mae 0.651059    tra_F1 0.950000    objective_loss 0.707491    LR 0.000100    Time 0.050411    \n",
      "Epoch: [0][  570/72780]    tra_nlloss 0.366251    tra_mseloss 0.336356    tra_mae 0.667278    tra_F1 0.950000    objective_loss 0.706794    LR 0.000100    Time 0.049910    \n",
      "Epoch: [0][  580/72780]    tra_nlloss 0.349433    tra_mseloss 0.330991    tra_mae 0.656077    tra_F1 0.975000    objective_loss 0.706754    LR 0.000100    Time 0.049442    \n",
      "Epoch: [0][  590/72780]    tra_nlloss 0.316662    tra_mseloss 0.331764    tra_mae 0.657657    tra_F1 1.000000    objective_loss 0.706541    LR 0.000100    Time 0.048989    \n",
      "Epoch: [0][  600/72780]    tra_nlloss 0.348169    tra_mseloss 0.337522    tra_mae 0.669023    tra_F1 0.975000    objective_loss 0.706089    LR 0.000100    Time 0.048536    \n",
      "Epoch: [0][  610/72780]    tra_nlloss 0.317031    tra_mseloss 0.334243    tra_mae 0.662523    tra_F1 1.000000    objective_loss 0.705725    LR 0.000100    Time 0.048094    \n",
      "Epoch: [0][  620/72780]    tra_nlloss 0.315369    tra_mseloss 0.331392    tra_mae 0.656871    tra_F1 1.000000    objective_loss 0.705369    LR 0.000100    Time 0.047681    \n",
      "Epoch: [0][  630/72780]    tra_nlloss 0.389783    tra_mseloss 0.331022    tra_mae 0.656139    tra_F1 0.925000    objective_loss 0.705279    LR 0.000100    Time 0.047281    \n",
      "Epoch: [0][  640/72780]    tra_nlloss 0.340173    tra_mseloss 0.331135    tra_mae 0.656362    tra_F1 0.975000    objective_loss 0.704841    LR 0.000100    Time 0.046903    \n",
      "Epoch: [0][  650/72780]    tra_nlloss 0.318225    tra_mseloss 0.339558    tra_mae 0.673059    tra_F1 1.000000    objective_loss 0.704337    LR 0.000100    Time 0.046517    \n",
      "Epoch: [0][  660/72780]    tra_nlloss 0.371204    tra_mseloss 0.364726    tra_mae 0.724534    tra_F1 0.950000    objective_loss 0.704149    LR 0.000100    Time 0.046174    \n",
      "Epoch: [0][  670/72780]    tra_nlloss 0.315369    tra_mseloss 0.334243    tra_mae 0.662523    tra_F1 1.000000    objective_loss 0.703903    LR 0.000100    Time 0.045819    \n",
      "Epoch: [0][  680/72780]    tra_nlloss 0.340173    tra_mseloss 0.347830    tra_mae 0.690407    tra_F1 0.975000    objective_loss 0.703591    LR 0.000100    Time 0.045475    \n",
      "Epoch: [0][  690/72780]    tra_nlloss 0.315369    tra_mseloss 0.334351    tra_mae 0.662737    tra_F1 1.000000    objective_loss 0.703091    LR 0.000100    Time 0.045129    \n",
      "Epoch: [0][  700/72780]    tra_nlloss 0.349618    tra_mseloss 0.330166    tra_mae 0.654443    tra_F1 0.975000    objective_loss 0.702974    LR 0.000100    Time 0.044801    \n",
      "Epoch: [0][  710/72780]    tra_nlloss 0.412082    tra_mseloss 0.332973    tra_mae 0.660005    tra_F1 0.900000    objective_loss 0.702852    LR 0.000100    Time 0.044481    \n",
      "Epoch: [0][  720/72780]    tra_nlloss 0.364978    tra_mseloss 0.326818    tra_mae 0.647862    tra_F1 0.950000    objective_loss 0.702695    LR 0.000100    Time 0.044188    \n",
      "Epoch: [0][  730/72780]    tra_nlloss 0.445043    tra_mseloss 0.370848    tra_mae 0.737407    tra_F1 0.875000    objective_loss 0.702464    LR 0.000100    Time 0.043899    \n",
      "Epoch: [0][  740/72780]    tra_nlloss 0.344223    tra_mseloss 0.331504    tra_mae 0.657095    tra_F1 0.975000    objective_loss 0.701978    LR 0.000100    Time 0.043607    \n",
      "Epoch: [0][  750/72780]    tra_nlloss 0.395972    tra_mseloss 0.330937    tra_mae 0.655970    tra_F1 0.900000    objective_loss 0.701941    LR 0.000100    Time 0.043325    \n",
      "Epoch: [0][  760/72780]    tra_nlloss 0.315369    tra_mseloss 0.328504    tra_mae 0.651148    tra_F1 1.000000    objective_loss 0.701628    LR 0.000100    Time 0.043046    \n",
      "Epoch: [0][  770/72780]    tra_nlloss 0.340173    tra_mseloss 0.329405    tra_mae 0.652934    tra_F1 0.975000    objective_loss 0.701462    LR 0.000100    Time 0.042775    \n",
      "Epoch: [0][  780/72780]    tra_nlloss 0.368015    tra_mseloss 0.323279    tra_mae 0.640791    tra_F1 0.950000    objective_loss 0.701354    LR 0.000100    Time 0.042514    \n",
      "Epoch: [0][  790/72780]    tra_nlloss 0.406824    tra_mseloss 0.341542    tra_mae 0.677750    tra_F1 0.900000    objective_loss 0.701296    LR 0.000100    Time 0.042274    \n",
      "Epoch: [0][  800/72780]    tra_nlloss 0.399523    tra_mseloss 0.329861    tra_mae 0.653889    tra_F1 0.900000    objective_loss 0.701200    LR 0.000100    Time 0.042023    \n",
      "Epoch: [0][  810/72780]    tra_nlloss 0.349847    tra_mseloss 0.333130    tra_mae 0.660318    tra_F1 0.950000    objective_loss 0.700972    LR 0.000100    Time 0.041784    \n",
      "Epoch: [0][  820/72780]    tra_nlloss 0.334258    tra_mseloss 0.339387    tra_mae 0.672720    tra_F1 0.975000    objective_loss 0.700979    LR 0.000100    Time 0.041542    \n",
      "Epoch: [0][  830/72780]    tra_nlloss 0.315369    tra_mseloss 0.335734    tra_mae 0.665479    tra_F1 1.000000    objective_loss 0.700815    LR 0.000100    Time 0.041322    \n",
      "Epoch: [0][  840/72780]    tra_nlloss 0.323352    tra_mseloss 0.337166    tra_mae 0.668318    tra_F1 1.000000    objective_loss 0.700510    LR 0.000100    Time 0.041100    \n",
      "Epoch: [0][  850/72780]    tra_nlloss 0.340173    tra_mseloss 0.328662    tra_mae 0.651461    tra_F1 0.975000    objective_loss 0.700236    LR 0.000100    Time 0.040876    \n",
      "Epoch: [0][  860/72780]    tra_nlloss 0.315369    tra_mseloss 0.333928    tra_mae 0.661898    tra_F1 1.000000    objective_loss 0.699957    LR 0.000100    Time 0.040663    \n",
      "Epoch: [0][  870/72780]    tra_nlloss 0.374423    tra_mseloss 0.337419    tra_mae 0.669354    tra_F1 0.950000    objective_loss 0.699626    LR 0.000100    Time 0.040454    \n",
      "Epoch: [0][  880/72780]    tra_nlloss 0.364978    tra_mseloss 0.345171    tra_mae 0.684936    tra_F1 0.950000    objective_loss 0.699367    LR 0.000100    Time 0.040258    \n",
      "Epoch: [0][  890/72780]    tra_nlloss 0.316056    tra_mseloss 0.331311    tra_mae 0.656711    tra_F1 1.000000    objective_loss 0.699000    LR 0.000100    Time 0.040061    \n",
      "Epoch: [0][  900/72780]    tra_nlloss 0.364978    tra_mseloss 0.345404    tra_mae 0.685505    tra_F1 0.950000    objective_loss 0.698874    LR 0.000100    Time 0.039874    \n",
      "Epoch: [0][  910/72780]    tra_nlloss 0.315369    tra_mseloss 0.339540    tra_mae 0.673023    tra_F1 1.000000    objective_loss 0.698847    LR 0.000100    Time 0.039688    \n",
      "Epoch: [0][  920/72780]    tra_nlloss 0.400912    tra_mseloss 0.345801    tra_mae 0.686187    tra_F1 0.900000    objective_loss 0.698746    LR 0.000100    Time 0.039503    \n",
      "Epoch: [0][  930/72780]    tra_nlloss 0.362466    tra_mseloss 0.339685    tra_mae 0.673894    tra_F1 0.950000    objective_loss 0.698597    LR 0.000100    Time 0.039311    \n",
      "Epoch: [0][  940/72780]    tra_nlloss 0.367847    tra_mseloss 0.338091    tra_mae 0.670711    tra_F1 0.950000    objective_loss 0.698335    LR 0.000100    Time 0.039137    \n",
      "Epoch: [0][  950/72780]    tra_nlloss 0.487682    tra_mseloss 0.345001    tra_mae 0.685389    tra_F1 0.800000    objective_loss 0.698306    LR 0.000100    Time 0.038961    \n",
      "Epoch: [0][  960/72780]    tra_nlloss 0.389783    tra_mseloss 0.323084    tra_mae 0.640452    tra_F1 0.925000    objective_loss 0.698317    LR 0.000100    Time 0.038796    \n",
      "Epoch: [0][  970/72780]    tra_nlloss 0.315369    tra_mseloss 0.334009    tra_mae 0.662059    tra_F1 1.000000    objective_loss 0.698013    LR 0.000100    Time 0.038631    \n",
      "Epoch: [0][  980/72780]    tra_nlloss 0.397564    tra_mseloss 0.332423    tra_mae 0.658916    tra_F1 0.900000    objective_loss 0.697791    LR 0.000100    Time 0.038472    \n",
      "Epoch: [0][  990/72780]    tra_nlloss 0.315369    tra_mseloss 0.334166    tra_mae 0.662371    tra_F1 1.000000    objective_loss 0.697661    LR 0.000100    Time 0.038311    \n",
      "Epoch: [0][ 1000/72780]    tra_nlloss 0.315697    tra_mseloss 0.325630    tra_mae 0.645452    tra_F1 1.000000    objective_loss 0.697523    LR 0.000100    Time 0.038158    \n",
      "Epoch: [0][ 1010/72780]    tra_nlloss 0.315369    tra_mseloss 0.331468    tra_mae 0.657023    tra_F1 1.000000    objective_loss 0.697458    LR 0.000100    Time 0.038008    \n",
      "Epoch: [0][ 1020/72780]    tra_nlloss 0.340173    tra_mseloss 0.323842    tra_mae 0.641907    tra_F1 0.975000    objective_loss 0.697468    LR 0.000100    Time 0.037851    \n",
      "Epoch: [0][ 1030/72780]    tra_nlloss 0.368605    tra_mseloss 0.347247    tra_mae 0.689050    tra_F1 0.950000    objective_loss 0.697494    LR 0.000100    Time 0.037698    \n",
      "Epoch: [0][ 1040/72780]    tra_nlloss 0.393884    tra_mseloss 0.351184    tra_mae 0.697472    tra_F1 0.925000    objective_loss 0.697480    LR 0.000100    Time 0.037551    \n",
      "Epoch: [0][ 1050/72780]    tra_nlloss 0.366784    tra_mseloss 0.347287    tra_mae 0.689105    tra_F1 0.950000    objective_loss 0.697344    LR 0.000100    Time 0.037411    \n",
      "Epoch: [0][ 1060/72780]    tra_nlloss 0.315369    tra_mseloss 0.331293    tra_mae 0.656675    tra_F1 1.000000    objective_loss 0.697122    LR 0.000100    Time 0.037287    \n",
      "Epoch: [0][ 1070/72780]    tra_nlloss 0.399227    tra_mseloss 0.350608    tra_mae 0.695970    tra_F1 0.900000    objective_loss 0.697046    LR 0.000100    Time 0.037148    \n",
      "Epoch: [0][ 1080/72780]    tra_nlloss 0.340173    tra_mseloss 0.330793    tra_mae 0.655684    tra_F1 0.975000    objective_loss 0.697324    LR 0.000100    Time 0.037009    \n",
      "Epoch: [0][ 1090/72780]    tra_nlloss 0.323296    tra_mseloss 0.336585    tra_mae 0.667166    tra_F1 1.000000    objective_loss 0.697188    LR 0.000100    Time 0.036873    \n",
      "Epoch: [0][ 1100/72780]    tra_nlloss 0.315369    tra_mseloss 0.331531    tra_mae 0.657148    tra_F1 1.000000    objective_loss 0.697138    LR 0.000100    Time 0.036739    \n",
      "Epoch: [0][ 1110/72780]    tra_nlloss 0.402653    tra_mseloss 0.356784    tra_mae 0.708707    tra_F1 0.925000    objective_loss 0.697357    LR 0.000100    Time 0.036612    \n",
      "Epoch: [0][ 1120/72780]    tra_nlloss 0.343945    tra_mseloss 0.336423    tra_mae 0.667586    tra_F1 0.975000    objective_loss 0.697189    LR 0.000100    Time 0.036484    \n",
      "Epoch: [0][ 1130/72780]    tra_nlloss 0.326322    tra_mseloss 0.328549    tra_mae 0.651237    tra_F1 1.000000    objective_loss 0.697278    LR 0.000100    Time 0.036359    \n",
      "Epoch: [0][ 1140/72780]    tra_nlloss 0.315369    tra_mseloss 0.331058    tra_mae 0.656211    tra_F1 1.000000    objective_loss 0.697075    LR 0.000100    Time 0.036246    \n",
      "Epoch: [0][ 1150/72780]    tra_nlloss 0.315369    tra_mseloss 0.339621    tra_mae 0.673184    tra_F1 1.000000    objective_loss 0.696955    LR 0.000100    Time 0.036152    \n",
      "Epoch: [0][ 1160/72780]    tra_nlloss 0.395090    tra_mseloss 0.327549    tra_mae 0.649255    tra_F1 0.925000    objective_loss 0.696794    LR 0.000100    Time 0.036057    \n",
      "Epoch: [0][ 1170/72780]    tra_nlloss 0.350914    tra_mseloss 0.330306    tra_mae 0.654720    tra_F1 0.975000    objective_loss 0.696576    LR 0.000100    Time 0.035967    \n",
      "Epoch: [0][ 1180/72780]    tra_nlloss 0.315369    tra_mseloss 0.328761    tra_mae 0.651657    tra_F1 1.000000    objective_loss 0.696556    LR 0.000100    Time 0.035875    \n",
      "Epoch: [0][ 1190/72780]    tra_nlloss 0.403124    tra_mseloss 0.329540    tra_mae 0.653202    tra_F1 0.900000    objective_loss 0.696510    LR 0.000100    Time 0.035788    \n",
      "Epoch: [0][ 1200/72780]    tra_nlloss 0.315369    tra_mseloss 0.336801    tra_mae 0.667595    tra_F1 1.000000    objective_loss 0.696321    LR 0.000100    Time 0.035700    \n",
      "Epoch: [0][ 1210/72780]    tra_nlloss 0.392171    tra_mseloss 0.333225    tra_mae 0.660505    tra_F1 0.925000    objective_loss 0.696251    LR 0.000100    Time 0.035619    \n",
      "Epoch: [0][ 1220/72780]    tra_nlloss 0.342164    tra_mseloss 0.345075    tra_mae 0.684709    tra_F1 0.975000    objective_loss 0.696025    LR 0.000100    Time 0.035546    \n",
      "Epoch: [0][ 1230/72780]    tra_nlloss 0.456064    tra_mseloss 0.348760    tra_mae 0.692130    tra_F1 0.850000    objective_loss 0.696066    LR 0.000100    Time 0.035467    \n",
      "Epoch: [0][ 1240/72780]    tra_nlloss 0.382566    tra_mseloss 0.350290    tra_mae 0.695273    tra_F1 0.925000    objective_loss 0.696045    LR 0.000100    Time 0.035389    \n",
      "Epoch: [0][ 1250/72780]    tra_nlloss 0.389783    tra_mseloss 0.332739    tra_mae 0.659715    tra_F1 0.925000    objective_loss 0.696094    LR 0.000100    Time 0.035309    \n",
      "Epoch: [0][ 1260/72780]    tra_nlloss 0.315369    tra_mseloss 0.336810    tra_mae 0.667612    tra_F1 1.000000    objective_loss 0.696139    LR 0.000100    Time 0.035237    \n",
      "Epoch: [0][ 1270/72780]    tra_nlloss 0.364662    tra_mseloss 0.331950    tra_mae 0.657978    tra_F1 0.950000    objective_loss 0.696213    LR 0.000100    Time 0.035161    \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 8.00 GiB total capacity; 7.31 GiB already allocated; 0 bytes free; 7.32 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m B \u001b[39m=\u001b[39m inputs_\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[39m# forward pass and loss calculation\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m logits, rmse_logits \u001b[39m=\u001b[39m model(inputs_)\n\u001b[0;32m     63\u001b[0m prob, pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(F\u001b[39m.\u001b[39msoftmax(logits, \u001b[39m1\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[0;32m     64\u001b[0m loss_nll   \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mnll_loss(F\u001b[39m.\u001b[39mlog_softmax(logits, \u001b[39m1\u001b[39m), states)\n",
      "File \u001b[1;32mc:\\Users\\MTinaco\\Dev\\ai8x-training\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\Users\\MTinaco\\Dev\\ai8x-training\\models\\ai87net-unetnilm.py:136\u001b[0m, in \u001b[0;36mAI85CNN1DNiLM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    134\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[0;32m    135\u001b[0m B \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[1;32m--> 136\u001b[0m conv_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menc_net(x))\n\u001b[0;32m    137\u001b[0m conv_out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39madaptive_avg_pool1d(conv_out, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool_filter)\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    138\u001b[0m mlp_out  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_layer(conv_out))\n",
      "File \u001b[1;32mc:\\Users\\MTinaco\\Dev\\ai8x-training\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\Users\\MTinaco\\Dev\\ai8x-training\\models\\ai87net-unetnilm.py:225\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    224\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39msize())\u001b[39m==\u001b[39m\u001b[39m3\u001b[39m\n\u001b[1;32m--> 225\u001b[0m     feats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_stack(x)\n\u001b[0;32m    226\u001b[0m     \u001b[39mreturn\u001b[39;00m feats\n",
      "File \u001b[1;32mc:\\Users\\MTinaco\\Dev\\ai8x-training\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\Users\\MTinaco\\Dev\\ai8x-training\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:119\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    118\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 119\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\MTinaco\\Dev\\ai8x-training\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\Users\\MTinaco\\Dev\\ai8x-training\\models\\ai87net-unetnilm.py:204\u001b[0m, in \u001b[0;36mConv1D.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m--> 204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet(x)\n",
      "File \u001b[1;32mc:\\Users\\MTinaco\\Dev\\ai8x-training\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\Users\\MTinaco\\Dev\\ai8x-training\\ai8x.py:642\u001b[0m, in \u001b[0;36mQuantizationAwareModule.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    639\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwide:\n\u001b[0;32m    640\u001b[0m         \u001b[39m# The device does not apply output shift in wide mode\u001b[39;00m\n\u001b[0;32m    641\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale(x, out_scale)\n\u001b[1;32m--> 642\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclamp(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquantize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivate(x)))\n\u001b[0;32m    643\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\MTinaco\\Dev\\ai8x-training\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\Users\\MTinaco\\Dev\\ai8x-training\\ai8x.py:254\u001b[0m, in \u001b[0;36mClamp.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Forward prop\"\"\"\u001b[39;00m\n\u001b[0;32m    253\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mclamp(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_val)\n\u001b[1;32m--> 254\u001b[0m \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39;49mclamp(\u001b[39mmax\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_val)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 8.00 GiB total capacity; 7.31 GiB already allocated; 0 bytes free; 7.32 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# store model history across epochs\n",
    "perf_scores_history = []\n",
    "model = model.to(device)\n",
    "\n",
    "name = model_name\n",
    "\n",
    "# start the clock\n",
    "tic = datetime.datetime.now()\n",
    "\n",
    "break_point = 10\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "        if epoch > break_point:\n",
    "                break\n",
    "\n",
    "        if epoch > 0 and epoch == qat_policy['start_epoch']:\n",
    "                print('QAT is starting!')\n",
    "                # Fuse the BN parameters into conv layers before Quantization \n",
    "                ai8x.fuse_bn_layers(model)\n",
    "        \n",
    "                # Switch model from unquantized to quantized for QAT\n",
    "                ai8x.initiate_qat(model, qat_policy)\n",
    "\n",
    "                # Model is re-transferred to GPU in case parameters were added\n",
    "                model.to(device)\n",
    "\n",
    "                # Empty the performance scores list for QAT operation\n",
    "                perf_scores_history = []\n",
    "                name = f'{model_name}_qat'\n",
    "        \n",
    "        # store loss and training stats\n",
    "        losses = {'objective_loss': tnt.AverageValueMeter()}\n",
    "        classerr = tnt.ClassErrorMeter(accuracy=True, topk=(1, min(num_classes, 5)))\n",
    "        batch_time = tnt.AverageValueMeter()\n",
    "        data_time = tnt.AverageValueMeter()\n",
    "\n",
    "        # logging stats\n",
    "        total_samples = len(train_loader.sampler)\n",
    "        batch_size = train_loader.batch_size\n",
    "        steps_per_epoch = (total_samples + batch_size - 1) // batch_size\n",
    "        msglogger.info('Training epoch: %d samples (%d per mini-batch)', total_samples, batch_size)\n",
    "\n",
    "        # Switch to train mode\n",
    "        model.train()\n",
    "        acc_stats = []\n",
    "        end = time.time()\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        # iterate over all batches in the dataset    \n",
    "        for train_step, (inputs, target, states) in enumerate(train_loader):\n",
    "\n",
    "                # Measure data loading time\n",
    "                data_time.add(time.time() - end)\n",
    "                inputs_, target, states = inputs.to(device), target.to(device), states.to(device)\n",
    "\n",
    "                B = inputs_.size(0)\n",
    "\n",
    "                # forward pass and loss calculation\n",
    "                logits, rmse_logits = model(inputs_)\n",
    "                prob, pred = torch.max(F.softmax(logits, 1), 1)\n",
    "                loss_nll   = F.nll_loss(F.log_softmax(logits, 1), states)\n",
    "                if len(quantiles)>1:\n",
    "                        prob=prob.unsqueeze(1).expand_as(rmse_logits)\n",
    "                        loss_mse = criterion(rmse_logits, target)\n",
    "                        mae_score = F.l1_loss(rmse_logits,target.unsqueeze(1).expand_as(rmse_logits))\n",
    "                else:    \n",
    "                        loss_mse = F.mse_loss(rmse_logits, target)\n",
    "                        mae_score = F.l1_loss(rmse_logits, target)\n",
    "\n",
    "                # UNETNILM\n",
    "                loss = loss_nll + loss_mse\n",
    "                res = f1_score(pred, states, task=\"multiclass\", num_classes=5)\n",
    "                logs = {\"nlloss\":loss_nll, \"mseloss\":loss_mse,\n",
    "                        \"mae\":mae_score, \"F1\": res}\n",
    "                \n",
    "                train_logs = {}\n",
    "                for key, value in logs.items():\n",
    "                        train_logs[f'tra_{key}']=value.item()\n",
    "\n",
    "                # # on the last batch store the stats for the epoch\n",
    "                # if train_step >= len(train_loader)-2:\n",
    "                #         if len(target.data.shape) <= 2:\n",
    "                #                 classerr.add(target.data, target)\n",
    "                #         else:\n",
    "                #                 classerr.add(target.data.permute(0, 2, 3, 1).flatten(start_dim=0, end_dim=2),\n",
    "                #                                 target.flatten())\n",
    "                #         acc_stats.append([classerr.value(1), classerr.value(min(num_classes, 5))])\n",
    "\n",
    "                # add the loss for each batch\n",
    "                losses[\"objective_loss\"].add(loss.item())\n",
    "\n",
    "                # reset the optimizer\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # backwards pass and parameter update\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "                # track batch stats\n",
    "                batch_time.add(time.time() - end)\n",
    "                steps_completed = (train_step+1)\n",
    "\n",
    "                # log stats every 10 batches\n",
    "                if steps_completed % print_freq == 0 or steps_completed == steps_per_epoch:\n",
    "                # Log some statistics\n",
    "                        errs = OrderedDict()\n",
    "                        stats_dict = OrderedDict()\n",
    "                        stats_dict.update(train_logs)\n",
    "\n",
    "                        for loss_name, meter in losses.items():\n",
    "                                stats_dict[loss_name] = meter.mean\n",
    "                        stats_dict.update(errs)\n",
    "\n",
    "                        stats_dict['LR'] = optimizer.param_groups[0]['lr']\n",
    "                        stats_dict['Time'] = batch_time.mean\n",
    "                        stats = ('Performance/Training/', stats_dict)\n",
    "                        params = None\n",
    "                        distiller.log_training_progress(stats,\n",
    "                                                        params,\n",
    "                                                        epoch, steps_completed,\n",
    "                                                        steps_per_epoch, print_freq,\n",
    "                                                        all_loggers)\n",
    "                end = time.time()\n",
    "\n",
    "                # Test\n",
    "                logits, pred_power  = model(inputs_)\n",
    "\n",
    "                prob, pred_state = torch.max(F.softmax(logits, 1), 1)\n",
    "                if len(quantiles)>1:\n",
    "                        prob=prob.unsqueeze(1).expand_as(pred_power)\n",
    "                \n",
    "                logs = {\"pred_power\":pred_power, \"pred_state\":pred_state, \"power\":target, \"state\":states}\n",
    "\n",
    "                outputs.append(logs)\n",
    "\n",
    "                del logits\n",
    "                del rmse_logits \n",
    "                del logs\n",
    "                del pred_power\n",
    "                del prob\n",
    "                del pred_state\n",
    "                del inputs_\n",
    "\n",
    "outputs = test_epoch_end(outputs)\n",
    "print(outputs)\n",
    "\n",
    "# after a training epoch, do validation\n",
    "msglogger.info('--- validate (epoch=%d)-----------', epoch)\n",
    "\n",
    "# vloss = validate(val_loader, model, criterion, [pylogger], epoch, tflogger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
