{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#\n",
    "# Copyright (C) 2022 Maxim Integrated Products, Inc. All Rights Reserved.\n",
    "#\n",
    "# Maxim Integrated Products, Inc. Default Copyright Notice:\n",
    "# https://www.maximintegrated.com/en/aboutus/legal/copyrights.html\n",
    "#\n",
    "###################################################################################################\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(os.path.join(os.getcwd(), '../models/'))\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import ai8x\n",
    "from datasets import helen\n",
    "from utils import parse_obj_detection_yaml\n",
    "\n",
    "ai85net_tinierssd = __import__(\"ai85net-tinierssd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset length: 1083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_path = '../data/'\n",
    "\n",
    "class Args:\n",
    "    def __init__(self, act_mode_8bit):\n",
    "        self.act_mode_8bit = act_mode_8bit\n",
    "        self.truncate_testset = False\n",
    "\n",
    "args = Args(act_mode_8bit=False)\n",
    "\n",
    "_, test_set = helen.HELEN_74_get_datasets((data_path, args), load_train=False, load_test=True)\n",
    "# test_set = train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring device: MAX78000, simulate=False.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "\n",
    "ai8x.set_device(85, False, False)\n",
    "\n",
    "model = ai85net_tinierssd.ai85tinierssd(num_classes=num_classes, device=device)\n",
    "\n",
    "# Run training first, using scripts/train_svhn_tinierssd.sh\n",
    "# checkpoint = torch.load('../logs/COMBINED_FACE_MIRRORED/ai85-tinierssd-helen-combined-aug-q.pth.tar')\n",
    "# checkpoint = torch.load('../logs/CORRECTED_COMBINED_HELEN_MIRRORED/checkpoint.pth.tar')\n",
    "checkpoint = torch.load('../logs/HIGHEST_SO_FAR/best.pth.tar')\n",
    "# checkpoint = torch.load('../logs/COMBINED_TWO_EYES/best.pth.tar')\n",
    "state_dict = checkpoint['state_dict']\n",
    "\n",
    "is_multi_gpu = all([key.startswith('module') for key in state_dict.keys()])\n",
    "\n",
    "# print(state_dict.keys())\n",
    "# print(model.state_dict().keys())\n",
    "# print(state_dict.keys()==model.state_dict().keys())\n",
    "\n",
    "if is_multi_gpu:\n",
    "    new_state_dict = OrderedDict()\n",
    "    for key, value in state_dict.items():\n",
    "        new_key = key.replace('module.', '')\n",
    "        new_state_dict[new_key] = value\n",
    "    model.load_state_dict(new_state_dict)\n",
    "\n",
    "else:\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'multi_box_loss': {'alpha': 2, 'neg_pos_ratio': 3}, 'nms': {'min_score': 0.2, 'max_overlap': 0.3, 'top_k': 20}}\n"
     ]
    }
   ],
   "source": [
    "obj_detection_params_yaml_file = '../parameters/obj_detection_params_svhn.yaml'\n",
    "obj_detection_params = parse_obj_detection_yaml.parse(obj_detection_params_yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16428"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_idx = np.random.randint(len(test_set))\n",
    "selected_idx = 883\n",
    "\n",
    "img, (boxes, lbls) = test_set[selected_idx]\n",
    "img = img.to(device)\n",
    "img_to_plot = ((128*(img.detach().cpu().numpy()+1))).astype(np.uint8)\n",
    "img_to_plot = img_to_plot.transpose([1,2,0])\n",
    "\n",
    "img_model = img.unsqueeze(0)\n",
    "locs, scores = model(img_model)\n",
    "\n",
    "all_images_boxes, all_images_labels, all_images_scores = \\\n",
    "    model.detect_objects(locs, scores,\n",
    "                         min_score=obj_detection_params['nms']['min_score'],\n",
    "                         max_overlap=obj_detection_params['nms']['max_overlap'],\n",
    "                         top_k=obj_detection_params['nms']['top_k'])\n",
    "\n",
    "\n",
    "img_ = Image.fromarray(img)\n",
    "img_.save(f\"img_{selected_idx}_true.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(img_to_plot)\n",
    "\n",
    "plt.tick_params(labelsize=16)\n",
    "        \n",
    "subplot_title=(\"Test set item: \" + str(selected_idx))\n",
    "ax.set_title(subplot_title, fontsize = 20)\n",
    "\n",
    "# Truth boxes\n",
    "boxes_resized = [[box_coord * test_set.resize_size[0] for box_coord in box] for box in boxes]\n",
    "# for b in range(len(boxes)):\n",
    "for b in range(2):\n",
    "    bb = boxes_resized[b]\n",
    "    rect = patches.Rectangle((bb[0], bb[1]), bb[2] - bb[0], bb[3] - bb[1], linewidth=3,\n",
    "                            edgecolor='r', facecolor=\"none\")\n",
    "    # ax.text(bb[0],(bb[1]), 'truth: eye', verticalalignment='center', color='white', fontsize=14, weight='bold')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "# # Predicted boxes\n",
    "# boxes_resized = [[box_coord * test_set.resize_size[0] for box_coord in box.detach().cpu().numpy()] for box in all_images_boxes]\n",
    "# detected_labels = [val.item() if val.item() != 10 else 0 for val in all_images_labels[0]]\n",
    "# for b in range(len(boxes_resized[0])):\n",
    "#     if(detected_labels[b] != 0):\n",
    "#         bb = boxes_resized[0][b]\n",
    "#         rect = patches.Rectangle((bb[0], bb[1]), bb[2] - bb[0], bb[3] - bb[1], linewidth=3,\n",
    "#                                 edgecolor='b', facecolor=\"none\")\n",
    "        \n",
    "#         ax.text(bb[0],(bb[1]), detected_labels[b], verticalalignment='center', color='white', fontsize=18, weight='bold')\n",
    "#         ax.add_patch(rect)    \n",
    "\n",
    "# Predicted boxes\n",
    "boxes_resized = [[box_coord * test_set.resize_size[0] for box_coord in box.detach().cpu().numpy()] for box in all_images_boxes]\n",
    "\n",
    "detected_labels = [val.item() if val.item() != 10 else 0 for val in all_images_labels[0]]\n",
    "for b in range(len(boxes_resized[0])):\n",
    "    if(detected_labels[b] != 0) and all_images_scores[0][b] > 0.7:\n",
    "        bb = boxes_resized[0][b]\n",
    "        rect = patches.Rectangle((bb[0], bb[1]), bb[2] - bb[0], bb[3] - bb[1], linewidth=3,\n",
    "                                edgecolor='b', facecolor=\"none\")\n",
    "        \n",
    "        ax.text(bb[0],(bb[1]), f'eye: {all_images_scores[0][b]:.2f}', verticalalignment='center', color='white', fontsize=14, weight='bold')\n",
    "        ax.add_patch(rect)    \n",
    "\n",
    "plt.show()\n",
    "\n",
    "# test\n",
    "# 55, 929, 951, 182, 93, 1034, 565, 883, 931, 327\n",
    "\n",
    "# with nose\n",
    "# 487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8fbdb6a1cb531b342c6a72b6095a624480ac77b81e108c1a1220c9f3e4cb717"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
