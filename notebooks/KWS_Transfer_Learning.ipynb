{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "## Load Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "from distiller import apputils\n",
    "import ai8x\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "kws20 = importlib.import_module(\"datasets.kws20-horsecough\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support, roc_auc_score, roc_curve\n",
    "\n",
    "def plot_confusion(y_true, y_pred, classes):\n",
    "    cf_matrix = confusion_matrix(y_true = y_true, y_pred = y_pred, labels =list(range(len(classes))))\n",
    "    print(cf_matrix)\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0,1], [0,1], 'r--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Checkpoint, Plot, and Dataset Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name:  human_others_4\n",
      "Classes:  ['combined', 'human_cough']\n",
      "Checkpoint Dir:  ./checkpoints/human_others_4/\n"
     ]
    }
   ],
   "source": [
    "# MODEL AND DATASET NAME \n",
    "model_name = 'human_others'\n",
    "classes = [\"combined\",'human_cough']\n",
    "checkpoint_dir = './checkpoints/'+model_name+'/'\n",
    "\n",
    "indexer = 0\n",
    "while os.path.exists(checkpoint_dir):\n",
    "    model_name = 'human_others'\n",
    "    model_name = model_name + '_' + str(indexer)\n",
    "    checkpoint_dir = './checkpoints/'+model_name+'/'\n",
    "    indexer += 1\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "print('Model Name: ', model_name)\n",
    "print('Classes: ', classes)\n",
    "print('Checkpoint Dir: ', checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\KWS_EQUINE\\raw\\combined\n",
      "..\\data\\KWS_EQUINE\\raw\\human_cough\n",
      "combined: 0.7269915\n",
      "human_cough: 1.0\n",
      "Weights:  [0.7269915, 1.0]\n"
     ]
    }
   ],
   "source": [
    "raw_data_path = Path(\"../data/KWS_EQUINE/raw/\")\n",
    "class_file_count = {}\n",
    "\n",
    "class_dirs = [d for d in raw_data_path.iterdir() if d.is_dir() and (d.stem != \"__combinedkws\") and (d.stem != \"__combined_others\") and (d.stem != \"__human_cough\")]\n",
    "\n",
    "for d in class_dirs:\n",
    "    print(d)\n",
    "    class_file_count[d] = len(list(d.iterdir()))\n",
    "\n",
    "min_file_count = float(min(class_file_count.values()))\n",
    "\n",
    "# Calculate weights\n",
    "class_weights = []\n",
    "for d in class_dirs:\n",
    "    class_file_count[d] = min_file_count / class_file_count[d]\n",
    "    print(f\"{d.stem}: {round(class_file_count[d], 7)}\")\n",
    "    class_weights.append(round(class_file_count[d], 7))\n",
    "class_weights = [0.5, 1]\n",
    "print('Weights: ',class_weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 4096\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    cpu = False\n",
    "else:\n",
    "     device = torch.device('cpu')\n",
    "     cpu = True\n",
    "\n",
    "print('Running on device: {}'.format(torch.cuda.get_device_name()))\n",
    "\n",
    "processed_data_path = Path(\"../data/KWS_EQUINE/processed/\")\n",
    "if len(os.listdir(processed_data_path)) == 0:\n",
    "    train_loader, val_loader, test_loader, _ = apputils.get_data_loaders(kws20.KWS_HORSE_TF_get_datasets, (\"../data\", True), train_batch_size, 4, validation_split=0.1,cpu=cpu)\n",
    "    print(f\"Dataset sizes:\\n\\ttraining={len(train_loader.sampler)}\\n\\tvalidation={len(val_loader.sampler)}\\n\\ttest={len(test_loader.sampler)}\")\n",
    "else:\n",
    "    print('Dataset Exists')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Reference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(params)\n",
    "    return params\n",
    "\n",
    "ai8x.set_device(device=85, simulate=False, round_avg=False)\n",
    "\n",
    "mod = importlib.import_module(\"models.ai85net-kws20-v3\")\n",
    "\n",
    "model = mod.AI85KWS20Netv3(num_classes=21, num_channels=128, dimensions=(128, 1), bias=False)\n",
    "print(f'Number of Model Params: {count_params(model)}')\n",
    "\n",
    "# WEIGHTS OF REFERENCE MODEL\n",
    "model, compression_scheduler, optimizer, start_epoch = apputils.load_checkpoint(\n",
    "            model, \"../logs/kws20_original/qat_best.pth.tar\")\n",
    "\n",
    " # FREEZE SOME LAYERS\n",
    "def freeze_layer(layer):\n",
    "    for p in layer.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "# freeze_layer(model.voice_conv1)\n",
    "# freeze_layer(model.voice_conv2)\n",
    "freeze_layer(model.voice_conv3)\n",
    "freeze_layer(model.voice_conv4)\n",
    "freeze_layer(model.kws_conv1)\n",
    "freeze_layer(model.kws_conv2)\n",
    "freeze_layer(model.kws_conv3)\n",
    "# freeze_layer(model.kws_conv4)\n",
    "model.fc = ai8x.Linear(256, len(classes), bias=False, wide=True)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20000\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "ms_lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[500, 1000], gamma=0.2)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights))\n",
    "criterion.to(device)\n",
    "\n",
    "qat_policy = {\n",
    "    'start_epoch': 400,\n",
    "    'weight_bits': 8\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "best_qat_acc = 0\n",
    "best_loss = 0\n",
    "best_epoch = 0\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "val_acc = []\n",
    "val_loss =[]\n",
    "running_class_acc = []\n",
    "\n",
    "for epoch in range(0, num_epochs):\n",
    "    train_start = time.time()\n",
    "    if epoch > 0 and epoch == qat_policy['start_epoch']:\n",
    "        print('QAT is starting!')\n",
    "        # Fuse the BN parameters into conv layers before Quantization Aware Training (QAT)\n",
    "        ai8x.fuse_bn_layers(model)\n",
    "        # Switch model from unquantized to quantized for QAT\n",
    "        ai8x.initiate_qat(model, qat_policy)\n",
    "        # Model is re-transferred to GPU in case parameters were added\n",
    "        model.to(device)\n",
    "\n",
    "    average_acc = 0\n",
    "    ############ TRAIN SECTION ############\n",
    "    running_loss = []\n",
    "    y_pred_train = []\n",
    "    y_true_train = []\n",
    "    acc_b = []\n",
    "    model.train()\n",
    "    for idx, (inputs, target) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        model_out = model(inputs)\n",
    "        target_out = torch.argmax(model_out, dim=1)\n",
    "        \n",
    "        y_pred_train.extend(target_out.cpu().numpy())\n",
    "        y_true_train.extend(target.cpu().numpy())\n",
    "        \n",
    "        tp = torch.sum(target_out == target)\n",
    "        acc_b.extend([(tp / target_out.numel()).detach().item()])\n",
    "        \n",
    "        loss = criterion(model_out, target)     \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss.append(loss.cpu().detach().numpy())\n",
    "    \n",
    "    total_acc = np.mean(acc_b)*100\n",
    "    mean_loss = np.mean(running_loss)\n",
    "\n",
    "    # TRAIN ACCURACY / TRAIN LOSS\n",
    "    train_acc.append(total_acc)\n",
    "    train_loss.append(mean_loss)\n",
    "    average_acc += total_acc/2\n",
    "\n",
    "    ############ VALIDATION SECTION ############\n",
    "    acc_b = []\n",
    "    y_pred_val = []\n",
    "    y_true_val = []\n",
    "    running_v_loss = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, target in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            model_out = model(inputs)\n",
    "            target_out = torch.argmax(model_out, dim=1)\n",
    "            \n",
    "            y_pred_val.extend(target_out.cpu().numpy())\n",
    "            y_true_val.extend(target.cpu().numpy())\n",
    "            \n",
    "            tp = torch.sum(target_out == target)\n",
    "            acc_b.extend([(tp / target_out.numel()).detach().item()])\n",
    "\n",
    "            v_loss = criterion(model_out, target)\n",
    "            running_v_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        total_acc = np.mean(acc_b)*100\n",
    "        mean_loss = np.mean(running_v_loss)\n",
    "\n",
    "        if epoch == qat_policy['start_epoch']: best_acc = 0\n",
    "        \n",
    "        # VALIDATION ACCURACY / VALIDATION LOSS\n",
    "        val_acc.append(total_acc)\n",
    "        val_loss.append(mean_loss)\n",
    "        average_acc += total_acc/2\n",
    "    \n",
    "    train_end = time.time()\n",
    "    ms_lr_scheduler.step()\n",
    "\n",
    "    ############ CLASS ACCURACY ############\n",
    "    class_acc = np.zeros(len(classes))\n",
    "    for class_num,class_type in enumerate(classes):\n",
    "        class_count_train = y_true_train.count(class_num)\n",
    "        class_count_val = y_true_val.count(class_num)\n",
    "\n",
    "        for t_idx, targ_val in enumerate(y_true_train):\n",
    "            if targ_val == y_pred_train[t_idx] and targ_val == class_num:\n",
    "                class_acc[class_num] += 1/class_count_train/2*100\n",
    "\n",
    "        for t_idx, targ_val in enumerate(y_true_val):\n",
    "            if targ_val == y_pred_val[t_idx] and targ_val == class_num:\n",
    "                class_acc[class_num] += 1/class_count_val/2*100\n",
    "        \n",
    "    running_class_acc.append(class_acc)\n",
    "    print('---------------------------------------------')\n",
    "    print(\"\\n\\n Epoch: {}/{} \\tLR: {} \\tDur: {:.2f} sec\".format(epoch+1, num_epochs, ms_lr_scheduler.get_lr() , (train_end-train_start)))\n",
    "\n",
    "    ############ SAVE CHECKPOINT ############   \n",
    "    if average_acc > best_acc:\n",
    "        best_acc = average_acc\n",
    "        checkpoint_extras = {'best_ave_acc': best_acc,\n",
    "                                'best_epoch': epoch}\n",
    "        \n",
    "        model_prefix = f'{model_name}' if epoch < qat_policy['start_epoch'] else (f'qat_{model_name}')\n",
    "        apputils.save_checkpoint(epoch, model_name+'_'+str(epoch), model, optimizer=optimizer,\n",
    "                                    scheduler=None, extras=checkpoint_extras,\n",
    "                                    is_best=True, name=model_prefix,\n",
    "                                    dir=checkpoint_dir)\n",
    "\n",
    "        # PLOT CONFUSION MATRIX AND STAT MEASURES ON TRAIN\n",
    "        conf_mat_train = confusion_matrix(y_true_train, y_pred_train)\n",
    "        cm_display_train = ConfusionMatrixDisplay(confusion_matrix = conf_mat_train, display_labels = classes)\n",
    "        p_train,r_train,f1_train,_= precision_recall_fscore_support(y_true_train, y_pred_train, average=None)\n",
    "        cm_display_train.plot(cmap= 'Blues',colorbar=False, values_format = 'd')\n",
    "        plt.title('Preicison: ({:.2f} {:.2f})   Recall: ({:.2f} {:.2f})   F1-Score: ({:.2f} {:.2f})'.format(p_train[0],p_train[1],r_train[0],r_train[1],f1_train[0],f1_train[1]))\n",
    "        plt.savefig(checkpoint_dir+model_name+'_cm_train.png')\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()\n",
    "\n",
    "        # PLOT ROC ON TRAIN\n",
    "        plot_roc_curve(y_true_train, y_pred_train)\n",
    "        plt.title('AUC: {:2f}'.format(roc_auc_score(y_true_train, y_pred_train)))\n",
    "        plt.savefig(checkpoint_dir+model_name+'_roc_train.png')\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()\n",
    "\n",
    "        # PLOT CONFUSION MATRIX AND STAT MEASURES ON VALIDATION\n",
    "        conf_mat_val = confusion_matrix(y_true_val, y_pred_val)\n",
    "        cm_display_val = ConfusionMatrixDisplay(confusion_matrix = conf_mat_val, display_labels = classes)\n",
    "        p_val,r_val,f1_val,_= precision_recall_fscore_support(y_true_train, y_pred_train, average=None)\n",
    "        cm_display_val.plot(cmap= 'Blues',colorbar=False, values_format = 'd')\n",
    "        plt.title('Preicison: ({:.2f} {:.2f})   Recall: ({:.2f} {:.2f})   F1-Score: ({:.2f} {:.2f})'.format(p_val[0],p_val[1],r_val[0],r_val[1],f1_val[0],f1_val[1]))\n",
    "        plt.savefig(checkpoint_dir+model_name+'_cm_Val.png')\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()\n",
    "\n",
    "        # PLOT ROC ON VAL\n",
    "        plot_roc_curve(y_true_val, y_pred_val)\n",
    "        plt.title('AUC: {:.2f}'.format(roc_auc_score(y_true_val, y_pred_val)))\n",
    "        plt.savefig(checkpoint_dir+model_name+'_roc_val.png')\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()\n",
    "\n",
    "        print(f' --------------------------------------------------------->  Model Checkpoints Saved with Mean Accuracy : {best_acc:.2f}%')\n",
    "\n",
    "    ############ CONFUSION MATRIX ############   \n",
    "    print(\"\\n Training - Confusion Matrix: \")\n",
    "    plot_confusion(y_true_train, y_pred_train, classes)\n",
    "    print(\"\\n Validation - Confusion Matrix: \")\n",
    "    plot_confusion(y_true_val, y_pred_val, classes)\n",
    "    \n",
    "    ############ ACC and LOSS ############  \n",
    "    print('\\nTrain Acc : ', train_acc[-1])\n",
    "    print('Train Loss : ', train_loss[-1])\n",
    "    print('Val Acc : ', val_acc[-1])\n",
    "    print('Val Loss : ', val_loss[-1])\n",
    "\n",
    "    ############ PLOTS ############\n",
    "    if (epoch%2 == 0 or epoch==num_epochs-1) and epoch > 0:\n",
    "        best_epoch = checkpoint_extras['best_epoch']\n",
    "        \n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.title(model_name)\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(val_acc, color ='green')\n",
    "        plt.plot(train_acc, color = 'red')\n",
    "        plt.plot(np.asarray(running_class_acc)[:,0],color='orange')\n",
    "        plt.plot(np.asarray(running_class_acc)[:,1],color='yellow')\n",
    "        plt.stem(best_epoch,train_acc[best_epoch])\n",
    "        plt.legend(['Validation','Train',classes[0],classes[1],'Checkpoint'])\n",
    "        plt.title('Accuracy: {:.2f}'.format(train_acc[best_epoch]))\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Value')\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(val_loss,color='green')\n",
    "        plt.plot(train_loss,color='red')\n",
    "        plt.stem(best_epoch,train_loss[best_epoch])\n",
    "        plt.legend(['Validation','Train','Checkpoint'])\n",
    "        plt.title('Loss: {:.2f}'.format(train_loss[best_epoch]))\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Value')\n",
    "\n",
    "        plt.savefig(checkpoint_dir+model_name+'.png')\n",
    "        \n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()\n",
    "\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec35e5d0984cc59eb0cd6a0be286daf2d556405b3fb6375200d13e76db69dcf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
