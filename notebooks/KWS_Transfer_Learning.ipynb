{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "## Load Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "from distiller import apputils\n",
    "import ai8x\n",
    "\n",
    "kws20 = importlib.import_module(\"datasets.kws20-horsecough\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse_cough: 0.3773585\n",
      "horse_neigh: 0.7407407\n",
      "human_cough: 1.0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "raw_data_path = Path(\"../data/KWS_EQUINE/raw/\")\n",
    "class_file_count = {}\n",
    "\n",
    "class_dirs = [d for d in raw_data_path.iterdir() if d.is_dir() and d.stem != \"_background_noise_\"]\n",
    "\n",
    "for d in class_dirs:\n",
    "    class_file_count[d] = len(list(d.iterdir()))\n",
    "\n",
    "min_file_count = float(min(class_file_count.values()))\n",
    "\n",
    "for d in class_dirs:\n",
    "    class_file_count[d] = min_file_count / class_file_count[d]\n",
    "    print(f\"{d.stem}: {round(class_file_count[d], 7)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No key `noise_var` in input augmentation dictionary!  Using defaults: [Min: 0., Max: 1.]\n",
      "No key `shift` in input augmentation dictionary! Using defaults: [Min:-0.1, Max: 0.1]\n",
      "No key `strech` in input augmentation dictionary! Using defaults: [Min: 0.8, Max: 1.3]\n",
      "Generating dataset from raw data samples for the first time. \n",
      "This process will take significant time (~60 minutes)...\n",
      "data_len: 16384\n",
      "------------- Label Size ---------------\n",
      "horse_cough:  \t53\n",
      "horse_neigh:  \t27\n",
      "human_cough:  \t20\n",
      "------------------------------------------\n",
      "Processing the label: horse_cough. 1 of 3\n",
      "\t1 of 53\n",
      "Finished in 1.604 seconds.\n",
      "(159, 128, 128)\n",
      "Data concatenation finished in 0.001 seconds.\n",
      "Processing the label: horse_neigh. 2 of 3\n",
      "\t1 of 27\n",
      "Finished in 0.802 seconds.\n",
      "(81, 128, 128)\n",
      "Data concatenation finished in 0.002 seconds.\n",
      "Processing the label: human_cough. 3 of 3\n",
      "\t1 of 20\n",
      "Finished in 0.609 seconds.\n",
      "(60, 128, 128)\n",
      "Data concatenation finished in 0.008 seconds.\n",
      "Dataset created.\n",
      "Training+Validation: 19,  Test: 1\n",
      "\n",
      "Processing train...\n",
      "Class horse_cough (# 0): 147 elements\n",
      "Class horse_neigh (# 1): 78 elements\n",
      "Class human_cough (# 2): 57 elements\n",
      "Class UNKNOWN: 0 elements\n",
      "\n",
      "Processing test...\n",
      "Class horse_cough (# 0): 12 elements\n",
      "Class horse_neigh (# 1): 3 elements\n",
      "Class human_cough (# 2): 3 elements\n",
      "Class UNKNOWN: 0 elements\n",
      "Dataset sizes:\n",
      "\ttraining=282\n",
      "\tvalidation=18\n",
      "\ttest=18\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 32\n",
    "train_loader, val_loader, test_loader, _ = apputils.get_data_loaders(\n",
    "    kws20.KWS_HORSE_TF_get_datasets, (\"../data\", False), train_batch_size, 1, validation_split=0)\n",
    "print(f\"Dataset sizes:\\n\\ttraining={len(train_loader.sampler)}\\n\\tvalidation={len(val_loader.sampler)}\\n\\ttest={len(test_loader.sampler)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"horse_cough\", \"horse_neigh\", \"human_cough\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring device: MAX78000, simulate=False.\n",
      "Number of Model Params: 173568\n"
     ]
    }
   ],
   "source": [
    "ai8x.set_device(device=85, simulate=False, round_avg=False)\n",
    "\n",
    "mod = importlib.import_module(\"models.ai85net-kws20-kabayo\")\n",
    "\n",
    "model = mod.AI85KWS20Netv3(num_classes=37, num_channels=128, dimensions=(128, 1), bias=False)\n",
    "print(f'Number of Model Params: {count_params(model)}')\n",
    "\n",
    "# model, compression_scheduler, optimizer, start_epoch = apputils.load_checkpoint(\n",
    "#             model, \"logs/2023.01.10-013008/qat_best.pth.tar\", model_device='cuda')\n",
    "\n",
    "model, compression_scheduler, optimizer, start_epoch = apputils.load_checkpoint(\n",
    "            model, \"../logs/2023.01.23-053753/qat_best.pth.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace FC layer and freeze the rest of the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_layer(layer):\n",
    "    for p in layer.parameters():\n",
    "        p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_layer(model.voice_conv1)\n",
    "freeze_layer(model.voice_conv2)\n",
    "freeze_layer(model.voice_conv3)\n",
    "freeze_layer(model.voice_conv4)\n",
    "freeze_layer(model.kws_conv1)\n",
    "# freeze_layer(model.kws_conv2)\n",
    "# freeze_layer(model.kws_conv3)\n",
    "# freeze_layer(model.kws_conv4)\n",
    "model.fc = ai8x.Linear(256, len(classes), bias=False, wide=True)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "epoch = 0\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "ms_lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20, 80], gamma=0.5)\n",
    "criterion = torch.nn.CrossEntropyLoss(\n",
    "    torch.Tensor((1, 1, 1))\n",
    ")\n",
    "criterion.to(device)\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss(\n",
    "#     torch.Tensor((1, 1, 0.01, 1, 1, 0.01, 0.01, 0.01))\n",
    "# )\n",
    "# criterion.to(device)\n",
    "\n",
    "qat_policy = {\n",
    "    'start_epoch': 20,\n",
    "    'weight_bits': 8\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion(y_true, y_pred, classes):\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred, list(range(len(classes))))\n",
    "    print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (input, target) in enumerate(train_loader):\n",
    "#     print(np.shape(input), np.shape(target), sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50\t LR: [0.0001]\t Train Loss: 0.9043\t Dur: 10.08 sec.\n",
      "Best model saved with accuracy: 66.67%\n",
      "\t\t Test Acc: 66.67\n",
      "\t\tConfusion:\n",
      "[[12  0  0]\n",
      " [ 2  0  1]\n",
      " [ 3  0  0]]\n",
      "Epoch: 2/50\t LR: [0.0001]\t Train Loss: 0.9107\t Dur: 9.97 sec.\n",
      "\t\t Test Acc: 66.67\n",
      "\t\tConfusion:\n",
      "[[12  0  0]\n",
      " [ 2  0  1]\n",
      " [ 3  0  0]]\n",
      "Epoch: 3/50\t LR: [0.0001]\t Train Loss: 0.8813\t Dur: 9.97 sec.\n",
      "\t\t Test Acc: 66.67\n",
      "\t\tConfusion:\n",
      "[[12  0  0]\n",
      " [ 2  0  1]\n",
      " [ 3  0  0]]\n",
      "Epoch: 4/50\t LR: [0.0001]\t Train Loss: 0.8859\t Dur: 10.14 sec.\n",
      "\t\t Test Acc: 66.67\n",
      "\t\tConfusion:\n",
      "[[12  0  0]\n",
      " [ 2  0  1]\n",
      " [ 3  0  0]]\n",
      "Epoch: 5/50\t LR: [0.0001]\t Train Loss: 0.8805\t Dur: 9.87 sec.\n",
      "\t\t Test Acc: 55.56\n",
      "\t\tConfusion:\n",
      "[[10  2  0]\n",
      " [ 2  0  1]\n",
      " [ 3  0  0]]\n",
      "Epoch: 6/50\t LR: [0.0001]\t Train Loss: 0.8541\t Dur: 9.82 sec.\n",
      "\t\t Test Acc: 55.56\n",
      "\t\tConfusion:\n",
      "[[10  2  0]\n",
      " [ 2  0  1]\n",
      " [ 3  0  0]]\n",
      "Epoch: 7/50\t LR: [0.0001]\t Train Loss: 0.8348\t Dur: 9.79 sec.\n",
      "\t\t Test Acc: 55.56\n",
      "\t\tConfusion:\n",
      "[[10  2  0]\n",
      " [ 2  0  1]\n",
      " [ 3  0  0]]\n",
      "Epoch: 8/50\t LR: [0.0001]\t Train Loss: 0.8530\t Dur: 10.01 sec.\n",
      "\t\t Test Acc: 61.11\n",
      "\t\tConfusion:\n",
      "[[11  1  0]\n",
      " [ 2  0  1]\n",
      " [ 3  0  0]]\n",
      "Epoch: 9/50\t LR: [0.0001]\t Train Loss: 0.8503\t Dur: 9.80 sec.\n",
      "\t\t Test Acc: 61.11\n",
      "\t\tConfusion:\n",
      "[[10  2  0]\n",
      " [ 1  1  1]\n",
      " [ 3  0  0]]\n",
      "Epoch: 10/50\t LR: [0.0001]\t Train Loss: 0.8308\t Dur: 9.85 sec.\n",
      "\t\t Test Acc: 61.11\n",
      "\t\tConfusion:\n",
      "[[10  2  0]\n",
      " [ 1  1  1]\n",
      " [ 3  0  0]]\n",
      "Epoch: 11/50\t LR: [0.0001]\t Train Loss: 0.8210\t Dur: 9.79 sec.\n",
      "\t\t Test Acc: 55.56\n",
      "\t\tConfusion:\n",
      "[[10  2  0]\n",
      " [ 2  0  1]\n",
      " [ 3  0  0]]\n",
      "Epoch: 12/50\t LR: [0.0001]\t Train Loss: 0.8150\t Dur: 9.81 sec.\n",
      "\t\t Test Acc: 50.00\n",
      "\t\tConfusion:\n",
      "[[9 3 0]\n",
      " [2 0 1]\n",
      " [3 0 0]]\n",
      "Epoch: 13/50\t LR: [0.0001]\t Train Loss: 0.8135\t Dur: 10.20 sec.\n",
      "\t\t Test Acc: 50.00\n",
      "\t\tConfusion:\n",
      "[[9 3 0]\n",
      " [2 0 1]\n",
      " [3 0 0]]\n",
      "Epoch: 14/50\t LR: [0.0001]\t Train Loss: 0.8267\t Dur: 9.84 sec.\n",
      "\t\t Test Acc: 50.00\n",
      "\t\tConfusion:\n",
      "[[9 3 0]\n",
      " [2 0 1]\n",
      " [3 0 0]]\n",
      "Epoch: 15/50\t LR: [0.0001]\t Train Loss: 0.8020\t Dur: 9.79 sec.\n",
      "\t\t Test Acc: 55.56\n",
      "\t\tConfusion:\n",
      "[[10  2  0]\n",
      " [ 2  0  1]\n",
      " [ 3  0  0]]\n",
      "Epoch: 16/50\t LR: [0.0001]\t Train Loss: 0.8098\t Dur: 9.90 sec.\n",
      "\t\t Test Acc: 50.00\n",
      "\t\tConfusion:\n",
      "[[9 3 0]\n",
      " [2 0 1]\n",
      " [3 0 0]]\n",
      "Epoch: 17/50\t LR: [0.0001]\t Train Loss: 0.7952\t Dur: 10.43 sec.\n",
      "\t\t Test Acc: 50.00\n",
      "\t\tConfusion:\n",
      "[[9 2 1]\n",
      " [2 0 1]\n",
      " [3 0 0]]\n",
      "Epoch: 18/50\t LR: [0.0001]\t Train Loss: 0.7779\t Dur: 9.76 sec.\n",
      "\t\t Test Acc: 55.56\n",
      "\t\tConfusion:\n",
      "[[9 2 1]\n",
      " [2 1 0]\n",
      " [3 0 0]]\n",
      "Epoch: 19/50\t LR: [0.0001]\t Train Loss: 0.7981\t Dur: 10.05 sec.\n",
      "\t\t Test Acc: 55.56\n",
      "\t\tConfusion:\n",
      "[[9 2 1]\n",
      " [2 1 0]\n",
      " [3 0 0]]\n",
      "Epoch: 20/50\t LR: [0.0001]\t Train Loss: 0.7762\t Dur: 9.91 sec.\n",
      "\t\t Test Acc: 55.56\n",
      "\t\tConfusion:\n",
      "[[9 2 1]\n",
      " [2 1 0]\n",
      " [3 0 0]]\n",
      "QAT is starting!\n",
      "Epoch: 21/50\t LR: [2.5e-05]\t Train Loss: 1.8903\t Dur: 10.10 sec.\n",
      "Best model saved with accuracy: 77.78%\n",
      "\t\t Test Acc: 77.78\n",
      "\t\tConfusion:\n",
      "[[11  1  0]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 22/50\t LR: [5e-05]\t Train Loss: 1.4485\t Dur: 10.20 sec.\n",
      "\t\t Test Acc: 77.78\n",
      "\t\tConfusion:\n",
      "[[11  1  0]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 23/50\t LR: [5e-05]\t Train Loss: 1.0988\t Dur: 10.14 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  1  1]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 24/50\t LR: [5e-05]\t Train Loss: 0.8742\t Dur: 9.96 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  1  1]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 25/50\t LR: [5e-05]\t Train Loss: 0.6909\t Dur: 9.96 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  0  2]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 26/50\t LR: [5e-05]\t Train Loss: 0.6706\t Dur: 9.94 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  0  2]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 27/50\t LR: [5e-05]\t Train Loss: 0.5898\t Dur: 9.90 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  0  2]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 28/50\t LR: [5e-05]\t Train Loss: 0.6415\t Dur: 10.04 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  0  2]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 29/50\t LR: [5e-05]\t Train Loss: 0.6767\t Dur: 10.01 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  0  2]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 30/50\t LR: [5e-05]\t Train Loss: 0.5188\t Dur: 10.12 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  0  2]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 31/50\t LR: [5e-05]\t Train Loss: 0.5374\t Dur: 10.08 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  0  2]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 32/50\t LR: [5e-05]\t Train Loss: 0.4313\t Dur: 9.96 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  0  2]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 33/50\t LR: [5e-05]\t Train Loss: 0.4788\t Dur: 10.04 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  0  2]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 34/50\t LR: [5e-05]\t Train Loss: 0.4886\t Dur: 10.33 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  0  2]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 35/50\t LR: [5e-05]\t Train Loss: 0.4218\t Dur: 10.18 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  1  1]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 36/50\t LR: [5e-05]\t Train Loss: 0.5346\t Dur: 9.97 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  1  1]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 37/50\t LR: [5e-05]\t Train Loss: 0.4594\t Dur: 10.12 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  1  1]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 38/50\t LR: [5e-05]\t Train Loss: 0.4534\t Dur: 10.10 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  1  1]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 39/50\t LR: [5e-05]\t Train Loss: 0.4608\t Dur: 10.13 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  1  1]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 40/50\t LR: [5e-05]\t Train Loss: 0.4181\t Dur: 9.99 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  1  1]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 41/50\t LR: [5e-05]\t Train Loss: 0.5261\t Dur: 10.39 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  1  1]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 42/50\t LR: [5e-05]\t Train Loss: 0.3520\t Dur: 10.11 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  1  1]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 43/50\t LR: [5e-05]\t Train Loss: 0.3869\t Dur: 10.40 sec.\n",
      "\t\t Test Acc: 66.67\n",
      "\t\tConfusion:\n",
      "[[10  1  1]\n",
      " [ 0  2  1]\n",
      " [ 3  0  0]]\n",
      "Epoch: 44/50\t LR: [5e-05]\t Train Loss: 0.3878\t Dur: 10.05 sec.\n",
      "\t\t Test Acc: 66.67\n",
      "\t\tConfusion:\n",
      "[[10  1  1]\n",
      " [ 0  2  1]\n",
      " [ 3  0  0]]\n",
      "Epoch: 45/50\t LR: [5e-05]\t Train Loss: 0.3624\t Dur: 9.99 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  1  1]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 46/50\t LR: [5e-05]\t Train Loss: 0.3409\t Dur: 9.99 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  1  1]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 47/50\t LR: [5e-05]\t Train Loss: 0.4525\t Dur: 10.13 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  2  0]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 48/50\t LR: [5e-05]\t Train Loss: 0.3946\t Dur: 10.09 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  2  0]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 49/50\t LR: [5e-05]\t Train Loss: 0.3594\t Dur: 9.98 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  2  0]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n",
      "Epoch: 50/50\t LR: [5e-05]\t Train Loss: 0.3812\t Dur: 10.04 sec.\n",
      "\t\t Test Acc: 72.22\n",
      "\t\tConfusion:\n",
      "[[10  2  0]\n",
      " [ 0  3  0]\n",
      " [ 3  0  0]]\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_qat_acc = 0\n",
    "for epoch in range(0, num_epochs):\n",
    "    if epoch > 0 and epoch == qat_policy['start_epoch']:\n",
    "        print('QAT is starting!')\n",
    "        # Fuse the BN parameters into conv layers before Quantization Aware Training (QAT)\n",
    "        ai8x.fuse_bn_layers(model)\n",
    "\n",
    "        # Switch model from unquantized to quantized for QAT\n",
    "        ai8x.initiate_qat(model, qat_policy)\n",
    "\n",
    "        # Model is re-transferred to GPU in case parameters were added\n",
    "        model.to(device)\n",
    "    running_loss = []\n",
    "    train_start = time.time()\n",
    "    model.train()\n",
    "    for idx, (inputs, target) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        model_out = model(inputs)\n",
    "        \n",
    "        loss = criterion(model_out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "    mean_loss = np.mean(running_loss)\n",
    "    train_end = time.time()\n",
    "    print(\"Epoch: {}/{}\\t LR: {}\\t Train Loss: {:.4f}\\t Dur: {:.2f} sec.\".format(\n",
    "        epoch+1, num_epochs, ms_lr_scheduler.get_lr(), mean_loss, (train_end-train_start)))\n",
    "    \n",
    "    model.eval()\n",
    "    acc = 0.\n",
    "    acc_weight = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, target in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            model_out = model(inputs)\n",
    "            target_out = torch.argmax(model_out, dim=1)\n",
    "            \n",
    "            y_pred.extend(target_out.cpu().numpy())\n",
    "            y_true.extend(target.cpu().numpy())\n",
    "            \n",
    "            tp = torch.sum(target_out == target)\n",
    "            acc_batch = (tp / target_out.numel()).detach().item()\n",
    "            acc += target_out.shape[0] * acc_batch\n",
    "            acc_weight += target_out.shape[0]\n",
    "            \n",
    "        total_acc = 100 * (acc / acc_weight)\n",
    "        if epoch == qat_policy['start_epoch']: best_acc = 0\n",
    "        if total_acc > best_acc:\n",
    "            best_acc = total_acc\n",
    "            checkpoint_extras = {'current_top1': best_acc,\n",
    "                                 'best_top1': best_acc,\n",
    "                                 'best_epoch': epoch}\n",
    "            model_name = 'ai85net_kws_equine'\n",
    "            model_prefix = f'{model_name}' if epoch < qat_policy['start_epoch'] else (f'qat_{model_name}')\n",
    "            apputils.save_checkpoint(epoch, model_name, model, optimizer=optimizer,\n",
    "                                     scheduler=None, extras=checkpoint_extras,\n",
    "                                     is_best=True, name=model_prefix,\n",
    "                                     dir='.')\n",
    "            print(f'Best model saved with accuracy: {best_acc:.2f}%')\n",
    "            \n",
    "        print('\\t\\t Test Acc: {:.2f}'.format(total_acc))\n",
    "        print(\"\\t\\tConfusion:\")\n",
    "        plot_confusion(y_true, y_pred, classes)\n",
    "    ms_lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33335497366de2c65b60bad2619bdb398d3af58569807f2e4d877bfe78d46b65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
