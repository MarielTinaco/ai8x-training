{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "## Load Libraries and Function Declarations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "from distiller import apputils\n",
    "import ai8x\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "kws20 = importlib.import_module(\"datasets.kws20-horsecough\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "import librosa\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# FIX SEED FOR REPRODUCIBILITY\n",
    "seed = 69\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "def rescale(audio, min_val=-1,max_val=1):\n",
    "    sig = audio\n",
    "    mean = np.average(sig)\n",
    "\n",
    "    sig = sig-mean # REMOVE DC COMPONENT\n",
    "\n",
    "    sig_max = np.max(sig)\n",
    "    sig_min = np.min(sig)\n",
    "\n",
    "    if sig_max >= np.abs(sig_min):\n",
    "        sig_scaled = sig/sig_max\n",
    "    else:\n",
    "        sig_scaled = sig/np.abs(sig_min)\n",
    "\n",
    "    return sig_scaled\n",
    "\n",
    "def rescale2(audio, min_val=-1,max_val=1):\n",
    "    scaler = MinMaxScaler(feature_range=(min_val,max_val))\n",
    "    audio = audio.reshape(-1,1)\n",
    "    scaler.fit(audio)\n",
    "    scaled = np.array(scaler.transform(audio))\n",
    "    \n",
    "    return scaled[:,0]\n",
    "\n",
    "\n",
    "def plot_confusion(y_true, y_pred, classes):\n",
    "    cf_matrix = confusion_matrix(y_true = y_true, y_pred = y_pred, labels =list(range(len(classes))))\n",
    "    print(cf_matrix)\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0,1], [0,1], 'r--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "def custom_dataloader(data, train_idx, val_idx, test_idx, batch_size = 2048):\n",
    "    data_file = data\n",
    "    x = np.asarray(data_file[0][test_idx])\n",
    "    y = np.squeeze(np.asarray(data_file[1][test_idx]))\n",
    "    test_set = TensorDataset(torch.Tensor(x),torch.Tensor(y).to(dtype =torch.int64))\n",
    "    test_loader = DataLoader(test_set,batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "    x = np.asarray(data_file[0][val_idx])\n",
    "    y = np.squeeze(np.asarray(data_file[1][val_idx]))\n",
    "    val_set = TensorDataset(torch.Tensor(x),torch.Tensor(y).to(dtype =torch.int64))\n",
    "    val_loader = DataLoader(val_set,batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "    x = np.asarray(data_file[0][train_idx])\n",
    "    y = np.squeeze(np.asarray(data_file[1][train_idx]))\n",
    "    train_set = TensorDataset(torch.Tensor(x),torch.Tensor(y).to(dtype =torch.int64))\n",
    "    train_loader = DataLoader(train_set,batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader,val_loader,test_loader\n",
    "\n",
    "def freeze_layer(layer):\n",
    "    for p in layer.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "def count_params(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(params)\n",
    "    return params\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Checkpoints Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL NAME AND CHECKPOINT FOLDER\n",
    "name = 'equine'\n",
    "classes = [\"COMBINED\",'COUGH']\n",
    "\n",
    "indexer = 0\n",
    "while True:\n",
    "    model_name = name + '_' + str(indexer)\n",
    "    checkpoint_dir = './checkpoints/'+model_name+'/'\n",
    "    indexer += 1\n",
    "\n",
    "    if os.path.exists(checkpoint_dir) is False:\n",
    "        break\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "print('Model Name: ', model_name)\n",
    "print('Classes: ', classes)\n",
    "print('Checkpoint Dir: ', checkpoint_dir)\n",
    "\n",
    "# CALCULATE WEIGHTS\n",
    "raw_data_path = Path(\"../data/KWS_EQUINE/raw/\")\n",
    "class_file_count = {}\n",
    "class_dirs = [d for d in raw_data_path.iterdir() if d.is_dir() and (d.stem != \"__combinedkws\") and (d.stem != \"__combined_others\") and (d.stem != \"__human_cough\")and (d.stem != \"__human_cough_v2\")]\n",
    "\n",
    "for d in class_dirs:\n",
    "    print(d)\n",
    "    class_file_count[d] = len(list(d.iterdir()))\n",
    "\n",
    "min_file_count = float(min(class_file_count.values()))\n",
    "\n",
    "\n",
    "class_weights = []\n",
    "for d in class_dirs:\n",
    "    class_file_count[d] = min_file_count / class_file_count[d]\n",
    "    print(f\"{d.stem}: {round(class_file_count[d], 7)}\")\n",
    "    class_weights.append(round(class_file_count[d], 7))\n",
    "    \n",
    "print('Weights: ',class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Smart compressed file creation\n",
    "# Change class dicts of main Dataloader class\n",
    "train_batch_size = 2048\n",
    "train_loader, val_loader, test_loader, _ = apputils.get_data_loaders(\n",
    "    kws20.KWS_HORSE_TF_get_datasets, (\"../data\", False), train_batch_size, 4, validation_split=0.2)\n",
    "\n",
    "print(f\"Dataset sizes:\\n\\ttraining={len(train_loader.sampler)}\\n\\tvalidation={len(val_loader.sampler)}\\n\\ttest={len(test_loader.sampler)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horse Cough Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HORSE COUGH DATA PATH\n",
    "inf_paths = [\"../data/KWS_EQUINE/inference/horse_cough/\",\"C:/Users/J_C/Desktop/DATASETS_N/horse_cough_stable/\"]\n",
    "\n",
    "files = []\n",
    "for path_root in inf_paths:\n",
    "            path_file = os.listdir(path_root)\n",
    "            for p in path_file:\n",
    "                files.append(path_root+p)\n",
    "\n",
    "inf_count = len(files)\n",
    "y_true_inf = np.ones(inf_count)\n",
    "\n",
    "print('\\n Horse Cough File Count: ',inf_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Reference Model and Train Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    cpu = False\n",
    "else:\n",
    "     device = torch.device('cpu')\n",
    "     cpu = True\n",
    "     \n",
    "ai8x.set_device(device=85, simulate=False, round_avg=False)\n",
    "\n",
    "# mod = importlib.import_module(\"models.ai85net-kws20-v3\")\n",
    "# model = mod.AI85KWS20Netv3(num_classes=21, num_channels=128, dimensions=(128, 1), bias=False)\n",
    "\n",
    "mod = importlib.import_module(\"models.ai85net-equine\")\n",
    "model = mod.AI85EQUINE()\n",
    "\n",
    "\n",
    "# WEIGHTS OF REFERENCE MODEL\n",
    "# model, compression_scheduler, optimizer, start_epoch = apputils.load_checkpoint(\n",
    "#             model, \"../logs/kws20_original/qat_best.pth.tar\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "ms_lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[300, 500], gamma=0.5)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.Tensor(class_weights))\n",
    "print(criterion.type)\n",
    "criterion.to(device)\n",
    "\n",
    "qat_policy = {\n",
    "    'start_epoch': 50,\n",
    "    'weight_bits': 8\n",
    "    }\n",
    "\n",
    "\n",
    "print('Running on device: {}'.format(torch.cuda.get_device_name()))\n",
    "print(f'Number of Model Params: {count_params(model)}')\n",
    "print('Optimizer: \\n',optimizer)\n",
    "print('Loss Function: \\n',criterion)\n",
    "print('QAT: \\n',qat_policy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_acc = 0\n",
    "# best_qat_acc = 0\n",
    "# for epoch in range(0, num_epochs):\n",
    "#     if epoch > 0 and epoch == qat_policy['start_epoch']:\n",
    "#         print('QAT is starting!')\n",
    "#         # Fuse the BN parameters into conv layers before Quantization Aware Training (QAT)\n",
    "#         ai8x.fuse_bn_layers(model)\n",
    "\n",
    "#         # Switch model from unquantized to quantized for QAT\n",
    "#         ai8x.initiate_qat(model, qat_policy)\n",
    "\n",
    "#         # Model is re-transferred to GPU in case parameters were added\n",
    "#         model.to(device)\n",
    "#     running_loss = []\n",
    "#     train_start = time.time()\n",
    "#     model.train()\n",
    "#     for idx, (inputs, target) in enumerate(train_loader):\n",
    "#         inputs = inputs.to(device)\n",
    "#         target = target.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         model_out = model(inputs)\n",
    "        \n",
    "#         loss = criterion(model_out, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "#     mean_loss = np.mean(running_loss)\n",
    "#     train_end = time.time()\n",
    "#     print(\"Epoch: {}/{}\\t LR: {}\\t Train Loss: {:.4f}\\t Dur: {:.2f} sec.\".format(\n",
    "#         epoch+1, num_epochs, ms_lr_scheduler.get_lr(), mean_loss, (train_end-train_start)))\n",
    "    \n",
    "#     model.eval()\n",
    "#     acc = 0.\n",
    "#     acc_weight = 0\n",
    "#     y_true = []\n",
    "#     y_pred = []\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, target in test_loader:\n",
    "#             inputs = inputs.to(device)\n",
    "#             target = target.to(device)\n",
    "#             model_out = model(inputs)\n",
    "#             target_out = torch.argmax(model_out, dim=1)\n",
    "            \n",
    "#             y_pred.extend(target_out.cpu().numpy())\n",
    "#             y_true.extend(target.cpu().numpy())\n",
    "            \n",
    "#             tp = torch.sum(target_out == target)\n",
    "#             acc_batch = (tp / target_out.numel()).detach().item()\n",
    "#             acc += target_out.shape[0] * acc_batch\n",
    "#             acc_weight += target_out.shape[0]\n",
    "            \n",
    "#         total_acc = 100 * (acc / acc_weight)\n",
    "#         if epoch == qat_policy['start_epoch']: best_acc = 0\n",
    "#         if total_acc > best_acc:\n",
    "#             best_acc = total_acc\n",
    "#             checkpoint_extras = {'current_top1': best_acc,\n",
    "#                                  'best_top1': best_acc,\n",
    "#                                  'best_epoch': epoch}\n",
    "#             model_name = 'ai85net_kws_equine'\n",
    "#             model_prefix = f'{model_name}' if epoch < qat_policy['start_epoch'] else (f'qat_{model_name}')\n",
    "#             apputils.save_checkpoint(epoch, model_name, model, optimizer=optimizer,\n",
    "#                                      scheduler=None, extras=checkpoint_extras,\n",
    "#                                      is_best=True, name=model_prefix,\n",
    "#                                      dir='.')\n",
    "#             print(f'Best model saved with accuracy: {best_acc:.2f}%')\n",
    "            \n",
    "#         print('\\t\\t Test Acc: {:.2f}'.format(total_acc))\n",
    "#         print(\"\\t\\tConfusion:\")\n",
    "#         plot_confusion(y_true, y_pred, classes)\n",
    "#     ms_lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 800\n",
    "\n",
    "best_acc = 0\n",
    "best_qat_acc = 0\n",
    "best_loss = 0\n",
    "best_epoch = 0\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "test_acc = []\n",
    "inf_acc = []\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "test_loss = []\n",
    "\n",
    "running_class_acc = []\n",
    "\n",
    "continue_train = True\n",
    "epoch = 0\n",
    "\n",
    "while(continue_train and epoch < num_epochs):\n",
    "    average_acc = 0\n",
    "    train_start = time.time()\n",
    "    if epoch > 0 and epoch == qat_policy['start_epoch']:\n",
    "        print('QAT is starting!')\n",
    "        # Fuse the BN parameters into conv layers before Quantization Aware Training (QAT)\n",
    "        ai8x.fuse_bn_layers(model)\n",
    "        # Switch model from unquantized to quantized for QAT\n",
    "        ai8x.initiate_qat(model, qat_policy)\n",
    "        # Model is re-transferred to GPU in case parameters were added\n",
    "        model.to(device)\n",
    "\n",
    "    ############ TRAIN SECTION ############\n",
    "    model.train()\n",
    "    acc_b = []   \n",
    "    y_pred_train = []\n",
    "    y_true_train = []\n",
    "    running_loss = []\n",
    "    for idx, (inputs, target) in enumerate(train_loader):\n",
    "        # temp_var = inputs.cpu().numpy()\n",
    "        # print(np.min(temp_var),np.max(temp_var))\n",
    "        # input()\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.type(torch.int64)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        model_out = model(inputs)\n",
    "        target_out = torch.argmax(model_out, dim=1)\n",
    "        \n",
    "        y_pred_train.extend(target_out.cpu().numpy())\n",
    "        y_true_train.extend(target.cpu().numpy())\n",
    "        \n",
    "        tp = torch.sum(target_out == target)\n",
    "        acc_b.extend([(tp / target_out.numel()).detach().item()])\n",
    "\n",
    "        loss = criterion(model_out, target)     \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss.append(loss.cpu().detach().numpy())\n",
    "    \n",
    "    total_acc = np.mean(acc_b)*100\n",
    "    mean_loss = np.mean(running_loss)\n",
    "\n",
    "    # TRAIN ACCURACY / TRAIN LOSS\n",
    "    train_acc.append(total_acc)\n",
    "    train_loss.append(mean_loss)\n",
    "    average_acc += total_acc*0.5\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        ############ VALIDATION SECTION ############\n",
    "        acc_b = []\n",
    "        y_pred_val = []\n",
    "        y_true_val = []\n",
    "        running_v_loss = []\n",
    "        for inputs, target in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            model_out = model(inputs)\n",
    "            target_out = torch.argmax(model_out, dim=1)\n",
    "            \n",
    "            y_pred_val.extend(target_out.cpu().numpy())\n",
    "            y_true_val.extend(target.cpu().numpy())\n",
    "            \n",
    "            tp = torch.sum(target_out == target)\n",
    "            acc_b.extend([(tp / target_out.numel()).detach().item()])\n",
    "\n",
    "            v_loss = criterion(model_out, target)\n",
    "            running_v_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        total_acc = np.mean(acc_b)*100\n",
    "        mean_loss = np.mean(running_v_loss)\n",
    "        \n",
    "        # VALIDATION ACCURACY / VALIDATION LOSS\n",
    "        val_acc.append(total_acc)\n",
    "        val_loss.append(mean_loss)\n",
    "        average_acc += total_acc*0.5\n",
    "\n",
    "        ############ TEST SECTION ############\n",
    "        acc_b = []\n",
    "        y_pred_test = []\n",
    "        y_true_test = []\n",
    "        running_t_loss = []\n",
    "\n",
    "        time_start = time.time()\n",
    "    \n",
    "        for inputs, target in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            model_out = model(inputs)\n",
    "            target_out = torch.argmax(model_out, dim=1)\n",
    "\n",
    "            y_true_test.extend(target.cpu().numpy())\n",
    "            y_pred_test.extend(target_out.cpu().numpy())\n",
    "\n",
    "            tp = torch.sum(target_out == target)\n",
    "            acc_b.extend([(tp / target_out.numel()).detach().item()])\n",
    "\n",
    "            v_loss = criterion(model_out, target)\n",
    "            running_t_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        total_acc = np.mean(acc_b)*100\n",
    "        mean_loss = np.mean(running_t_loss)\n",
    "        \n",
    "        # VALIDATION ACCURACY / VALIDATION LOSS\n",
    "        test_acc.append(total_acc)\n",
    "        test_loss.append(mean_loss)\n",
    "\n",
    "        ############ HORSE COUGH SECTION ############\n",
    "        y_pred_inf = []\n",
    "        acc_b = 0\n",
    "        for counter,f in enumerate(files):\n",
    "            try:\n",
    "                # CONVERT EACH AUDIO FILE TO A 128X128 ARRAY TO TENSOR\n",
    "                data_sq = np.zeros(128)\n",
    "                data, sr = librosa.load(f,sr = 16000)\n",
    "                data = rescale2(data,min_val=-1,max_val=1)\n",
    "                data = librosa.util.fix_length(data,size=int(128*128))\n",
    "                for index in range(0,len(data),128):\n",
    "                    data_row = data[index:index+128]\n",
    "                    data_sq = np.vstack((data_sq,data_row))\n",
    "                data_sq = data_sq[1:129]\n",
    "                data_sq = data_sq.transpose()\n",
    "                data_sq = np.expand_dims(data_sq, axis=0)\n",
    "                inputs = torch.from_numpy(data_sq.astype(np.float32))  \n",
    "                inputs.to(torch.uint8)\n",
    "\n",
    "                ############ INFERENCE SECTION ############\n",
    "                inputs = inputs.to(device)\n",
    "                model_out = model(inputs)\n",
    "                target_out = torch.argmax(model_out, dim=1)\n",
    "                class_output = target_out.detach().item()\n",
    "                if class_output == 1: acc_b += 1/inf_count*100\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "        inf_acc.append(acc_b)\n",
    "\n",
    "    # ############ CLASS ACCURACY ############\n",
    "    # class_acc = np.zeros(len(classes))\n",
    "    # for class_num,class_type in enumerate(classes):\n",
    "    #     class_count_train = y_true_train.count(class_num)\n",
    "    #     class_count_val = y_true_val.count(class_num)\n",
    "\n",
    "    #     for t_idx, targ_val in enumerate(y_true_train):\n",
    "    #         if targ_val == y_pred_train[t_idx] and targ_val == class_num:\n",
    "    #             class_acc[class_num] += 1/class_count_train*10\n",
    "\n",
    "    #     for t_idx, targ_val in enumerate(y_true_val):\n",
    "    #         if targ_val == y_pred_val[t_idx] and targ_val == class_num:\n",
    "    #             class_acc[class_num] += 1/class_count_val*90\n",
    "        \n",
    "    # running_class_acc.append(class_acc)\n",
    "    \n",
    "    train_end = time.time()\n",
    "    print('---------------------------------------------')\n",
    "    print(\"\\n\\n Epoch: {}/{} \\tLR: {} \\tDur: {:.2f} sec\".format(epoch+1, num_epochs, ms_lr_scheduler.get_lr() , (train_end-train_start)))\n",
    "\n",
    "    ############ CONFUSION MATRIX ############   \n",
    "    print(\"\\n TRAIN - Confusion Matrix: \")\n",
    "    plot_confusion(y_true_train, y_pred_train, classes)\n",
    "    print(\"\\n VAL - Confusion Matrix: \")\n",
    "    plot_confusion(y_true_val, y_pred_val, classes)\n",
    "    print(\"\\n TEST - Confusion Matrix: \")\n",
    "    plot_confusion(y_true_test, y_pred_test, classes)\n",
    "    \n",
    "    ############ ACC and LOSS ############  \n",
    "    print('\\nTrain Acc : ', train_acc[-1])\n",
    "    print('Train Loss : ', train_loss[-1])\n",
    "    print('Val Acc : ', val_acc[-1])\n",
    "    print('Val Loss : ', val_loss[-1])\n",
    "    print('Test Acc : ', test_acc[-1])\n",
    "    print('Test Loss : ', test_loss[-1])\n",
    "    print('Inference Acc : ', inf_acc[-1])\n",
    "\n",
    "    ############ PLOTS ############\n",
    "    if (epoch%5 == 0 or epoch==num_epochs-1) and epoch > 0:\n",
    "        best_epoch = checkpoint_extras['best_epoch']\n",
    "        \n",
    "        plt.figure(figsize=(20,10),dpi=300)\n",
    "        plt.title(model_name)\n",
    "        plt.subplot(1,2,1)\n",
    "        # plt.plot(np.asarray(running_class_acc)[:,0],color='orange')\n",
    "        # plt.plot(np.asarray(running_class_acc)[:,1],color='yellow')\n",
    "        plt.plot(test_acc,color = 'black')\n",
    "        plt.plot(val_acc, color ='green')\n",
    "        plt.plot(train_acc, color = 'red')\n",
    "        plt.plot(inf_acc, color ='blue')\n",
    "        plt.stem(best_epoch,train_acc[best_epoch])\n",
    "        # plt.legend([classes[0],classes[1],'Test','Validation','Train','Horse Cough','Checkpoint'])\n",
    "        plt.legend(['Test','Validation','Train','Horse Cough','Checkpoint'])\n",
    "\n",
    "        plt.title('Accuracy: {:.2f}'.format(train_acc[best_epoch]))\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Value')\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(test_loss, color = 'black')\n",
    "        plt.plot(val_loss,color='green')\n",
    "        plt.plot(train_loss,color='red')\n",
    "        plt.stem(best_epoch,train_loss[best_epoch])\n",
    "        plt.legend(['Test','Validation','Train','Checkpoint'])\n",
    "        plt.title('Loss: {:.2f}'.format(train_loss[best_epoch]))\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Value')\n",
    "\n",
    "        plt.savefig(checkpoint_dir+model_name+'.png')\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()\n",
    "    \n",
    "    ############ SAVE CHECKPOINT ############   \n",
    "    if average_acc > best_acc:\n",
    "        best_acc = average_acc\n",
    "        checkpoint_extras = {'best_ave_acc': best_acc,\n",
    "                                'best_epoch': epoch}\n",
    "        \n",
    "        model_prefix = f'{model_name}' if epoch < qat_policy['start_epoch'] else (f'qat_{model_name}')\n",
    "        apputils.save_checkpoint(epoch, model_name, model, optimizer=optimizer,\n",
    "                                    scheduler=None, extras=checkpoint_extras,\n",
    "                                    is_best=True, name=model_prefix,\n",
    "                                    dir=checkpoint_dir)\n",
    "\n",
    "        # PLOT CONFUSION MATRIX AND STAT MEASURES ON TRAIN\n",
    "        conf_mat_train = confusion_matrix(y_true_train, y_pred_train)\n",
    "        cm_display_train = ConfusionMatrixDisplay(confusion_matrix = conf_mat_train, display_labels = classes)\n",
    "        p_train,r_train,f1_train,_= precision_recall_fscore_support(y_true_train, y_pred_train, average=None)\n",
    "        cm_display_train.plot(cmap= 'Blues',colorbar=False, values_format = 'd')\n",
    "        plt.title('Preicison: ({:.2f} {:.2f})   Recall: ({:.2f} {:.2f})   F1-Score: ({:.2f} {:.2f})'.format(p_train[0],p_train[1],r_train[0],r_train[1],f1_train[0],f1_train[1]))\n",
    "        plt.savefig(checkpoint_dir+model_name+'_cm_TRAIN.png')\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()\n",
    "\n",
    "        # PLOT CONFUSION MATRIX AND STAT MEASURES ON VALIDATION\n",
    "        conf_mat_val = confusion_matrix(y_true_val, y_pred_val)\n",
    "        cm_display_val = ConfusionMatrixDisplay(confusion_matrix = conf_mat_val, display_labels = classes)\n",
    "        p_val,r_val,f1_val,_= precision_recall_fscore_support(y_true_val, y_pred_val, average=None)\n",
    "        cm_display_val.plot(cmap= 'Blues',colorbar=False, values_format = 'd')\n",
    "        plt.title('Preicison: ({:.2f} {:.2f})   Recall: ({:.2f} {:.2f})   F1-Score: ({:.2f} {:.2f})'.format(p_val[0],p_val[1],r_val[0],r_val[1],f1_val[0],f1_val[1]))\n",
    "        plt.savefig(checkpoint_dir+model_name+'_cm_VAL.png')\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()\n",
    "\n",
    "        # PLOT CONFUSION MATRIX AND STAT MEASURES ON TEST\n",
    "        conf_mat_test = confusion_matrix(y_true_test, y_pred_test)\n",
    "        cm_display_test = ConfusionMatrixDisplay(confusion_matrix = conf_mat_test, display_labels = classes)\n",
    "        p_test,r_test,f1_test,_= precision_recall_fscore_support(y_true_test, y_pred_test, average=None)\n",
    "        cm_display_test.plot(cmap= 'Blues',colorbar=False, values_format = 'd')\n",
    "        plt.title('Preicison: ({:.2f} {:.2f})   Recall: ({:.2f} {:.2f})   F1-Score: ({:.2f} {:.2f})'.format(p_test[0],p_test[1],r_test[0],r_test[1],f1_test[0],f1_test[1]))\n",
    "        plt.savefig(checkpoint_dir+model_name+'_cm_TEST.png')\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        print(f' --------------------------------------------------------->   Model Checkpoints Saved with Mean Accuracy : {best_acc:.2f}%')\n",
    "    \n",
    "        ############ STOP TRAINING ############ \n",
    "        if epoch > num_epochs*0.75 and best_acc > 95:\n",
    "            print('--------------------------------------------------------->   Ending Training, Best Checkpoint Found')\n",
    "            continue_train = False\n",
    "            break\n",
    "    \n",
    "    ms_lr_scheduler.step()\n",
    "    epoch += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFERENCE ON TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Processing Inference on Test Dataset \\n')\n",
    "# y_true_inf = []\n",
    "# y_pred_inf = []\n",
    "\n",
    "# time_start = time.time()\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for inputs, target in test_loader:\n",
    "#         inputs = inputs.to(device)\n",
    "#         target = target.to(device)\n",
    "#         model_out = model(inputs)\n",
    "#         target_out = torch.argmax(model_out, dim=1)\n",
    "#         y_true_inf.extend(target.cpu().numpy())\n",
    "#         y_pred_inf.extend(target_out.cpu().numpy())\n",
    "\n",
    "# time_end = time.time()\n",
    "\n",
    "# print('Inference Finished in {:2f} seconds'.format(time_end-time_start))\n",
    "\n",
    "# conf_mat_train = confusion_matrix(y_true_inf, y_pred_inf)\n",
    "# cm_display_train = ConfusionMatrixDisplay(confusion_matrix = conf_mat_train, display_labels = classes)\n",
    "# p_train,r_train,f1_train,_= precision_recall_fscore_support(y_true_inf, y_pred_inf, average=None)\n",
    "# cm_display_train.plot(cmap= 'Blues',colorbar=False, values_format = 'd')\n",
    "\n",
    "\n",
    "# plt.title('Preicison: ({:.2f} {:.2f})   Recall: ({:.2f} {:.2f})   F1-Score: ({:.2f} {:.2f})'.format(p_train[0],p_train[1],r_train[0],r_train[1],f1_train[0],f1_train[1]))\n",
    "\n",
    "# fname = model_name+'_cm_test.png'\n",
    "# plt.savefig(checkpoint_dir+fname)\n",
    "# plt.clf()\n",
    "# plt.cla()\n",
    "# plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFERENCE ON HORSE COUGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Processing Inference on Custom Dataset \\n')\n",
    "     \n",
    "\n",
    "class_paths = {'horse_cough_internet': \"../data/KWS_EQUINE/inference/horse_cough/\",\n",
    "               'horse_cough_stable': \"C:/Users/J_C/Desktop/DATASETS_N/horse_cough_stable/\"}\n",
    "\n",
    "sample_count = False\n",
    "y_true_inf = []\n",
    "y_pred_inf = []\n",
    "\n",
    "\n",
    "\n",
    "classes = list(class_paths.keys())\n",
    "time_start = time.time()\n",
    "with torch.no_grad():\n",
    "    for class_ix,inf_path in enumerate(list(class_paths.values())):\n",
    "        files = os.listdir(inf_path)\n",
    "        file_count = len(files)\n",
    "        inferences = []\n",
    "        \n",
    "        random.shuffle(files)\n",
    "        \n",
    "        if sample_count < file_count and type(sample_count) == int : files = files[0:sample_count]\n",
    "\n",
    "        for counter,f in enumerate(files):\n",
    "            try:\n",
    "                # CONVERT EACH AUDIO FILE TO A 128X128 ARRAY\n",
    "                data_sq = np.zeros(128)\n",
    "                data, sr = librosa.load(inf_path+f,sr = 16000)\n",
    "                data = rescale2(data,min_val=-1,max_val=1) \n",
    "                data = librosa.util.fix_length(data,size=int(128*128))\n",
    "                for index in range(0,len(data),128):\n",
    "                    data_row = data[index:index+128]\n",
    "                    data_sq = np.vstack((data_sq,data_row))\n",
    "                data_sq = data_sq[1:129]\n",
    "                data_sq = data_sq.transpose()\n",
    "                \n",
    "                # CONVERT ARRAY TO TENSOR\n",
    "                data_sq = np.expand_dims(data_sq, axis=0)\n",
    "                inputs = torch.from_numpy(data_sq.astype(np.float32))  \n",
    "                inputs.to(torch.uint8)\n",
    "                ############ INFERENCE SECTION ############\n",
    "                inputs = inputs.to(device)\n",
    "                model_out = model(inputs)\n",
    "                target_out = torch.argmax(model_out, dim=1)\n",
    "                class_output = target_out.detach().item()\n",
    "\n",
    "                y_true_inf.append(class_ix)\n",
    "                y_pred_inf.append(class_output)\n",
    "\n",
    "                \n",
    "                print('Remaining: ',(file_count-counter),'\\tTrue:', class_ix,'\\tOutput:', class_output)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "     #print('\\t\\t Test Acc: {:.2f}'.format(total_acc))\n",
    "   \n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "print('Inference Finished in {:2f} seconds'.format(time_end-time_start))\n",
    "\n",
    "conf_mat_train = confusion_matrix(y_true_inf, y_pred_inf)\n",
    "cm_display_train = ConfusionMatrixDisplay(confusion_matrix = conf_mat_train, display_labels = classes)\n",
    "p_train,r_train,f1_train,_= precision_recall_fscore_support(y_true_inf, y_pred_inf, average=None)\n",
    "cm_display_train.plot(cmap= 'Blues',colorbar=False, values_format = 'd')\n",
    "\n",
    "\n",
    "plt.title('Preicison: ({:.2f} {:.2f})   Recall: ({:.2f} {:.2f})   F1-Score: ({:.2f} {:.2f})'.format(p_train[0],p_train[1],r_train[0],r_train[1],f1_train[0],f1_train[1]))\n",
    "\n",
    "fname = model_name+'_'+str(classes[0])+'_'+str(classes[1])+'_cm_inference_horse.png'\n",
    "fname = model_name+'_cm_HORSE.png'\n",
    "plt.savefig(checkpoint_dir+fname)\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFERENCE ON WHOLE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Processing Inference on Training Dataset \\n')\n",
    "\n",
    "# LOAD DATASET FILE\n",
    "# data_file = torch.load(processed_dir+model_name+'.pt') # (data, class, type)\n",
    "processed_dir = '../data/KWS_EQUINE/processed'\n",
    "data_file =torch.load(processed_dir+'/dataset2.pt')\n",
    "\n",
    "y_true_inf = data_file[1].cpu().numpy()\n",
    "y_pred_inf = []\n",
    "file_count = len(y_true_inf)\n",
    "\n",
    "time_start = time.time()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for counter,val in enumerate((data_file[0])):\n",
    "        val =val[None,:]\n",
    "        inputs = val.to(torch.float)\n",
    "        ############ INFERENCE SECTION ############\n",
    "        inputs = inputs.to(device)\n",
    "        model_out = model(inputs)\n",
    "        target_out = torch.argmax(model_out, dim=1)\n",
    "        \n",
    "        class_output = target_out.detach().item()\n",
    "\n",
    "        print('Remaining: ',(file_count-counter),'\\tTrue:', y_true_inf[counter],'\\tOutput:', class_output)\n",
    "        y_pred_inf.append(class_output)\n",
    "\n",
    "     #print('\\t\\t Test Acc: {:.2f}'.format(total_acc))\n",
    "   \n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "print('Inference Finished in {:2f} seconds'.format(time_end-time_start))\n",
    "\n",
    "conf_mat_train = confusion_matrix(y_true_inf, y_pred_inf)\n",
    "cm_display_train = ConfusionMatrixDisplay(confusion_matrix = conf_mat_train, display_labels = classes)\n",
    "p_train,r_train,f1_train,_= precision_recall_fscore_support(y_true_inf, y_pred_inf, average=None)\n",
    "cm_display_train.plot(cmap= 'Blues',colorbar=False, values_format = 'd')\n",
    "\n",
    "\n",
    "plt.title('Preicison: ({:.2f} {:.2f})   Recall: ({:.2f} {:.2f})   F1-Score: ({:.2f} {:.2f})'.format(p_train[0],p_train[1],r_train[0],r_train[1],f1_train[0],f1_train[1]))\n",
    "\n",
    "fname = model_name+'_cm_WHOLE.png'\n",
    "plt.savefig(checkpoint_dir+fname)\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33335497366de2c65b60bad2619bdb398d3af58569807f2e4d877bfe78d46b65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
