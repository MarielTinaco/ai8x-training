{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#\n",
    "# Copyright (C) 2022 Maxim Integrated Products, Inc. All Rights Reserved.\n",
    "#\n",
    "# Maxim Integrated Products, Inc. Default Copyright Notice:\n",
    "# https://www.maximintegrated.com/en/aboutus/legal/copyrights.html\n",
    "#\n",
    "###################################################################################################\n",
    "\n",
    "## IMPORTS\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "import distiller\n",
    "\n",
    "## FOR TENSOR BOARD\n",
    "try:\n",
    "    import tensorboard  # pylint: disable=import-error\n",
    "    import tensorflow  # pylint: disable=import-error\n",
    "    tensorflow.io.gfile = tensorboard.compat.tensorflow_stub.io.gfile\n",
    "except (ModuleNotFoundError, AttributeError):\n",
    "    pass\n",
    "\n",
    "import torchnet.meter as tnt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import distiller.apputils as apputils\n",
    "from distiller.data_loggers import PythonLogger, TensorBoardLogger\n",
    "\n",
    "## PATH FOR MODELS AND DATASET\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'models'))\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'datasets'))\n",
    "\n",
    "from unetnilm.metrics import get_results_summary\n",
    "from datasets import nilm\n",
    "import ai8x\n",
    "mod = importlib.import_module(\"ai87net-unetnilm\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "msglogger = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fn = nilm.ukdale_get_datasets\n",
    "data_path = \"../data/NILM/\"\n",
    "batch_size = 8\n",
    "workers = 5\n",
    "validation_split = 0.1\n",
    "deterministic = True\n",
    "dataset_name = \"ukdale\"\n",
    "appliance_data = {\n",
    "    \"kettle\": {\n",
    "        \"mean\": 700,\n",
    "        \"std\": 1000,\n",
    "        'window':10,\n",
    "        'on_power_threshold': 2000,\n",
    "        'max_on_power': 3998\n",
    "    },\n",
    "    \"fridge\": {\n",
    "        \"mean\": 200,\n",
    "        \"std\": 400,\n",
    "        \"window\":50,\n",
    "        'on_power_threshold': 50,\n",
    "    },\n",
    "    \"dish washer\": {\n",
    "        \"mean\": 700,\n",
    "        \"std\": 700,\n",
    "        \"window\":50,\n",
    "        'on_power_threshold': 10\n",
    "    },\n",
    "    \"washer dryer\": {\n",
    "        \"mean\": 400,\n",
    "        \"std\": 700,\n",
    "        \"window\":50,\n",
    "        'on_power_threshold': 20,\n",
    "        'max_on_power': 3999\n",
    "    },\n",
    "    \"microwave\": {\n",
    "        \"mean\": 500,\n",
    "        \"std\": 800,\n",
    "        \"window\":10,\n",
    "        'on_power_threshold': 200,\n",
    "    },\n",
    "}\n",
    "appliances = list(appliance_data.keys())\n",
    "\n",
    "## Variable Declaration for MSG Logger\n",
    "log_prefix = \"ukdale-train\"\n",
    "log_dir = \"../logs/\"\n",
    "dataset_name = \"ukdale\"\n",
    "num_classes = 5\n",
    "model_name = \"cnn1dnilm\"\n",
    "seq_len = 100\n",
    "lr = 1e-4\n",
    "\n",
    "## Variable Declaration for Model\n",
    "quantiles = [0.0025,0.1, 0.5, 0.9, 0.975]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "        def __init__(self, act_mode_8bit):\n",
    "                self.act_mode_8bit = act_mode_8bit\n",
    "                self.truncate_testset = False\n",
    "\n",
    "def count_params(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params\n",
    "\n",
    "class NormDen:\n",
    "        def __init__(self, mini, maxi):\n",
    "               self.mini = mini\n",
    "               self.maxi = maxi\n",
    "\n",
    "        def normalize(self, data):\n",
    "                data = (data - self.mini) / (self.maxi - self.mini)\n",
    "                return data.sub(0.5).mul(256.).round().clamp(min=-128, max=127).div(128.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSG Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msglogger = apputils.config_pylogger('logging.conf', log_prefix,\n",
    "                                        log_dir)\n",
    "\n",
    "pylogger = PythonLogger(msglogger, log_1d=True)\n",
    "all_loggers = [pylogger]\n",
    "\n",
    "# tensorboard\n",
    "tflogger = TensorBoardLogger(msglogger.logdir, log_1d=True, comment='_'+dataset_name)\n",
    "\n",
    "tflogger.tblogger.writer.add_text('Command line', \"args ---\")\n",
    "\n",
    "msglogger.info('dataset_name:%s\\ndataset_fn=%s\\nnum_classes=%d\\nmodel_name=%s\\seq_len=%s\\nbatch_size=%d\\nvalidation_split=%s\\nlr=%f',\n",
    "                dataset_name,dataset_fn,num_classes,model_name,seq_len,batch_size,validation_split,lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(act_mode_8bit=False)\n",
    "train_set, test_set, val_set = dataset_fn((data_path, args), load_train=True, load_test=True, load_val=True)\n",
    "train_set.visualize_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, _ = apputils.get_data_loaders(\n",
    "        dataset_fn, (data_path,args), batch_size,\n",
    "        workers, validation_split, deterministic,1, 1, 1)\n",
    "msglogger.info('Dataset sizes:\\n\\ttraining=%d\\n\\tvalidation=%d\\n\\ttest=%d',\n",
    "                   len(train_loader.sampler), len(val_loader.sampler), len(test_loader.sampler))\n",
    "msglogger.info('Augmentations:%s',train_loader.dataset.transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path Initialization\n",
    "pth_path = '../logs/ukdale-train___2024.02.20-031228_golden/'\n",
    "pth_best = os.path.join(os.path.dirname(pth_path), 'cnn1dnilm_best.pth.tar')\n",
    "pth_checkpoint = os.path.join(os.path.dirname(pth_path), 'cnn1dnilm_checkpoint.pth.tar')\n",
    "\n",
    "## Class for Args\n",
    "class Args:\n",
    "    def __init__(self, act_mode_8bit):\n",
    "        self.act_mode_8bit = act_mode_8bit\n",
    "        self.truncate_testset = False\n",
    "\n",
    "args = Args(act_mode_8bit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## device setup\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))\n",
    "\n",
    "ai8x.set_device(device=85, simulate=False, round_avg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import ai8x\n",
    "\n",
    "class AI85UNetNILM(nn.Module):\n",
    "    \"\"\"\n",
    "    Large size UNet model. This model also enables the use of folded data.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_classes=4,         # in_size\n",
    "            num_channels=48,        #\n",
    "            dimensions=(88, 88),  # pylint: disable=unused-argument\n",
    "            dropout=0.1,\n",
    "            bias=True,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.fold_ratio = fold_ratio\n",
    "        # self.num_classes = num_classes\n",
    "        # self.num_final_channels = num_classes * fold_ratio * fold_ratio\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.prep0 = ai8x.FusedConv1dBNReLU(num_channels, 64, 1, stride=1, padding=0,\n",
    "                                            bias=bias, batchnorm='NoAffine', **kwargs)\n",
    "        self.prep1 = ai8x.FusedConv1dBNReLU(64, 64, 1, stride=1, padding=0,\n",
    "                                            bias=bias, batchnorm='NoAffine', **kwargs)\n",
    "        self.prep2 = ai8x.FusedConv1dBNReLU(64, 32, 1, stride=1, padding=0,\n",
    "                                            bias=bias, batchnorm='NoAffine', **kwargs)\n",
    "\n",
    "        self.enc1 = ai8x.FusedConv1dBNReLU(32, 8, 3, stride=1, padding=1,\n",
    "                                           bias=bias, batchnorm='NoAffine', **kwargs)\n",
    "        self.enc2 = ai8x.FusedMaxPoolConv1dBNReLU(8, 28, 3, stride=1, padding=1,\n",
    "                                                  bias=bias, batchnorm='NoAffine', **kwargs)\n",
    "        self.enc3 = ai8x.FusedMaxPoolConv1dBNReLU(28, 56, 3, stride=1, padding=1,\n",
    "                                                  bias=bias, batchnorm='NoAffine', **kwargs)\n",
    "\n",
    "        self.bneck = ai8x.FusedMaxPoolConv1dBNReLU(56, 112, 3, stride=1, padding=1,\n",
    "                                                   bias=bias, batchnorm='NoAffine', **kwargs)\n",
    "\n",
    "        self.upconv3 = ai8x.ConvTranspose2d(112, 56, 3, stride=2, padding=1)\n",
    "        self.dec3 = ai8x.FusedConv1dBNReLU(112, 56, 3, stride=1, padding=1,\n",
    "                                           bias=bias, batchnorm='NoAffine', **kwargs)\n",
    "\n",
    "        # self.upconv2 = nn.ConvTranspose1d(56, 28, 3, stride=2, padding=1)\n",
    "        # self.dec2 = ai8x.FusedConv1dBNReLU(56, 28, 3, stride=1, padding=1,\n",
    "        #                                    bias=bias, batchnorm='NoAffine', **kwargs)\n",
    "\n",
    "        # self.upconv1 = nn.ConvTranspose1d(28, 8, 3, stride=2, padding=1)\n",
    "        # self.dec1 = ai8x.FusedConv1dBNReLU(16, 48, 3, stride=1, padding=1,\n",
    "        #                                    bias=bias, batchnorm='NoAffine', **kwargs)\n",
    "\n",
    "        # self.dec0 = ai8x.FusedConv1dBNReLU(48, 64, 3, stride=1, padding=1,\n",
    "        #                                    bias=bias, batchnorm='NoAffine', **kwargs)\n",
    "\n",
    "        # self.conv_p1 = ai8x.FusedConv1dBNReLU(64, 64, 1, stride=1, padding=0,\n",
    "        #                                       bias=bias, batchnorm='NoAffine', **kwargs)\n",
    "        # self.conv_p2 = ai8x.FusedConv1dBNReLU(64, 64, 1, stride=1, padding=0,\n",
    "        #                                       bias=bias, batchnorm='NoAffine', **kwargs)\n",
    "        # self.conv_p3 = ai8x.Conv1d(64, 64, 1, stride=1, padding=0,\n",
    "        #                                   bias=bias, batchnorm='NoAffine', **kwargs)\n",
    "\n",
    "        # self.conv = ai8x.Conv1d(64, self.num_final_channels, 1, stride=1, padding=0,\n",
    "        #                             bias=bias, batchnorm='NoAffine', **kwargs)\n",
    "\n",
    "    def forward(self, x):  # pylint: disable=arguments-differ\n",
    "        \"\"\"Forward prop\"\"\"\n",
    "        # Run CNN\n",
    "        B = x.size(0)\n",
    "        x = x.permute(0,2,1)\n",
    "\n",
    "        x = self.prep0(x)\n",
    "        # x = self.prep1(x)\n",
    "        # x = self.prep2(x)\n",
    "        \n",
    "        # # Encoder\n",
    "        # enc1 = self.enc1(x)                    # 8x(dim1)x(dim2)\n",
    "        # enc2 = self.enc2(enc1)                 # 28x(dim1/2)x(dim2/2)\n",
    "        # enc3 = self.enc3(enc2)                 # 56x(dim1/4)x(dim2/4)\n",
    "\n",
    "        # bottleneck = self.bneck(enc3)          # 112x(dim1/8)x(dim2/8)\n",
    "\n",
    "        # dec3 = self.upconv3(bottleneck)        # 56x(dim1/4)x(dim2/4)\n",
    "        # dec3 = torch.cat((dec3, enc3), dim=1)  # 112x(dim1/4)x(dim2/4)\n",
    "        # dec3 = self.dec3(dec3)                 # 56x(dim1/4)x(dim2/4)\n",
    "        # dec2 = self.upconv2(dec3)              # 28x(dim1/2)x(dim2/2)\n",
    "        # dec2 = torch.cat((dec2, enc2), dim=1)  # 56(dim1/2)x(dim2/2)\n",
    "        # dec2 = self.dec2(dec2)                 # 28x(dim1/2)x(dim2/2)\n",
    "        # dec1 = self.upconv1(dec2)              # 8x(dim1)x(dim2)\n",
    "        # dec1 = torch.cat((dec1, enc1), dim=1)  # 16x(dim1)x(dim2)\n",
    "        # dec1 = self.dec1(dec1)                 # 48x(dim1)x(dim2)\n",
    "        # dec0 = self.dec0(dec1)                 # 64x(dim1)x(dim2)\n",
    "\n",
    "        # dec0 = self.conv_p1(dec0)\n",
    "        # dec0 = self.conv_p2(dec0)\n",
    "        # dec0 = self.conv_p3(dec0)\n",
    "        # dec0 = self.conv(dec0)                 # num_final_channelsx(dim1)x(dim2)\n",
    "\n",
    "        # return dec0\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class AI85CNN1DNiLM(nn.Module):\n",
    "    def __init__(self, in_size=1, \n",
    "                 output_size=5,\n",
    "                 d_model=64,\n",
    "                 dropout=0.1, \n",
    "                 seq_len=99,  \n",
    "                 n_layers=5, \n",
    "                 n_quantiles=3, \n",
    "                 pool_filter=16,\n",
    "                 device=\"cuda:0\"):\n",
    "        super(AI85CNN1DNiLM, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.enc_net = Encoder(n_channels=in_size, n_kernels=d_model, n_layers=n_layers, seq_size=seq_len, device=device)\n",
    "        self.pool_filter = pool_filter\n",
    "        self.mlp_layer = MLPLayer(in_size=d_model*pool_filter, hidden_arch=[1024], output_size=None)\n",
    "        self.n_quantiles = n_quantiles\n",
    "        \n",
    "        self.fc_out_state  = ai8x.Linear(1024, output_size*2, bias=True)\n",
    "        self.fc_out_power  = ai8x.Linear(1024, output_size*n_quantiles, bias=True)\n",
    "        nn.init.xavier_normal_(self.fc_out_state.op.weight)\n",
    "        nn.init.xavier_normal_(self.fc_out_power.op.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0,2,1)\n",
    "        B = x.size(0)\n",
    "        print(f\"X: max: {x.max()} min: {x.min()}\")\n",
    "        conv_out = self.dropout(self.enc_net(x))\n",
    "        print(f\"ENC_OUT: max: {conv_out.max()} min: {conv_out.min()}\")\n",
    "        conv_out = F.adaptive_avg_pool1d(conv_out, self.pool_filter)\n",
    "        conv_out = conv_out.reshape(x.size(0), -1)\n",
    "        print(f\"AVG_POOL_OUT: max: {conv_out.max()} min: {conv_out.min()}\")\n",
    "        mlp_out  = self.dropout(self.mlp_layer(conv_out))\n",
    "        print(f\"MLP_OUT: max: {mlp_out.max()} min: {mlp_out.min()}\")\n",
    "        states_logits   = self.fc_out_state(mlp_out).reshape(B, 2, -1)\n",
    "        power_logits    = self.fc_out_power(mlp_out)\n",
    "        if self.n_quantiles>1:\n",
    "            power_logits = power_logits.reshape(B, self.n_quantiles, -1)\n",
    "        print(f\"STATES: max: {states_logits.max()} min: {states_logits.min()}\")\n",
    "        print(f\"POWER: max: {power_logits.max()} min: {power_logits.min()}\")\n",
    "        return states_logits, power_logits\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_channels=10, \n",
    "                 n_kernels=16, \n",
    "                 n_layers=3, \n",
    "                 seq_size=50,\n",
    "                 device=\"cuda:0\"):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.feat_size = (seq_size-1) // 2**n_layers +1\n",
    "        self.feat_dim = self.feat_size * n_kernels\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            *([Conv1D(n_channels, n_kernels // 2**(n_layers-1), activation=\"ReLU\", pooling=\"Max\", last=False, device=device)] +\n",
    "              [Conv1D(n_kernels//2**(n_layers-l),\n",
    "                         n_kernels//2**(n_layers-l-1), activation=\"ReLU\", pooling=\"Max\", last=False, device=device)\n",
    "               for l in range(1, n_layers-1)] +\n",
    "              [Conv1D(n_kernels // 2, n_kernels, activation=\"ReLU\", pooling=\"Max\", last=True, device=device)])\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        assert len(x.size())==3\n",
    "        feats = self.conv_stack(x)\n",
    "        return feats\n",
    "\n",
    "class MLPLayer(nn.Module):\n",
    "    def __init__(self, in_size, \n",
    "                 hidden_arch=[128/2, 512/2, 1024/2], \n",
    "                 output_size=None):\n",
    "        \n",
    "        super(MLPLayer, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.output_size = output_size\n",
    "        layer_sizes = [in_size] + [x for x in hidden_arch]\n",
    "        self.layers = []\n",
    "        \n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            layer = ai8x.FusedLinearReLU(layer_sizes[i], layer_sizes[i+1])\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        if output_size is not None:\n",
    "            layer = ai8x.FusedLinearReLU(layer_sizes[-1], output_size)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.init_weights()\n",
    "        self.mlp_network =  nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.mlp_network(z)\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for layer in self.layers:\n",
    "            try:\n",
    "                if isinstance(layer, ai8x.FusedLinearReLU):\n",
    "                    nn.utils.weight_norm(layer)\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "            except: pass\n",
    "\n",
    "\n",
    "class Conv1D(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 num_channels,\n",
    "                 num_kernels,\n",
    "                 kernel_size=3,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 pooling=\"Max\",\n",
    "                 activation=\"ReLU\",\n",
    "                 batchnorm=\"NoAffine\",\n",
    "                 last=False,\n",
    "                 device=\"cuda:0\",\n",
    "                 **kwargs):\n",
    "        super(Conv1D, self).__init__()\n",
    "        \n",
    "        if not last:\n",
    "            if pooling == \"Max\":\n",
    "                if activation == \"ReLU\":\n",
    "                    self.net = ai8x.FusedMaxPoolConv1dBNReLU(in_channels=num_channels,\n",
    "                                                             out_channels=num_kernels,\n",
    "                                                             kernel_size=kernel_size,\n",
    "                                                             stride=stride,\n",
    "                                                             padding=padding,\n",
    "                                                             bias=True,\n",
    "                                                             batchnorm=\"NoAffine\",\n",
    "                                                             **kwargs)\n",
    "                elif activation == \"Abs\":\n",
    "                    self.net = ai8x.FusedMaxPoolConv1dBNAbs(in_channels=num_channels,\n",
    "                                                            out_channels=num_kernels,\n",
    "                                                            kernel_size=kernel_size,\n",
    "                                                            stride=stride,\n",
    "                                                            padding=padding,\n",
    "                                                            bias=True,\n",
    "                                                            batchnorm=\"NoAffine\",\n",
    "                                                            **kwargs)\n",
    "                else:\n",
    "                    self.net = ai8x.FusedMaxPoolConv1d(in_channels=num_channels,\n",
    "                                                       out_channels=num_kernels,\n",
    "                                                       kernel_size=kernel_size,\n",
    "                                                       stride=stride,\n",
    "                                                       padding=padding,\n",
    "                                                       batchnorm=batchnorm,\n",
    "                                                       **kwargs)\n",
    "            elif pooling == \"Avg\":\n",
    "                if activation == \"ReLU\":\n",
    "                    self.net = ai8x.FusedAvgPoolConv1dBNReLU(in_channels=num_channels,\n",
    "                                                             out_channels=num_kernels,\n",
    "                                                             kernel_size=kernel_size,\n",
    "                                                             stride=stride,\n",
    "                                                             padding=padding,\n",
    "                                                             bias=True,\n",
    "                                                             batchnorm=\"NoAffine\",\n",
    "                                                             **kwargs)\n",
    "                elif activation == \"Abs\":\n",
    "                    self.net = ai8x.FusedAvgPoolConv1dBNAbs(in_channels=num_channels,\n",
    "                                                            out_channels=num_kernels,\n",
    "                                                            kernel_size=kernel_size,\n",
    "                                                            stride=stride,\n",
    "                                                            padding=padding,\n",
    "                                                            bias=True,\n",
    "                                                            batchnorm=\"NoAffine\",\n",
    "                                                            **kwargs)\n",
    "                else:\n",
    "                    self.net = ai8x.FusedAvgPoolConv1d(in_channels=num_channels,\n",
    "                                                       out_channels=num_kernels,\n",
    "                                                       kernel_size=kernel_size,\n",
    "                                                       stride=stride,\n",
    "                                                       padding=padding,\n",
    "                                                       batchnorm=batchnorm,\n",
    "                                                    **kwargs)\n",
    "            else:\n",
    "                if activation == \"ReLU\":\n",
    "                    self.net = ai8x.FusedConv1dBNReLU(in_channels=num_channels,\n",
    "                                                      out_channels=num_kernels,\n",
    "                                                      kernel_size=kernel_size,\n",
    "                                                      stride=stride,\n",
    "                                                      padding=padding,\n",
    "                                                      bias=True,\n",
    "                                                      batchnorm=\"NoAffine\",\n",
    "                                                      **kwargs)\n",
    "                elif activation == \"Abs\":\n",
    "                    self.net = ai8x.FusedConv1dBNAbs(in_channels=num_channels,\n",
    "                                                    out_channels=num_kernels,\n",
    "                                                    kernel_size=kernel_size,\n",
    "                                                    stride=stride,\n",
    "                                                    padding=padding,\n",
    "                                                    bias=True,\n",
    "                                                    batchnorm=\"NoAffine\",\n",
    "                                                    **kwargs)\n",
    "                else:\n",
    "                    self.net = ai8x.FusedAvgPoolConv1d(in_channels=num_channels,\n",
    "                                                       out_channels=num_kernels,\n",
    "                                                       kernel_size=kernel_size,\n",
    "                                                       stride=stride,\n",
    "                                                       padding=padding,\n",
    "                                                       batchnorm=batchnorm,\n",
    "                                                       **kwargs\n",
    "                    )\n",
    "        else:\n",
    "            if pooling == \"Max\":\n",
    "                self.net = ai8x.FusedMaxPoolConv1d(in_channels=num_channels,\n",
    "                                                   out_channels=num_kernels,\n",
    "                                                   kernel_size=kernel_size,\n",
    "                                                   stride=stride,\n",
    "                                                   padding=padding,\n",
    "                                                   batchnorm=batchnorm,\n",
    "                                                   **kwargs\n",
    "                )\n",
    "            elif pooling == \"Avg\":\n",
    "                self.net = ai8x.FusedAvgPoolConv1d(\n",
    "                    in_channels=num_channels,\n",
    "                    out_channels=num_kernels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                    batchnorm=batchnorm,\n",
    "                    **kwargs\n",
    "                )\n",
    "            else:\n",
    "                self.net = ai8x.Conv1d(\n",
    "                    in_channels=num_channels,\n",
    "                    out_channels=num_kernels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                    batchnorm=batchnorm,\n",
    "                    **kwargs\n",
    "                )\n",
    "\n",
    "        nn.utils.weight_norm(self.net.op.to(device))    \n",
    "        nn.init.xavier_uniform_(self.net.op.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mod.AI85CNN1DNiLM(in_size=1, output_size=5, dropout=0.2, n_quantiles=len(quantiles), pool_filter=16, device=device)\n",
    "msglogger.info('model: %s',model)\n",
    "\n",
    "model = apputils.load_lean_checkpoint(model, pth_checkpoint, model_device=device)\n",
    "ai8x.update_model(model)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_workers = 5\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers)\n",
    "\n",
    "max_in_batch = 0\n",
    "min_in_batch = 100\n",
    "\n",
    "train_batch_with_max = 0\n",
    "test_batch_with_max = 0\n",
    "val_batch_with_max = 0\n",
    "\n",
    "batch_select = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index =365\n",
    "data = val_set[index]\n",
    "input_data = data[0]\n",
    "input_data = input_data[None].to(device)\n",
    "states, target = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index =365\n",
    "data = val_set[index]\n",
    "input_data = torch.unsqueeze(data[0], dim=0).to(device)\n",
    "states, target = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch_end(outputs):\n",
    "        \n",
    "        # appliance_data = {'fridge': {'window': 50, 'mean': 40.158577, 'std': 53.56288}, 'washer dryer': {'window': 50, 'mean': 27.768433, 'std': 212.51971}, 'kettle': {'window': 10, 'mean': 16.753872, 'std': 191.05873}, 'dish washer': {'window': 50, 'mean': 27.384077, 'std': 239.23492}, 'microwave': {'window': 10, 'mean': 8.35921, 'std': 105.1099}}\n",
    "        pred_power = torch.cat([x['pred_power'] for x in outputs], 0).cpu().numpy()\n",
    "        pred_state = torch.cat([x['pred_state'] for x in outputs], 0).cpu().numpy().astype(np.int32)\n",
    "        power = torch.cat([x['power'] for x in outputs], 0).cpu().numpy()\n",
    "        state = torch.cat([x['state'] for x in outputs], 0).cpu().numpy().astype(np.int32)\n",
    "\n",
    "        for idx, app in enumerate(appliances):\n",
    "                power[:,idx] = (power[:, idx] * appliance_data[app]['std']) + appliance_data[app]['std']\n",
    "                if len(quantiles)>=2:\n",
    "                        pred_power[:,:, idx] = (pred_power[:,:, idx] * appliance_data[app]['std']) + appliance_data[app]['std']\n",
    "                        pred_power[:,:, idx] = np.where(pred_power[:,:, idx]<0, 0, pred_power[:,:, idx])\n",
    "                else:\n",
    "                        pred_power[:, idx] = (pred_power[:, idx] * appliance_data[app]['std']) + appliance_data[app]['std']\n",
    "                        pred_power[:, idx] = np.where(pred_power[:, idx]<0, 0, pred_power[:, idx])    \n",
    "\n",
    "        if len(quantiles)>=2:\n",
    "                idx = len(quantiles)//2\n",
    "                y_pred = pred_power[:,idx]\n",
    "        else:\n",
    "                y_pred = pred_power \n",
    "                \n",
    "        per_app_results, avg_results = get_results_summary(state, pred_state, \n",
    "                                                                        power, y_pred,\n",
    "                                                                        appliances, \n",
    "                                                                        dataset_name.upper())  \n",
    "        logs = {\"pred_power\":pred_power, \n",
    "                \"pred_state\":pred_state, \n",
    "                \"power\":power, \n",
    "                \"state\":state,  \n",
    "                'app_results':per_app_results, \n",
    "                'avg_results':avg_results} \n",
    "        \n",
    "        return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_step, (inputs, target, states) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "                inputs, target, states =  inputs.to(device), target.to(device), states.to(device)\n",
    "                logits, pred_power  = model(inputs)\n",
    "\n",
    "                prob, pred_state = torch.max(F.softmax(logits, 1), 1)\n",
    "                if len(quantiles)>1:\n",
    "                        prob=prob.unsqueeze(1).expand_as(pred_power)\n",
    "                \n",
    "                logs = {\"pred_power\":pred_power, \"pred_state\":pred_state, \"power\":target, \"state\":states}\n",
    "\n",
    "                outputs.append(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = test_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_power=model_result['pred_power']\n",
    "pred_state=model_result['pred_state']\n",
    "power=model_result['power']\n",
    "state=model_result['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 79250\n",
    "end = start + 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p_unet = model_result['pred_power'][start:end]\n",
    "y_t_unet = model_result['power'][start:end]\n",
    "z_t_unet = model_result['state'][start:end]\n",
    "z_p_unet = model_result['pred_state'][start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors =[plt.cm.Blues(0.6), plt.cm.Reds(0.4), plt.cm.Greens(0.6), '#ffcc99', plt.cm.Greys(0.6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appliance_labels={'kettle':\"KT\", 'fridge':\"FRZ\", 'dish washer':\"DW\", 'washer dryer':\"WM\", 'microwave':\"MW\"}\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "for i, app in enumerate(list(appliance_data.keys())):\n",
    "    plt.plot(y_t_unet[:,i]*z_t_unet[:,i], label=appliance_labels[app], color=colors[i])\n",
    "    #plt.plot(y_p_unet[:,2,i]t label=appliance_labels[app], color=colors[i], linestyle=\"--\")\n",
    "plt.ylabel(\"Power $W$\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appliance_labels={'kettle':\"KT\", 'fridge':\"FRZ\", 'dish washer':\"DW\", 'washer dryer':\"WM\", 'microwave':\"MW\"}\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "for i, app in enumerate(list(appliance_data.keys())):\n",
    "    # plt.plot(y_p_unet[:,2,i], label=appliance_labels[app], color=colors[i], linestyle=\"--\")\n",
    "    plt.plot(y_p_unet[:,2,i]*z_p_unet[:,i], label=appliance_labels[app], color=colors[i], linestyle=\"--\")\n",
    "plt.ylabel(\"Predicted Power $W$\")\n",
    "plt.ylim(0, 2500)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 79450\n",
    "end = start + 200\n",
    "\n",
    "y_p_unet = model_result['pred_power'][start:end]\n",
    "y_t_unet = model_result['power'][start:end]\n",
    "z_t_unet = model_result['state'][start:end]\n",
    "z_p_unet = model_result['pred_state'][start:end]\n",
    "\n",
    "colors =[plt.cm.Blues(0.6), plt.cm.Reds(0.4), plt.cm.Greens(0.6), '#ffcc99', plt.cm.Greys(0.6)]\n",
    "i = 1\n",
    "app = 'fridge'\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "\n",
    "plt.plot(y_t_unet[:,i]*z_t_unet[:,i], label=f\"TRUE: {appliance_labels[app]}\", color=colors[i])\n",
    "plt.plot(y_p_unet[:,2,i]*z_p_unet[:,i], label=f\"PRED: {appliance_labels[app]}\", color=colors[-1], linestyle=\"--\")\n",
    "plt.ylabel(\"True Power vs. Predicted Power $W$\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "753beada7fab6a3ef0fbaf27a665d05d016c9908abab69e0598c961cccc7799f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
