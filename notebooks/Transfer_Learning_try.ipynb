{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "from distiller import apputils\n",
    "import ai8x\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "kws20 = importlib.import_module(\"datasets.kws20-horsecough\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "import librosa\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# FIX SEED FOR REPRODUCIBILITY\n",
    "seed = 69\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(audio, min_val=-1,max_val=1):\n",
    "    sig = audio\n",
    "    mean = np.average(sig)\n",
    "\n",
    "    sig = sig-mean # REMOVE DC COMPONENT\n",
    "\n",
    "    sig_max = np.max(sig)\n",
    "    sig_min = np.min(sig)\n",
    "\n",
    "    if sig_max >= np.abs(sig_min):\n",
    "        sig_scaled = sig/sig_max\n",
    "    else:\n",
    "        sig_scaled = sig/np.abs(sig_min)\n",
    "\n",
    "    return sig_scaled\n",
    "\n",
    "def rescale2(audio, min_val=-1,max_val=1):\n",
    "    scaler = MinMaxScaler(feature_range=(min_val,max_val))\n",
    "    audio = audio.reshape(-1,1)\n",
    "    scaler.fit(audio)\n",
    "    scaled = np.array(scaler.transform(audio))\n",
    "    \n",
    "    return scaled[:,0]\n",
    "\n",
    "\n",
    "def plot_confusion(y_true, y_pred, classes):\n",
    "    cf_matrix = confusion_matrix(y_true = y_true, y_pred = y_pred, labels =list(range(len(classes))))\n",
    "    print(cf_matrix)\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0,1], [0,1], 'r--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "def custom_dataloader(data, train_idx, val_idx, test_idx, batch_size = 2048):\n",
    "    data_file = data\n",
    "    x = np.asarray(data_file[0][test_idx])\n",
    "    y = np.squeeze(np.asarray(data_file[1][test_idx]))\n",
    "    test_set = TensorDataset(torch.Tensor(x),torch.Tensor(y).to(dtype =torch.int64))\n",
    "    test_loader = DataLoader(test_set,batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "    x = np.asarray(data_file[0][val_idx])\n",
    "    y = np.squeeze(np.asarray(data_file[1][val_idx]))\n",
    "    val_set = TensorDataset(torch.Tensor(x),torch.Tensor(y).to(dtype =torch.int64))\n",
    "    val_loader = DataLoader(val_set,batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "    x = np.asarray(data_file[0][train_idx])\n",
    "    y = np.squeeze(np.asarray(data_file[1][train_idx]))\n",
    "    train_set = TensorDataset(torch.Tensor(x),torch.Tensor(y).to(dtype =torch.int64))\n",
    "    train_loader = DataLoader(train_set,batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader,val_loader,test_loader\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Checkpoint, Plot, and Dataset Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL AND DATASET NAME \n",
    "model_name = 'human_others'\n",
    "classes = [\"combined\",'human_cough']\n",
    "checkpoint_dir = './checkpoints/'+model_name+'/'\n",
    "\n",
    "indexer = 0\n",
    "while os.path.exists(checkpoint_dir):\n",
    "    model_name = 'human_others'\n",
    "    model_name = model_name + '_' + str(indexer)\n",
    "    checkpoint_dir = './checkpoints/'+model_name+'/'\n",
    "    indexer += 1\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "print('Model Name: ', model_name)\n",
    "print('Classes: ', classes)\n",
    "print('Checkpoint Dir: ', checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = Path(\"../data/KWS_EQUINE/raw/\")\n",
    "class_file_count = {}\n",
    "\n",
    "class_dirs = [d for d in raw_data_path.iterdir() if d.is_dir() and (d.stem != \"__combinedkws\") and (d.stem != \"__combined_others\") and (d.stem != \"__human_cough\")]\n",
    "\n",
    "for d in class_dirs:\n",
    "    print(d)\n",
    "    class_file_count[d] = len(list(d.iterdir()))\n",
    "\n",
    "min_file_count = float(min(class_file_count.values()))\n",
    "\n",
    "# Calculate weights\n",
    "class_weights = []\n",
    "for d in class_dirs:\n",
    "    class_file_count[d] = min_file_count / class_file_count[d]\n",
    "    print(f\"{d.stem}: {round(class_file_count[d], 7)}\")\n",
    "    class_weights.append(round(class_file_count[d], 7))\n",
    "print('Weights: ',class_weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Processed Datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 4096\n",
    "\n",
    "processed_data_path = Path(\"../data/KWS_EQUINE/processed/\")\n",
    "fname = model_name+'.pt'\n",
    "_, _, _, _ = apputils.get_data_loaders(kws20.KWS_HORSE_TF_get_datasets,(\"../data\", True), \n",
    "                                       train_batch_size, 4, validation_split=0.1,\n",
    "                                       download=True, fname = fname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 4096\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    cpu = False\n",
    "else:\n",
    "     device = torch.device('cpu')\n",
    "     cpu = True\n",
    "\n",
    "print('Running on device: {}'.format(torch.cuda.get_device_name()))\n",
    "\n",
    "processed_dir = \"../data/KWS_EQUINE/processed/\"\n",
    "\n",
    "test_ratio = 0.1\n",
    "val_ratio = 0.1\n",
    "\n",
    "if os.path.exists(processed_dir+fname):\n",
    "     data_file = torch.load(processed_dir+fname) # (data, class, type)\n",
    "     len_dataset = len(data_file[0])\n",
    "\n",
    "     train_indices, test_indices = train_test_split(np.arange(len_dataset),test_size=test_ratio, train_size=1-test_ratio)\n",
    "     train_indices, val_indices = train_test_split(train_indices,test_size=val_ratio/(1-test_ratio), train_size=1-(val_ratio/(1-test_ratio)))\n",
    "\n",
    "     train_loader,val_loader,test_loader = custom_dataloader(data=data_file, train_idx = train_indices,\n",
    "     val_idx = val_indices, test_idx = test_indices, batch_size = train_batch_size)\n",
    "\n",
    "     # x = np.asarray(data_file[0][test_indices])\n",
    "     # y = np.squeeze(np.asarray(data_file[1][test_indices]))\n",
    "\n",
    "     # test_set = TensorDataset(torch.Tensor(x),torch.Tensor(y).to(dtype =torch.int64))\n",
    "     # test_loader = DataLoader(test_set,batch_size=train_batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "     # x = np.asarray(data_file[0][val_indices])\n",
    "     # y = np.squeeze(np.asarray(data_file[1][val_indices]))\n",
    "\n",
    "     # val_set = TensorDataset(torch.Tensor(x),torch.Tensor(y).to(dtype =torch.int64))\n",
    "     # val_loader = DataLoader(val_set,batch_size=train_batch_size, num_workers=4, pin_memory=True)\n",
    "     \n",
    "     # x = np.asarray(data_file[0][train_indices])\n",
    "     # y = np.squeeze(np.asarray(data_file[1][train_indices]))\n",
    "\n",
    "     # train_set = TensorDataset(torch.Tensor(x),torch.Tensor(y).to(dtype =torch.int64))\n",
    "     # train_loader = DataLoader(train_set,batch_size=train_batch_size, num_workers=4, pin_memory=True)\n",
    "     \n",
    "     print('Dataloaders Created')\n",
    "     print('Train Loader Size: ',len(train_loader.dataset))\n",
    "     print('Validation Loader Size: ',len(val_loader.dataset))\n",
    "     print('Test Loader Size: ',len(test_loader.dataset))\n",
    "else:\n",
    "     print('Dataset does not Exist')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Reference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(params)\n",
    "    return params\n",
    "\n",
    "ai8x.set_device(device=85, simulate=False, round_avg=False)\n",
    "\n",
    "mod = importlib.import_module(\"models.ai85net-kws20-v3\")\n",
    "\n",
    "model = mod.AI85KWS20Netv3(num_classes=21, num_channels=128, dimensions=(128, 1), bias=False)\n",
    "print(f'Number of Model Params: {count_params(model)}')\n",
    "\n",
    "# WEIGHTS OF REFERENCE MODEL\n",
    "model, compression_scheduler, optimizer, start_epoch = apputils.load_checkpoint(\n",
    "            model, \"../logs/kws20_original/qat_best.pth.tar\")\n",
    "\n",
    " # FREEZE SOME LAYERS\n",
    "def freeze_layer(layer):\n",
    "    for p in layer.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "# freeze_layer(model.voice_conv1)\n",
    "# freeze_layer(model.voice_conv2)\n",
    "freeze_layer(model.voice_conv3)\n",
    "freeze_layer(model.voice_conv4)\n",
    "freeze_layer(model.kws_conv1)\n",
    "freeze_layer(model.kws_conv2)\n",
    "freeze_layer(model.kws_conv3)\n",
    "# freeze_layer(model.kws_conv4)\n",
    "model.fc = ai8x.Linear(256, len(classes), bias=False, wide=True)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "ms_lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[500, 1000], gamma=0.2)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights))\n",
    "print(criterion.type)\n",
    "criterion.to(device)\n",
    "\n",
    "qat_policy = {\n",
    "    'start_epoch': 300,\n",
    "    'weight_bits': 8\n",
    "    }\n",
    "print('Epochs: ', num_epochs)\n",
    "print('Optimizer: \\n',optimizer)\n",
    "print('Loss Function: \\n',criterion)\n",
    "print('QAT: \\n',qat_policy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "best_qat_acc = 0\n",
    "best_loss = 0\n",
    "best_epoch = 0\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "val_acc = []\n",
    "val_loss =[]\n",
    "running_class_acc = []\n",
    "\n",
    "continue_train = True\n",
    "epoch = 0\n",
    "while(continue_train and epoch < num_epochs):\n",
    "    train_start = time.time()\n",
    "    if epoch > 0 and epoch == qat_policy['start_epoch']:\n",
    "        print('QAT is starting!')\n",
    "        # Fuse the BN parameters into conv layers before Quantization Aware Training (QAT)\n",
    "        ai8x.fuse_bn_layers(model)\n",
    "        # Switch model from unquantized to quantized for QAT\n",
    "        ai8x.initiate_qat(model, qat_policy)\n",
    "        # Model is re-transferred to GPU in case parameters were added\n",
    "        model.to(device)\n",
    "\n",
    "    average_acc = 0\n",
    "    ############ TRAIN SECTION ############\n",
    "    running_loss = []\n",
    "    y_pred_train = []\n",
    "    y_true_train = []\n",
    "    acc_b = []\n",
    "    model.train()\n",
    "    for idx, (inputs, target) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.type(torch.int64)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        model_out = model(inputs)\n",
    "        target_out = torch.argmax(model_out, dim=1)\n",
    "        \n",
    "        y_pred_train.extend(target_out.cpu().numpy())\n",
    "        y_true_train.extend(target.cpu().numpy())\n",
    "        \n",
    "        tp = torch.sum(target_out == target)\n",
    "        acc_b.extend([(tp / target_out.numel()).detach().item()])\n",
    "\n",
    "        loss = criterion(model_out, target)     \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss.append(loss.cpu().detach().numpy())\n",
    "    \n",
    "    total_acc = np.mean(acc_b)*100\n",
    "    mean_loss = np.mean(running_loss)\n",
    "\n",
    "    # TRAIN ACCURACY / TRAIN LOSS\n",
    "    train_acc.append(total_acc)\n",
    "    train_loss.append(mean_loss)\n",
    "    average_acc += total_acc*0.5\n",
    "\n",
    "    ############ VALIDATION SECTION ############\n",
    "    acc_b = []\n",
    "    y_pred_val = []\n",
    "    y_true_val = []\n",
    "    running_v_loss = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, target in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            model_out = model(inputs)\n",
    "            target_out = torch.argmax(model_out, dim=1)\n",
    "            \n",
    "            y_pred_val.extend(target_out.cpu().numpy())\n",
    "            y_true_val.extend(target.cpu().numpy())\n",
    "            \n",
    "            tp = torch.sum(target_out == target)\n",
    "            acc_b.extend([(tp / target_out.numel()).detach().item()])\n",
    "\n",
    "            v_loss = criterion(model_out, target)\n",
    "            running_v_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        total_acc = np.mean(acc_b)*100\n",
    "        mean_loss = np.mean(running_v_loss)\n",
    "\n",
    "        if epoch == qat_policy['start_epoch']: best_acc = 0\n",
    "        \n",
    "        # VALIDATION ACCURACY / VALIDATION LOSS\n",
    "        val_acc.append(total_acc)\n",
    "        val_loss.append(mean_loss)\n",
    "        average_acc += total_acc*0.5\n",
    "    \n",
    "    ############ CLASS ACCURACY ############\n",
    "    class_acc = np.zeros(len(classes))\n",
    "    for class_num,class_type in enumerate(classes):\n",
    "        class_count_train = y_true_train.count(class_num)\n",
    "        class_count_val = y_true_val.count(class_num)\n",
    "\n",
    "        for t_idx, targ_val in enumerate(y_true_train):\n",
    "            if targ_val == y_pred_train[t_idx] and targ_val == class_num:\n",
    "                class_acc[class_num] += 1/class_count_train*10\n",
    "\n",
    "        for t_idx, targ_val in enumerate(y_true_val):\n",
    "            if targ_val == y_pred_val[t_idx] and targ_val == class_num:\n",
    "                class_acc[class_num] += 1/class_count_val*90\n",
    "        \n",
    "    running_class_acc.append(class_acc)\n",
    "    \n",
    "    train_end = time.time()\n",
    "    print('---------------------------------------------')\n",
    "    print(\"\\n\\n Epoch: {}/{} \\tLR: {} \\tDur: {:.2f} sec\".format(epoch+1, num_epochs, ms_lr_scheduler.get_lr() , (train_end-train_start)))\n",
    "\n",
    "    ############ SAVE CHECKPOINT ############   \n",
    "    if average_acc > best_acc:\n",
    "        best_acc = average_acc\n",
    "        checkpoint_extras = {'best_ave_acc': best_acc,\n",
    "                                'best_epoch': epoch}\n",
    "        \n",
    "        model_prefix = f'{model_name}' if epoch < qat_policy['start_epoch'] else (f'qat_{model_name}')\n",
    "        apputils.save_checkpoint(epoch, model_name+'_'+str(epoch), model, optimizer=optimizer,\n",
    "                                    scheduler=None, extras=checkpoint_extras,\n",
    "                                    is_best=True, name=model_prefix,\n",
    "                                    dir=checkpoint_dir)\n",
    "\n",
    "        # PLOT CONFUSION MATRIX AND STAT MEASURES ON TRAIN\n",
    "        conf_mat_train = confusion_matrix(y_true_train, y_pred_train)\n",
    "        cm_display_train = ConfusionMatrixDisplay(confusion_matrix = conf_mat_train, display_labels = classes)\n",
    "        p_train,r_train,f1_train,_= precision_recall_fscore_support(y_true_train, y_pred_train, average=None)\n",
    "        cm_display_train.plot(cmap= 'Blues',colorbar=False, values_format = 'd')\n",
    "        plt.title('Preicison: ({:.2f} {:.2f})   Recall: ({:.2f} {:.2f})   F1-Score: ({:.2f} {:.2f})'.format(p_train[0],p_train[1],r_train[0],r_train[1],f1_train[0],f1_train[1]))\n",
    "        plt.savefig(checkpoint_dir+model_name+'_cm_train.png')\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()\n",
    "\n",
    "        # PLOT ROC ON TRAIN\n",
    "        plot_roc_curve(y_true_train, y_pred_train)\n",
    "        plt.title('AUC: {:2f}'.format(roc_auc_score(y_true_train, y_pred_train)))\n",
    "        plt.savefig(checkpoint_dir+model_name+'_roc_train.png')\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()\n",
    "\n",
    "        # PLOT CONFUSION MATRIX AND STAT MEASURES ON VALIDATION\n",
    "        conf_mat_val = confusion_matrix(y_true_val, y_pred_val)\n",
    "        cm_display_val = ConfusionMatrixDisplay(confusion_matrix = conf_mat_val, display_labels = classes)\n",
    "        p_val,r_val,f1_val,_= precision_recall_fscore_support(y_true_val, y_pred_val, average=None)\n",
    "        cm_display_val.plot(cmap= 'Blues',colorbar=False, values_format = 'd')\n",
    "        plt.title('Preicison: ({:.2f} {:.2f})   Recall: ({:.2f} {:.2f})   F1-Score: ({:.2f} {:.2f})'.format(p_val[0],p_val[1],r_val[0],r_val[1],f1_val[0],f1_val[1]))\n",
    "        plt.savefig(checkpoint_dir+model_name+'_cm_Val.png')\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()\n",
    "\n",
    "        # PLOT ROC ON VAL\n",
    "        plot_roc_curve(y_true_val, y_pred_val)\n",
    "        plt.title('AUC: {:.2f}'.format(roc_auc_score(y_true_val, y_pred_val)))\n",
    "        plt.savefig(checkpoint_dir+model_name+'_roc_val.png')\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()\n",
    "\n",
    "        print(f' --------------------------------------------------------->  Model Checkpoints Saved with Mean Accuracy : {best_acc:.2f}%')\n",
    "\n",
    "    ############ CONFUSION MATRIX ############   \n",
    "    print(\"\\n Training - Confusion Matrix: \")\n",
    "    plot_confusion(y_true_train, y_pred_train, classes)\n",
    "    print(\"\\n Validation - Confusion Matrix: \")\n",
    "    plot_confusion(y_true_val, y_pred_val, classes)\n",
    "    \n",
    "    ############ ACC and LOSS ############  \n",
    "    print('\\nTrain Acc : ', train_acc[-1])\n",
    "    print('Train Loss : ', train_loss[-1])\n",
    "    print('Val Acc : ', val_acc[-1])\n",
    "    print('Val Loss : ', val_loss[-1])\n",
    "\n",
    "    ############ PLOTS ############\n",
    "    if (epoch%10 == 0 or epoch==num_epochs-1) and epoch > 0:\n",
    "        best_epoch = checkpoint_extras['best_epoch']\n",
    "        \n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.title(model_name)\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(val_acc, color ='green')\n",
    "        plt.plot(train_acc, color = 'red')\n",
    "        plt.plot(np.asarray(running_class_acc)[:,0],color='orange')\n",
    "        plt.plot(np.asarray(running_class_acc)[:,1],color='yellow')\n",
    "        plt.stem(best_epoch,train_acc[best_epoch])\n",
    "        plt.legend(['Validation','Train',classes[0],classes[1],'Checkpoint'])\n",
    "        plt.title('Accuracy: {:.2f}'.format(train_acc[best_epoch]))\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Value')\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(val_loss,color='green')\n",
    "        plt.plot(train_loss,color='red')\n",
    "        plt.stem(best_epoch,train_loss[best_epoch])\n",
    "        plt.legend(['Validation','Train','Checkpoint'])\n",
    "        plt.title('Loss: {:.2f}'.format(train_loss[best_epoch]))\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Value')\n",
    "\n",
    "        plt.savefig(checkpoint_dir+model_name+'.png')\n",
    "        \n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()\n",
    "    \n",
    "    ############ STOP TRAINING ############ \n",
    "    if epoch > num_epochs*0.75 and best_acc > 90 and average_acc > best_acc:\n",
    "        continue_train = False\n",
    "    \n",
    "    ms_lr_scheduler.step()\n",
    "    epoch += 1\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Processing Inference on Test Dataset \\n')\n",
    "y_true_inf = []\n",
    "y_pred_inf = []\n",
    "\n",
    "time_start = time.time()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, target in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.to(device)\n",
    "        model_out = model(inputs)\n",
    "        target_out = torch.argmax(model_out, dim=1)\n",
    "        y_true_inf.extend(target.cpu().numpy())\n",
    "        y_pred_inf.extend(target_out.cpu().numpy())\n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "print('Inference Finished in {:2f} seconds'.format(time_end-time_start))\n",
    "\n",
    "conf_mat_train = confusion_matrix(y_true_inf, y_pred_inf)\n",
    "cm_display_train = ConfusionMatrixDisplay(confusion_matrix = conf_mat_train, display_labels = classes)\n",
    "p_train,r_train,f1_train,_= precision_recall_fscore_support(y_true_inf, y_pred_inf, average=None)\n",
    "cm_display_train.plot(cmap= 'Blues',colorbar=False, values_format = 'd')\n",
    "\n",
    "\n",
    "plt.title('Preicison: ({:.2f} {:.2f})   Recall: ({:.2f} {:.2f})   F1-Score: ({:.2f} {:.2f})'.format(p_train[0],p_train[1],r_train[0],r_train[1],f1_train[0],f1_train[1]))\n",
    "\n",
    "fname = model_name+'_cm_test.png'\n",
    "plt.savefig(checkpoint_dir+fname)\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on Training and Validation Dataset from Processed Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Processing Inference on Training Dataset \\n')\n",
    "\n",
    "# LOAD DATASET FILE\n",
    "#data_file = torch.load(processed_dir+model_name+'.pt') # (data, class, type)\n",
    "\n",
    "y_true_inf = data_file[1].cpu().numpy()\n",
    "y_pred_inf = []\n",
    "file_count = len(y_true_inf)\n",
    "\n",
    "time_start = time.time()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for counter,val in enumerate((data_file[0])):\n",
    "        val =val[None,:]\n",
    "        inputs = val.to(torch.float)\n",
    "        ############ INFERENCE SECTION ############\n",
    "        inputs = inputs.to(device)\n",
    "        model_out = model(inputs)\n",
    "        target_out = torch.argmax(model_out, dim=1)\n",
    "        \n",
    "        class_output = target_out.detach().item()\n",
    "\n",
    "        print('Remaining: ',(file_count-counter),'\\tTrue:', y_true_inf[counter],'\\tOutput:', class_output)\n",
    "        y_pred_inf.append(class_output)\n",
    "\n",
    "     #print('\\t\\t Test Acc: {:.2f}'.format(total_acc))\n",
    "   \n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "print('Inference Finished in {:2f} seconds'.format(time_end-time_start))\n",
    "\n",
    "conf_mat_train = confusion_matrix(y_true_inf, y_pred_inf)\n",
    "cm_display_train = ConfusionMatrixDisplay(confusion_matrix = conf_mat_train, display_labels = classes)\n",
    "p_train,r_train,f1_train,_= precision_recall_fscore_support(y_true_inf, y_pred_inf, average=None)\n",
    "cm_display_train.plot(cmap= 'Blues',colorbar=False, values_format = 'd')\n",
    "\n",
    "\n",
    "plt.title('Preicison: ({:.2f} {:.2f})   Recall: ({:.2f} {:.2f})   F1-Score: ({:.2f} {:.2f})'.format(p_train[0],p_train[1],r_train[0],r_train[1],f1_train[0],f1_train[1]))\n",
    "\n",
    "fname = model_name+'_'+str(classes[0])+'_'+str(classes[1])+'_cm_inference.png'\n",
    "fname = model_name+'_processed_inf.png'\n",
    "plt.savefig(checkpoint_dir+fname)\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on Horse Cough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Processing Inference on Custom Dataset \\n')\n",
    "     \n",
    "class_paths = {'combined': \"../data/KWS_EQUINE/raw/combined/\",\n",
    "               'human_cough':\"../data/KWS_EQUINE/raw/human_cough/\"}\n",
    "\n",
    "# class_paths = {'combined': \"../data/KWS_EQUINE/raw/combined/\",\n",
    "#                'human_cough': \"C:/Users/J_C/Desktop/DATASETS_N/human_cough_v3/\"}\n",
    "\n",
    "class_paths = {'combinedKWS': \"../data/KWS_EQUINE/raw/__combinedkws/\",\n",
    "               'horse_cough': \"../data/KWS_EQUINE/inference/horse_cough/\"}\n",
    "\n",
    "# class_paths = {'combined': \"../data/KWS_EQUINE/raw/combined/\",\n",
    "#                'horse_cough': \"../data/KWS_EQUINE/inference/horse_cough/\"}\n",
    "\n",
    "sample_count = False\n",
    "y_true_inf = []\n",
    "y_pred_inf = []\n",
    "\n",
    "min_val=0\n",
    "max_val=255\n",
    "\n",
    "classes = list(class_paths.keys())\n",
    "time_start = time.time()\n",
    "with torch.no_grad():\n",
    "    for class_ix,inf_path in enumerate(list(class_paths.values())):\n",
    "        files = os.listdir(inf_path)\n",
    "        file_count = len(files)\n",
    "        inferences = []\n",
    "        \n",
    "        random.shuffle(files)\n",
    "        \n",
    "        if sample_count < file_count and type(sample_count) == int : files = files[0:sample_count]\n",
    "\n",
    "        for counter,f in enumerate(files):\n",
    "            try:\n",
    "                # CONVERT EACH AUDIO FILE TO A 128X128 ARRAY\n",
    "                data_sq = np.zeros(128)\n",
    "                data, sr = librosa.load(inf_path+f,sr = 16000)\n",
    "                data = rescale2(data,min_val=0,max_val=254) \n",
    "                data = librosa.util.fix_length(data,size=int(128*128))\n",
    "                for index in range(0,len(data),128):\n",
    "                    data_row = data[index:index+128]\n",
    "                    data_sq = np.vstack((data_sq,data_row))\n",
    "                data_sq = data_sq[1:129]\n",
    "                data_sq = data_sq.transpose()\n",
    "                \n",
    "                # CONVERT ARRAY TO TENSOR\n",
    "                data_sq = np.expand_dims(data_sq, axis=0)\n",
    "                inputs = torch.from_numpy(data_sq.astype(np.float32))  \n",
    "                inputs.to(torch.uint8)\n",
    "                ############ INFERENCE SECTION ############\n",
    "                inputs = inputs.to(device)\n",
    "                model_out = model(inputs)\n",
    "                target_out = torch.argmax(model_out, dim=1)\n",
    "                class_output = target_out.detach().item()\n",
    "\n",
    "                y_true_inf.append(class_ix)\n",
    "                y_pred_inf.append(class_output)\n",
    "\n",
    "                \n",
    "                print('Remaining: ',(file_count-counter),'\\tTrue:', class_ix,'\\tOutput:', class_output)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "     #print('\\t\\t Test Acc: {:.2f}'.format(total_acc))\n",
    "   \n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "print('Inference Finished in {:2f} seconds'.format(time_end-time_start))\n",
    "\n",
    "conf_mat_train = confusion_matrix(y_true_inf, y_pred_inf)\n",
    "cm_display_train = ConfusionMatrixDisplay(confusion_matrix = conf_mat_train, display_labels = classes)\n",
    "p_train,r_train,f1_train,_= precision_recall_fscore_support(y_true_inf, y_pred_inf, average=None)\n",
    "cm_display_train.plot(cmap= 'Blues',colorbar=False, values_format = 'd')\n",
    "\n",
    "classes = ['combined','human_cough']\n",
    "\n",
    "plt.title('Preicison: ({:.2f} {:.2f})   Recall: ({:.2f} {:.2f})   F1-Score: ({:.2f} {:.2f})'.format(p_train[0],p_train[1],r_train[0],r_train[1],f1_train[0],f1_train[1]))\n",
    "\n",
    "fname = model_name+'_'+str(classes[0])+'_'+str(classes[1])+'_cm_inference_2.png'\n",
    "fname = model_name+'_custom_inf.png'\n",
    "plt.savefig(checkpoint_dir+fname)\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec35e5d0984cc59eb0cd6a0be286daf2d556405b3fb6375200d13e76db69dcf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
