{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "from distiller import apputils\n",
    "import ai8x\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "kws20 = importlib.import_module(\"datasets.kws20-horsecough\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,multilabel_confusion_matrix\n",
    "\n",
    "def rescale(audio, min_val=-1,max_val=1):\n",
    "            sig = audio\n",
    "            mean = np.average(sig)\n",
    "\n",
    "            sig = sig-mean # REMOVE DC COMPONENT\n",
    "\n",
    "            sig_max = np.max(sig)\n",
    "            sig_min = np.min(sig)\n",
    "\n",
    "            if sig_max >= np.abs(sig_min):\n",
    "                sig_scaled = sig/sig_max\n",
    "            else:\n",
    "                sig_scaled = sig/np.abs(sig_min)\n",
    "\n",
    "            return sig_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring device: MAX78000, simulate=False.\n",
      "Running on device: NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AI85EQUINE(\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       "  (voice_conv1): FusedConv1dReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (op): Conv1d(128, 100, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (voice_conv2): FusedConv1dReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (op): Conv1d(100, 96, kernel_size=(3,), stride=(1,), bias=False)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (voice_conv3): FusedMaxPoolConv1dReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (op): Conv1d(96, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (voice_conv4): FusedConv1dReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (op): Conv1d(64, 48, kernel_size=(3,), stride=(1,), bias=False)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (kws_conv1): FusedMaxPoolConv1dReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (op): Conv1d(48, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (kws_conv2): FusedConv1dReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (op): Conv1d(64, 96, kernel_size=(3,), stride=(1,), bias=False)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (kws_conv3): FusedAvgPoolConv1dReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (pool): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (op): Conv1d(96, 100, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Clamp()\n",
       "  )\n",
       "  (kws_conv4): FusedMaxPoolConv1dReLU(\n",
       "    (activate): ReLU(inplace=True)\n",
       "    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (op): Conv1d(100, 64, kernel_size=(6,), stride=(1,), padding=(1,), bias=False)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       "  (fc): Linear(\n",
       "    (activate): Empty()\n",
       "    (op): Linear(in_features=256, out_features=2, bias=False)\n",
       "    (calc_out_shift): OutputShiftSqueeze()\n",
       "    (calc_weight_scale): One()\n",
       "    (scale): Scaler()\n",
       "    (calc_out_scale): OutputScale()\n",
       "    (quantize_weight): Empty()\n",
       "    (quantize_bias): Empty()\n",
       "    (clamp_weight): Empty()\n",
       "    (clamp_bias): Empty()\n",
       "    (quantize): Empty()\n",
       "    (clamp): Clamp()\n",
       "    (quantize_pool): Empty()\n",
       "    (clamp_pool): Empty()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_params(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(params)\n",
    "    return params\n",
    "\n",
    "ai8x.set_device(device=85, simulate=False, round_avg=False)\n",
    "\n",
    "model_name = 'equine_1'\n",
    "checkpoint_dir = '../notebooks/checkpoints/'+model_name+'/'\n",
    "checkpoint_file = checkpoint_dir+'/qat_'+model_name+'_best.pth.tar'\n",
    "\n",
    "# GET MODEL STRUCTURE\n",
    "mod = importlib.import_module(\"models.ai85net-equine\")\n",
    "model = mod.AI85EQUINE(num_classes=2, num_channels=128, dimensions=(128, 1), bias=False)\n",
    "\n",
    "# LOAD MODEL CHECKPOINT\n",
    "model, compression_scheduler, optimizer, start_epoch = apputils.load_checkpoint(model,checkpoint_file,lean_checkpoint=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    cpu = False\n",
    "else:\n",
    "     device = torch.device('cpu')\n",
    "     cpu = True\n",
    "\n",
    "print('Running on device: {}'.format(torch.cuda.get_device_name()))\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  0   Remaining:  127\n",
      "Class:  0   Remaining:  126\n",
      "Class:  0   Remaining:  125\n",
      "Class:  0   Remaining:  124\n",
      "Class:  0   Remaining:  123\n",
      "Class:  0   Remaining:  122\n",
      "Class:  0   Remaining:  121\n",
      "Class:  0   Remaining:  120\n",
      "Class:  0   Remaining:  119\n",
      "Class:  0   Remaining:  118\n",
      "Class:  0   Remaining:  117\n",
      "Class:  0   Remaining:  116\n",
      "Class:  0   Remaining:  115\n",
      "Class:  0   Remaining:  114\n",
      "Class:  0   Remaining:  113\n",
      "Class:  0   Remaining:  112\n",
      "Class:  0   Remaining:  111\n",
      "Class:  0   Remaining:  110\n",
      "Class:  0   Remaining:  109\n",
      "Class:  0   Remaining:  108\n",
      "Class:  0   Remaining:  107\n",
      "Class:  0   Remaining:  106\n",
      "Class:  0   Remaining:  105\n",
      "Class:  0   Remaining:  104\n",
      "Class:  0   Remaining:  103\n",
      "Class:  0   Remaining:  102\n",
      "Class:  0   Remaining:  101\n",
      "Class:  0   Remaining:  100\n",
      "Class:  0   Remaining:  99\n",
      "Class:  0   Remaining:  98\n",
      "Class:  0   Remaining:  97\n",
      "Class:  0   Remaining:  96\n",
      "Class:  0   Remaining:  95\n",
      "Class:  0   Remaining:  94\n",
      "Class:  0   Remaining:  93\n",
      "Class:  0   Remaining:  92\n",
      "Class:  0   Remaining:  91\n",
      "Class:  0   Remaining:  90\n",
      "Class:  0   Remaining:  89\n",
      "Class:  0   Remaining:  88\n",
      "Class:  0   Remaining:  87\n",
      "Class:  0   Remaining:  86\n",
      "Class:  0   Remaining:  85\n",
      "Class:  0   Remaining:  84\n",
      "Class:  0   Remaining:  83\n",
      "Class:  0   Remaining:  82\n",
      "Class:  0   Remaining:  81\n",
      "Class:  0   Remaining:  80\n",
      "Class:  0   Remaining:  79\n",
      "Class:  0   Remaining:  78\n",
      "Class:  0   Remaining:  77\n",
      "Class:  0   Remaining:  76\n",
      "Class:  0   Remaining:  75\n",
      "Class:  0   Remaining:  74\n",
      "Class:  0   Remaining:  73\n",
      "Class:  0   Remaining:  72\n",
      "Class:  0   Remaining:  71\n",
      "Class:  0   Remaining:  70\n",
      "Class:  0   Remaining:  69\n",
      "Class:  0   Remaining:  68\n",
      "Class:  0   Remaining:  67\n",
      "Class:  0   Remaining:  66\n",
      "Class:  0   Remaining:  65\n",
      "Class:  0   Remaining:  64\n",
      "Class:  0   Remaining:  63\n",
      "Class:  0   Remaining:  62\n",
      "Class:  0   Remaining:  61\n",
      "Class:  0   Remaining:  60\n",
      "Class:  0   Remaining:  59\n",
      "Class:  0   Remaining:  58\n",
      "Class:  0   Remaining:  57\n",
      "Class:  0   Remaining:  56\n",
      "Class:  0   Remaining:  55\n",
      "Class:  0   Remaining:  54\n",
      "Class:  0   Remaining:  53\n",
      "Class:  0   Remaining:  52\n",
      "Class:  0   Remaining:  51\n",
      "Class:  0   Remaining:  50\n",
      "Class:  0   Remaining:  49\n",
      "Class:  0   Remaining:  48\n",
      "Class:  0   Remaining:  47\n",
      "Class:  0   Remaining:  46\n",
      "Class:  0   Remaining:  45\n",
      "Class:  0   Remaining:  44\n",
      "Class:  0   Remaining:  43\n",
      "Class:  0   Remaining:  42\n",
      "Class:  0   Remaining:  41\n",
      "Class:  0   Remaining:  40\n",
      "Class:  0   Remaining:  39\n",
      "Class:  0   Remaining:  38\n",
      "Class:  0   Remaining:  37\n",
      "Class:  0   Remaining:  36\n",
      "Class:  0   Remaining:  35\n",
      "Class:  0   Remaining:  34\n",
      "Class:  0   Remaining:  33\n",
      "Class:  0   Remaining:  32\n",
      "Class:  0   Remaining:  31\n",
      "Class:  0   Remaining:  30\n",
      "Class:  0   Remaining:  29\n",
      "Class:  0   Remaining:  28\n",
      "Class:  0   Remaining:  27\n",
      "Class:  0   Remaining:  26\n",
      "Class:  0   Remaining:  25\n",
      "Class:  0   Remaining:  24\n",
      "Class:  0   Remaining:  23\n",
      "Class:  0   Remaining:  22\n",
      "Class:  0   Remaining:  21\n",
      "Class:  0   Remaining:  20\n",
      "Class:  0   Remaining:  19\n",
      "Class:  0   Remaining:  18\n",
      "Class:  0   Remaining:  17\n",
      "Class:  0   Remaining:  16\n",
      "Class:  0   Remaining:  15\n",
      "Class:  0   Remaining:  14\n",
      "Class:  0   Remaining:  13\n",
      "Class:  0   Remaining:  12\n",
      "Class:  0   Remaining:  11\n",
      "Class:  0   Remaining:  10\n",
      "Class:  0   Remaining:  9\n",
      "Class:  0   Remaining:  8\n",
      "Class:  0   Remaining:  7\n",
      "Class:  0   Remaining:  6\n",
      "Class:  0   Remaining:  5\n",
      "Class:  0   Remaining:  4\n",
      "Class:  0   Remaining:  3\n",
      "Class:  0   Remaining:  2\n",
      "Class:  0   Remaining:  1\n",
      "Class:  1   Remaining:  10\n",
      "Class:  1   Remaining:  9\n",
      "Class:  1   Remaining:  8\n",
      "Class:  1   Remaining:  7\n",
      "Class:  1   Remaining:  6\n",
      "Class:  1   Remaining:  5\n",
      "Class:  1   Remaining:  4\n",
      "Class:  1   Remaining:  3\n",
      "Class:  1   Remaining:  2\n",
      "Class:  1   Remaining:  1\n",
      "Inference Finished in 3.120355 seconds\n"
     ]
    }
   ],
   "source": [
    "# class_paths = {'combined': \"../data/KWS_EQUINE/raw/combined/\",\n",
    "#                'human_cough': \"C:/Users/J_C/Desktop/DATASETS_N/human_cough_v3/\"}\n",
    "\n",
    "# class_paths = {'combinedKWS': \"../data/KWS_EQUINE/raw/__combinedkws/\",\n",
    "#                'horse_cough': \"../data/KWS_EQUINE/inference/horse_cough/\"}\n",
    "\n",
    "# class_paths = {'combined': \"../data/KWS_EQUINE/raw/combined/\",\n",
    "#                'horse_cough': \"../data/KWS_EQUINE/inference/horse_cough/\"}\n",
    "\n",
    "class_paths = {'horse_cough_internet': \"../data/KWS_EQUINE/inference/horse_cough/\",\n",
    "               'horse_cough_stable': \"C:/Users/J_C/Desktop/DATASETS_N/horse_cough_stable/\"}\n",
    "\n",
    "\n",
    "y_true_train = []\n",
    "y_pred_train = []\n",
    "\n",
    "classes = list(class_paths.keys())\n",
    "time_start = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for class_ix,inf_path in enumerate(list(class_paths.values())):\n",
    "        files = os.listdir(inf_path)\n",
    "        file_count = len(files)\n",
    "        inferences = []\n",
    "        for counter,f in enumerate(files):\n",
    "            try:\n",
    "                print('Class: ',class_ix,'  Remaining: ',(file_count-counter))\n",
    "\n",
    "                # CONVERT EACH AUDIO FILE TO A 128X128 ARRAY\n",
    "                data_sq = np.zeros(128)\n",
    "                data,sr = librosa.load(inf_path+f,sr = 16000)\n",
    "                data = rescale(audio=data)\n",
    "                data = librosa.util.fix_length(data,size=int(128*128))\n",
    "                for index in range(0,len(data),128):\n",
    "                    data_row = data[index:index+128]\n",
    "                    data_sq = np.vstack((data_sq,data_row))\n",
    "                data_sq = data_sq[1:129]\n",
    "                data_sq = np.asarray(data_sq).astype(np.float32)\n",
    "                data_sq = data_sq.transpose()\n",
    "                \n",
    "                # CONVERT ARRAY TO TENSOR\n",
    "                data_sq = np.expand_dims(data_sq, axis=0)\n",
    "                inputs = torch.from_numpy(data_sq)  \n",
    "                \n",
    "                ############ INFERENCE SECTION ############\n",
    "                inputs = inputs.to(device)\n",
    "                model_out = model(inputs)\n",
    "                target_out = torch.argmax(model_out, dim=1)\n",
    "                class_output = target_out.detach().item()\n",
    "\n",
    "                # For KWS words\n",
    "                if class_ix == 2 and class_output == 0: class_output = class_ix\n",
    "                elif class_ix == 2 and class_output == 1: class_output = 3\n",
    "\n",
    "                # For Horse Cough\n",
    "                if class_ix == 3 and class_output == 1: class_output = class_ix\n",
    "                elif class_ix == 3 and class_output == 0: class_output = 2\n",
    "\n",
    "                \n",
    "                y_true_train.append(class_ix)\n",
    "                y_pred_train.append(class_output)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "     #print('\\t\\t Test Acc: {:.2f}'.format(total_acc))\n",
    "   \n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "print('Inference Finished in {:2f} seconds'.format(time_end-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_dir = \"../data/KWS_EQUINE/processed/\"\n",
    "# classes = ['combined','cough']\n",
    "\n",
    "# # LOAD DATASET FILE\n",
    "# data_file = torch.load(processed_dir+'/dataset2.pt')\n",
    "\n",
    "\n",
    "# y_true_train = data_file[1].cpu().numpy()\n",
    "# y_pred_train = []\n",
    "\n",
    "# time_start = time.time()\n",
    "\n",
    "# file_count = len(y_true_train)\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for counter,val in enumerate((data_file[0])):\n",
    "#         val = val.numpy().astype(np.float32)\n",
    "#         val = np.expand_dims(val,axis=0)\n",
    "#         inputs = torch.from_numpy(val)  \n",
    "\n",
    "#         ############ INFERENCE SECTION ############\n",
    "#         inputs = inputs.to(device)\n",
    "#         model_out = model(inputs)\n",
    "#         target_out = torch.argmax(model_out, dim=1)\n",
    "        \n",
    "#         class_output = target_out.detach().item()\n",
    "\n",
    "#         print('Remaining: ',(file_count-counter),'\\tTrue:', y_true_train[counter],'\\tOutput:', class_output)\n",
    "#         y_pred_train.append(class_output)\n",
    "\n",
    "#      #print('\\t\\t Test Acc: {:.2f}'.format(total_acc))\n",
    "   \n",
    "\n",
    "# time_end = time.time()\n",
    "\n",
    "# print('Inference Finished in {:2f} seconds'.format(time_end-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
    "\n",
    "def plot_confusion(y_true, y_pred, classes):\n",
    "    cf_matrix = confusion_matrix(y_true = y_true, y_pred = y_pred, labels =list(range(len(classes))))\n",
    "    print(cf_matrix)\n",
    "\n",
    "# PLOT CONFUSION MATRIX AND STAT MEASURES ON TRAIN\n",
    "conf_mat_train = confusion_matrix(y_true_train, y_pred_train)\n",
    "cm_display_train = ConfusionMatrixDisplay(confusion_matrix = conf_mat_train, display_labels = classes)\n",
    "p_train,r_train,f1_train,_= precision_recall_fscore_support(y_true_train, y_pred_train, average=None)\n",
    "cm_display_train.plot(cmap= 'Blues',colorbar=False, values_format = 'd')\n",
    "plt.title('Preicison: ({:.2f} {:.2f})   Recall: ({:.2f} {:.2f})   F1-Score: ({:.2f} {:.2f})'.format(p_train[0],p_train[1],r_train[0],r_train[1],f1_train[0],f1_train[1]))\n",
    "\n",
    "fname = model_name+'_'+str(classes[0])+'_'+str(classes[1])+'_cm_inference.png'\n",
    "fname = 'test.png'\n",
    "plt.savefig(checkpoint_dir+fname)\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
